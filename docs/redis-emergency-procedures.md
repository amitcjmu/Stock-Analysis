# Redis Emergency Procedures and Troubleshooting Guide
*Generated by CC DevSecOps Engineer*

This document provides comprehensive emergency procedures, troubleshooting steps, and recovery protocols for Redis infrastructure issues in the AI Force Migration Platform.

## ðŸš¨ Emergency Contact Information

**Critical Escalation Path:**
1. **DevOps Engineer** - Primary Redis infrastructure contact
2. **Security Team** - For security-related incidents
3. **Platform Engineering** - For application-level cache issues
4. **Management** - For business impact assessment

**Emergency Notification Channels:**
- Slack: `#redis-alerts` 
- Email: `redis-alerts@company.com`
- PagerDuty: Redis service key

---

## ðŸš¨ Critical Emergency Procedures

### 1. Redis Complete Outage

**Symptoms:**
- All Redis connections failing
- Application showing "Redis unavailable" errors
- Health checks returning 503 status

**Immediate Actions (< 5 minutes):**

```bash
# Step 1: Check Redis service status
docker ps | grep redis                    # Local development
railway status                           # Production

# Step 2: Quick health check
redis-cli -h localhost -p 6379 ping     # Local
curl https://your-app.railway.app/api/v1/health/redis  # Production

# Step 3: Emergency fallback - Disable Redis
export REDIS_ENABLED=false              # Local
railway variables set REDIS_ENABLED=false  # Production
```

**Recovery Steps:**

```bash
# Local Development Recovery
cd /Users/chocka/CursorProjects/migrate-ui-orchestrator
docker-compose -f docker-compose.dev.yml restart redis
docker-compose -f docker-compose.dev.yml logs redis

# Production Recovery
railway restart
railway logs

# Validate recovery
python scripts/deploy_redis_infrastructure.py production --validate-only
```

### 2. Memory Exhaustion

**Symptoms:**
- `OOM command not allowed when used memory > 'maxmemory'`
- High memory usage alerts
- Slow Redis response times

**Immediate Actions:**

```bash
# Check memory usage
redis-cli info memory | grep used_memory
redis-cli info memory | grep maxmemory

# Find large keys
redis-cli --bigkeys

# Emergency memory cleanup (DANGEROUS - use carefully)
redis-cli flushdb  # Only if absolutely necessary
```

**Safe Recovery:**

```bash
# Increase memory limit temporarily
redis-cli config set maxmemory 512mb

# Clean up expired keys
redis-cli eval "return redis.call('del', unpack(redis.call('keys', 'temp:*')))" 0

# Set shorter TTL on non-critical data
redis-cli eval "
    local keys = redis.call('keys', 'cache:*')
    for i=1,#keys do
        redis.call('expire', keys[i], 300)
    end
    return #keys
" 0
```

### 3. Security Breach

**Symptoms:**
- Suspicious Redis commands in logs
- Unexpected data modifications
- Authentication failures

**Immediate Actions:**

```bash
# Step 1: Isolate Redis
# Change all Redis passwords immediately
export REDIS_PASSWORD="$(openssl rand -base64 32)"

# Step 2: Check for unauthorized access
redis-cli client list | grep -v "127.0.0.1"

# Step 3: Review ACL logs
redis-cli acl log

# Step 4: Enable ACL logging
redis-cli config set acllog-max-len 128
```

**Security Incident Response:**

```bash
# Backup current state for forensics
redis-cli --rdb redis_incident_backup_$(date +%Y%m%d_%H%M%S).rdb

# Check for malicious keys
redis-cli --scan --pattern "*malicious*"
redis-cli --scan --pattern "*suspicious*"

# Review slow log for unusual commands
redis-cli slowlog get 100

# Reset ACL users with new passwords
redis-cli acl setuser app_backend reset >${NEW_APP_PASSWORD}
```

---

## ðŸ”§ Common Issues and Solutions

### Issue 1: Connection Timeouts

**Symptoms:**
```
ConnectionError: Error connecting to localhost:6379. Connection timed out.
```

**Diagnosis:**
```bash
# Check if Redis is running
pgrep redis-server
docker ps | grep redis

# Check network connectivity
telnet localhost 6379
nc -zv localhost 6379

# Check Redis configuration
redis-cli config get timeout
redis-cli config get tcp-keepalive
```

**Solutions:**
```bash
# Increase connection timeout
redis-cli config set timeout 300

# Enable TCP keepalive
redis-cli config set tcp-keepalive 60

# Restart Redis with optimal settings
docker-compose -f docker-compose.dev.yml restart redis
```

### Issue 2: High Latency

**Symptoms:**
- Redis operations taking > 100ms
- Application performance degradation

**Diagnosis:**
```bash
# Check slow log
redis-cli slowlog get 10

# Monitor real-time latency
redis-cli --latency

# Check memory fragmentation
redis-cli info memory | grep mem_fragmentation_ratio

# Monitor current operations
redis-cli monitor  # Ctrl+C to stop
```

**Solutions:**
```bash
# Optimize memory usage
redis-cli config set activerehashing yes

# Increase background save frequency
redis-cli config set save "900 1 300 10 60 10000"

# Use pipelining for bulk operations
redis-cli --pipe < bulk_commands.txt
```

### Issue 3: Data Corruption

**Symptoms:**
- Redis refusing to start
- RDB/AOF file corruption errors

**Diagnosis:**
```bash
# Check Redis logs
docker-compose -f docker-compose.dev.yml logs redis
tail -f /var/log/redis/redis.log

# Test RDB file
redis-check-rdb /data/dump.rdb

# Test AOF file
redis-check-aof /data/appendonly.aof
```

**Recovery:**
```bash
# Fix AOF file
redis-check-aof --fix /data/appendonly.aof

# Restore from backup
cp /backup/dump.rdb /data/dump.rdb
chown redis:redis /data/dump.rdb

# Start Redis with recovery options
redis-server --appendonly yes --aof-load-truncated yes
```

---

## ðŸ“Š Monitoring and Alerting

### Critical Metrics to Monitor

1. **Memory Usage**: `used_memory / maxmemory > 0.8`
2. **Connection Count**: `connected_clients / maxclients > 0.8`
3. **Hit Rate**: `keyspace_hits / (keyspace_hits + keyspace_misses) < 0.9`
4. **Latency**: `avg_latency > 10ms`
5. **Error Rate**: `error_count / total_operations > 0.01`

### Automated Health Checks

```bash
#!/bin/bash
# Redis Health Check Script
# Save as: scripts/redis_health_check.sh

REDIS_HOST=${REDIS_HOST:-localhost}
REDIS_PORT=${REDIS_PORT:-6379}
REDIS_PASSWORD=${REDIS_PASSWORD}

# Function to check Redis health
check_redis_health() {
    local cmd="redis-cli -h $REDIS_HOST -p $REDIS_PORT"
    
    if [ ! -z "$REDIS_PASSWORD" ]; then
        cmd="$cmd -a $REDIS_PASSWORD"
    fi
    
    # Ping test
    if ! $cmd ping > /dev/null 2>&1; then
        echo "âŒ Redis ping failed"
        return 1
    fi
    
    # Memory check
    local memory_info=$($cmd info memory)
    local used_memory=$(echo "$memory_info" | grep "used_memory:" | cut -d: -f2 | tr -d '\r')
    local max_memory=$(echo "$memory_info" | grep "maxmemory:" | cut -d: -f2 | tr -d '\r')
    
    if [ "$max_memory" -gt 0 ]; then
        local memory_percent=$((used_memory * 100 / max_memory))
        if [ $memory_percent -gt 85 ]; then
            echo "âš ï¸  High memory usage: ${memory_percent}%"
        fi
    fi
    
    echo "âœ… Redis health check passed"
    return 0
}

# Run health check
check_redis_health
```

### Setting Up Alerts

```python
# Monitoring script with alerts
# Save as: scripts/redis_monitoring.py

import asyncio
import json
import logging
import smtplib
from datetime import datetime
from email.mime.text import MIMEText

class RedisAlerting:
    def __init__(self):
        self.alert_thresholds = {
            'memory_usage_percent': 85,
            'connection_usage_percent': 80,
            'hit_rate_percent': 90,
            'avg_latency_ms': 50,
            'error_rate_percent': 1
        }
        
    async def check_and_alert(self):
        """Check Redis metrics and send alerts if needed"""
        # Get current metrics from monitoring
        metrics = await self.get_redis_metrics()
        
        alerts = []
        
        # Check each threshold
        for metric, threshold in self.alert_thresholds.items():
            current_value = metrics.get(metric, 0)
            
            if self.should_alert(metric, current_value, threshold):
                alerts.append({
                    'metric': metric,
                    'current': current_value,
                    'threshold': threshold,
                    'severity': self.get_alert_severity(metric, current_value, threshold)
                })
        
        # Send alerts if any
        if alerts:
            await self.send_alerts(alerts)
    
    def should_alert(self, metric, current, threshold):
        """Determine if alert should be sent"""
        if 'percent' in metric:
            return current > threshold
        elif 'rate' in metric and 'hit' in metric:
            return current < threshold  # Hit rate should be high
        else:
            return current > threshold
    
    async def send_alerts(self, alerts):
        """Send alert notifications"""
        message = self.format_alert_message(alerts)
        
        # Send to Slack, email, etc.
        await self.send_slack_alert(message)
        self.send_email_alert(message)
    
    def format_alert_message(self, alerts):
        """Format alert message"""
        message = f"ðŸš¨ Redis Alert - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        
        for alert in alerts:
            emoji = "ðŸ”´" if alert['severity'] == 'critical' else "âš ï¸"
            message += f"{emoji} {alert['metric']}: {alert['current']} (threshold: {alert['threshold']})\n"
        
        return message
```

---

## ðŸ”„ Backup and Recovery

### Automated Backup Script

```bash
#!/bin/bash
# Redis Backup Script
# Save as: scripts/backup_redis.sh

BACKUP_DIR="/backup/redis"
DATE=$(date +%Y%m%d_%H%M%S)
REDIS_HOST=${REDIS_HOST:-localhost}
REDIS_PORT=${REDIS_PORT:-6379}

# Create backup directory
mkdir -p $BACKUP_DIR

# Create RDB backup
echo "Creating RDB backup..."
redis-cli -h $REDIS_HOST -p $REDIS_PORT --rdb "$BACKUP_DIR/redis_backup_$DATE.rdb"

# Create AOF backup if enabled
if redis-cli -h $REDIS_HOST -p $REDIS_PORT config get appendonly | grep -q yes; then
    echo "Creating AOF backup..."
    cp /data/appendonly.aof "$BACKUP_DIR/redis_aof_backup_$DATE.aof"
fi

# Compress backups
gzip "$BACKUP_DIR/redis_backup_$DATE.rdb"
if [ -f "$BACKUP_DIR/redis_aof_backup_$DATE.aof" ]; then
    gzip "$BACKUP_DIR/redis_aof_backup_$DATE.aof"
fi

# Upload to cloud storage (optional)
# aws s3 cp "$BACKUP_DIR/" s3://redis-backups/ --recursive

# Clean old backups (keep last 7 days)
find $BACKUP_DIR -name "redis_backup_*.rdb.gz" -mtime +7 -delete
find $BACKUP_DIR -name "redis_aof_backup_*.aof.gz" -mtime +7 -delete

echo "Backup completed: $BACKUP_DIR/redis_backup_$DATE.rdb.gz"
```

### Recovery Procedures

```bash
# Full Redis Recovery from Backup

# Step 1: Stop Redis
docker-compose -f docker-compose.dev.yml stop redis

# Step 2: Backup current data
mv /data/dump.rdb /data/dump.rdb.backup.$(date +%Y%m%d_%H%M%S)

# Step 3: Restore from backup
gunzip -c /backup/redis/redis_backup_YYYYMMDD_HHMMSS.rdb.gz > /data/dump.rdb
chown redis:redis /data/dump.rdb

# Step 4: Start Redis
docker-compose -f docker-compose.dev.yml start redis

# Step 5: Verify restoration
redis-cli ping
redis-cli dbsize
```

---

## ðŸ› ï¸ Diagnostic Tools

### Redis Diagnostic Script

```python
#!/usr/bin/env python3
# Redis Diagnostic Tool
# Save as: scripts/redis_diagnostics_comprehensive.py

import asyncio
import json
import subprocess
import sys
import time
from datetime import datetime

class RedisDiagnostics:
    def __init__(self):
        self.redis_host = "localhost"
        self.redis_port = 6379
        self.results = {
            'timestamp': datetime.now().isoformat(),
            'diagnostics': {}
        }
    
    async def run_full_diagnostics(self):
        """Run comprehensive Redis diagnostics"""
        print("ðŸ” Running Redis Diagnostics...")
        print("=" * 50)
        
        # Check 1: Basic connectivity
        await self.check_connectivity()
        
        # Check 2: Memory analysis
        await self.check_memory()
        
        # Check 3: Performance metrics
        await self.check_performance()
        
        # Check 4: Configuration analysis
        await self.check_configuration()
        
        # Check 5: Key analysis
        await self.check_keys()
        
        # Check 6: Client analysis
        await self.check_clients()
        
        # Generate report
        self.generate_report()
    
    async def check_connectivity(self):
        """Test Redis connectivity"""
        print("\n1. Connectivity Check:")
        
        try:
            result = subprocess.run(
                ['redis-cli', '-h', self.redis_host, '-p', str(self.redis_port), 'ping'],
                capture_output=True, text=True, timeout=5
            )
            
            if result.returncode == 0 and 'PONG' in result.stdout:
                print("   âœ… Connection successful")
                self.results['diagnostics']['connectivity'] = {'status': 'ok', 'latency': 'normal'}
            else:
                print("   âŒ Connection failed")
                self.results['diagnostics']['connectivity'] = {'status': 'failed', 'error': result.stderr}
        except Exception as e:
            print(f"   âŒ Connection error: {e}")
            self.results['diagnostics']['connectivity'] = {'status': 'error', 'error': str(e)}
    
    async def check_memory(self):
        """Analyze Redis memory usage"""
        print("\n2. Memory Analysis:")
        
        try:
            result = subprocess.run(
                ['redis-cli', '-h', self.redis_host, '-p', str(self.redis_port), 'info', 'memory'],
                capture_output=True, text=True
            )
            
            if result.returncode == 0:
                memory_info = {}
                for line in result.stdout.split('\n'):
                    if ':' in line and not line.startswith('#'):
                        key, value = line.strip().split(':', 1)
                        memory_info[key] = value
                
                used_memory_human = memory_info.get('used_memory_human', 'unknown')
                peak_memory_human = memory_info.get('used_memory_peak_human', 'unknown')
                fragmentation_ratio = memory_info.get('mem_fragmentation_ratio', 'unknown')
                
                print(f"   Used Memory: {used_memory_human}")
                print(f"   Peak Memory: {peak_memory_human}")
                print(f"   Fragmentation Ratio: {fragmentation_ratio}")
                
                self.results['diagnostics']['memory'] = memory_info
                
        except Exception as e:
            print(f"   âŒ Memory check failed: {e}")
    
    async def check_performance(self):
        """Check Redis performance metrics"""
        print("\n3. Performance Analysis:")
        
        try:
            # Get stats
            result = subprocess.run(
                ['redis-cli', '-h', self.redis_host, '-p', str(self.redis_port), 'info', 'stats'],
                capture_output=True, text=True
            )
            
            if result.returncode == 0:
                stats = {}
                for line in result.stdout.split('\n'):
                    if ':' in line and not line.startswith('#'):
                        key, value = line.strip().split(':', 1)
                        stats[key] = value
                
                ops_per_sec = stats.get('instantaneous_ops_per_sec', '0')
                total_commands = stats.get('total_commands_processed', '0')
                keyspace_hits = int(stats.get('keyspace_hits', 0))
                keyspace_misses = int(stats.get('keyspace_misses', 0))
                
                if keyspace_hits + keyspace_misses > 0:
                    hit_rate = (keyspace_hits / (keyspace_hits + keyspace_misses)) * 100
                else:
                    hit_rate = 0
                
                print(f"   Operations/sec: {ops_per_sec}")
                print(f"   Total Commands: {total_commands}")
                print(f"   Hit Rate: {hit_rate:.2f}%")
                
                self.results['diagnostics']['performance'] = {
                    'ops_per_sec': ops_per_sec,
                    'hit_rate_percent': round(hit_rate, 2),
                    'total_commands': total_commands
                }
                
        except Exception as e:
            print(f"   âŒ Performance check failed: {e}")
    
    def generate_report(self):
        """Generate diagnostic report"""
        report_file = f"redis_diagnostics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(report_file, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"\nðŸ“Š Diagnostic report saved: {report_file}")
        
        # Print summary
        print("\n" + "=" * 50)
        print("DIAGNOSTIC SUMMARY")
        print("=" * 50)
        
        connectivity = self.results['diagnostics'].get('connectivity', {})
        if connectivity.get('status') == 'ok':
            print("âœ… Connectivity: OK")
        else:
            print("âŒ Connectivity: FAILED")
        
        memory = self.results['diagnostics'].get('memory', {})
        if memory:
            print(f"ðŸ’¾ Memory: {memory.get('used_memory_human', 'unknown')}")
        
        performance = self.results['diagnostics'].get('performance', {})
        if performance:
            print(f"ðŸš€ Hit Rate: {performance.get('hit_rate_percent', 0)}%")

async def main():
    diagnostics = RedisDiagnostics()
    await diagnostics.run_full_diagnostics()

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ðŸ“ž Escalation Procedures

### Level 1 - Service Degradation
- **Response Time**: 15 minutes
- **Actions**: Restart services, check logs, apply immediate fixes
- **Escalate If**: Issue persists after 30 minutes

### Level 2 - Service Outage
- **Response Time**: 5 minutes
- **Actions**: Emergency procedures, fallback activation, incident commander assigned
- **Escalate If**: Recovery time > 1 hour

### Level 3 - Data Loss Risk
- **Response Time**: Immediate
- **Actions**: Stop all writes, forensic backup, security team involvement
- **Escalate If**: Any data integrity concerns

---

## ðŸ“‹ Post-Incident Checklist

After resolving any Redis incident:

- [ ] Document incident timeline and root cause
- [ ] Update monitoring thresholds if needed
- [ ] Review and test backup/recovery procedures
- [ ] Check if additional alerting is needed
- [ ] Update this documentation with lessons learned
- [ ] Schedule post-mortem meeting within 48 hours
- [ ] Implement preventive measures
- [ ] Update runbooks based on findings

---

**Last Updated**: Generated by CC DevSecOps Engineer
**Document Version**: 1.0
**Review Schedule**: Monthly