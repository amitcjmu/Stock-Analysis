"""
Cached Context API Endpoints

Enhanced context endpoints with Redis caching, ETag support, and conditional requests.
These endpoints demonstrate the integration of the CacheMiddleware with real API operations.

ðŸ”’ Security: Multi-tenant isolation, secure caching, audit logging
âš¡ Performance: Redis caching, ETag support, optimized queries
ðŸŽ¯ Coherence: Cache invalidation integration, real-time updates
ðŸ“Š Analytics: Cache metrics, performance monitoring

Generated by CC (Claude Code)
"""

import hashlib
import json
import time
from datetime import datetime
from typing import Any, Dict, Optional
from uuid import UUID

from fastapi import APIRouter, Depends, HTTPException, Request, Response, status
from fastapi.responses import JSONResponse
from sqlalchemy.ext.asyncio import AsyncSession

from app.api.v1.auth.auth_utils import get_current_user
from app.constants.cache_keys import CacheKeys
from app.core.database import get_db
from app.core.logging import get_logger
from app.models import User

# from app.schemas.context import UserContext  # Unused import
from app.services.cache_invalidation import (
    CacheInvalidationService,
    get_cache_invalidation_service,
)
from app.services.caching.redis_cache import RedisCache, get_redis_cache

# Import the existing context services
from app.api.v1.endpoints.context.services.user_service import UserService
from app.api.v1.endpoints.context.services.client_service import ClientService
from app.api.v1.endpoints.context.services.engagement_service import EngagementService

logger = get_logger(__name__)

router = APIRouter(prefix="/cached-context", tags=["cached-context"])


class CachedContextService:
    """
    Service that wraps existing context services with caching capabilities.

    This service demonstrates how to integrate Redis caching with existing
    business logic while maintaining proper cache invalidation.
    """

    def __init__(
        self,
        db: AsyncSession,
        redis_cache: RedisCache,
        invalidation_service: CacheInvalidationService,
    ):
        self.db = db
        self.redis = redis_cache
        self.invalidation = invalidation_service

        # Wrap existing services
        self.user_service = UserService(db)
        self.client_service = ClientService(db)
        self.engagement_service = EngagementService(db)

    async def get_user_context_cached(
        self,
        user: User,
        client_account_id: Optional[str] = None,
        engagement_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Get user context with Redis caching.

        Args:
            user: Current user
            client_account_id: Client account for tenant isolation
            engagement_id: Optional engagement context

        Returns:
            User context dictionary with cache metadata
        """
        try:
            # Generate cache key with tenant isolation
            cache_key = CacheKeys.user_context(str(user.id))

            # Add tenant context to cache key for security
            if client_account_id:
                cache_key = f"{cache_key}:client:{client_account_id}"
            if engagement_id:
                cache_key = f"{cache_key}:engagement:{engagement_id}"

            logger.debug(f"Getting user context with cache key: {cache_key}")

            # Try to get from cache first
            cached_data = await self.redis.get(cache_key)
            if cached_data:
                logger.debug(f"Cache HIT for user context: {user.id}")

                # Add cache metadata
                return {
                    "data": cached_data,
                    "cache_metadata": {
                        "cached": True,
                        "cache_key": cache_key,
                        "retrieved_at": datetime.utcnow().isoformat(),
                    },
                }

            # Cache miss - get fresh data
            logger.debug(f"Cache MISS for user context: {user.id}")
            start_time = time.time()

            # Get fresh user context from existing service
            user_context = await self.user_service.get_user_context_with_flows(user)

            # Convert to dictionary for caching
            context_dict = {
                "user": {
                    "id": str(user_context.user.id),
                    "email": user_context.user.email,
                    "username": user_context.user.username,
                    "role": user_context.user.role,
                    "is_active": user_context.user.is_active,
                    "created_at": (
                        user_context.user.created_at.isoformat()
                        if user_context.user.created_at
                        else None
                    ),
                },
                "client": (
                    {
                        "id": str(user_context.client.id),
                        "name": user_context.client.name,
                        "created_at": (
                            user_context.client.created_at.isoformat()
                            if user_context.client.created_at
                            else None
                        ),
                    }
                    if user_context.client
                    else None
                ),
                "engagement": (
                    {
                        "id": str(user_context.engagement.id),
                        "name": user_context.engagement.name,
                        "client_id": str(user_context.engagement.client_id),
                        "created_at": (
                            user_context.engagement.created_at.isoformat()
                            if user_context.engagement.created_at
                            else None
                        ),
                    }
                    if user_context.engagement
                    else None
                ),
                "session": (
                    {
                        "id": str(user_context.session.id),
                        "engagement_id": (
                            str(user_context.session.engagement_id)
                            if user_context.session.engagement_id
                            else None
                        ),
                        "created_at": (
                            user_context.session.created_at.isoformat()
                            if user_context.session.created_at
                            else None
                        ),
                    }
                    if user_context.session
                    else None
                ),
                "active_flows": [
                    {
                        "id": str(flow.id),
                        "name": flow.name,
                        "flow_type": flow.flow_type,
                        "status": flow.status,
                        "engagement_id": (
                            str(flow.engagement_id) if flow.engagement_id else None
                        ),
                        "created_by": flow.created_by,
                        "metadata": flow.metadata or {},
                    }
                    for flow in (user_context.active_flows or [])
                ],
                "primary_flow_id": (
                    str(user_context.primary_flow_id)
                    if user_context.primary_flow_id
                    else None
                ),
            }

            # Cache the data with appropriate TTL (1 hour for user context)
            ttl = 3600
            await self.redis.set(cache_key, context_dict, ttl)

            fetch_time_ms = (time.time() - start_time) * 1000
            logger.debug(
                f"Cached user context for {user.id} (fetch: {fetch_time_ms:.2f}ms)"
            )

            return {
                "data": context_dict,
                "cache_metadata": {
                    "cached": False,
                    "cache_key": cache_key,
                    "fetch_time_ms": fetch_time_ms,
                    "cached_at": datetime.utcnow().isoformat(),
                    "ttl_seconds": ttl,
                },
            }

        except Exception as e:
            logger.error(f"Failed to get cached user context: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Error fetching user context: {str(e)}",
            )

    async def get_clients_cached(
        self, user: User, client_account_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """Get user's accessible clients with caching."""
        try:
            cache_key = CacheKeys.user_clients(str(user.id))

            # Try cache first
            cached_data = await self.redis.get(cache_key)
            if cached_data:
                return {
                    "data": cached_data,
                    "cache_metadata": {"cached": True, "cache_key": cache_key},
                }

            # Cache miss - get fresh data
            start_time = time.time()
            clients = await self.client_service.get_user_accessible_clients(user)

            # Convert to serializable format
            clients_data = [
                {
                    "id": str(client.id),
                    "name": client.name,
                    "description": client.description,
                    "is_active": client.is_active,
                    "created_at": (
                        client.created_at.isoformat() if client.created_at else None
                    ),
                }
                for client in clients
            ]

            # Cache for 30 minutes
            ttl = 1800
            await self.redis.set(cache_key, clients_data, ttl)

            fetch_time_ms = (time.time() - start_time) * 1000

            return {
                "data": clients_data,
                "cache_metadata": {
                    "cached": False,
                    "cache_key": cache_key,
                    "fetch_time_ms": fetch_time_ms,
                    "ttl_seconds": ttl,
                },
            }

        except Exception as e:
            logger.error(f"Failed to get cached clients: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Error fetching clients: {str(e)}",
            )

    async def get_engagements_cached(
        self, client_id: str, user: User
    ) -> Dict[str, Any]:
        """Get client's engagements with caching."""
        try:
            cache_key = CacheKeys.client_engagements(client_id)

            # Try cache first
            cached_data = await self.redis.get(cache_key)
            if cached_data:
                return {
                    "data": cached_data,
                    "cache_metadata": {"cached": True, "cache_key": cache_key},
                }

            # Cache miss - get fresh data
            start_time = time.time()
            engagements = await self.engagement_service.get_client_engagements(
                UUID(client_id), user
            )

            # Convert to serializable format
            engagements_data = [
                {
                    "id": str(engagement.id),
                    "name": engagement.name,
                    "description": engagement.description,
                    "client_id": str(engagement.client_id),
                    "is_active": engagement.is_active,
                    "created_at": (
                        engagement.created_at.isoformat()
                        if engagement.created_at
                        else None
                    ),
                }
                for engagement in engagements
            ]

            # Cache for 30 minutes
            ttl = 1800
            await self.redis.set(cache_key, engagements_data, ttl)

            fetch_time_ms = (time.time() - start_time) * 1000

            return {
                "data": engagements_data,
                "cache_metadata": {
                    "cached": False,
                    "cache_key": cache_key,
                    "fetch_time_ms": fetch_time_ms,
                    "ttl_seconds": ttl,
                },
            }

        except Exception as e:
            logger.error(f"Failed to get cached engagements: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Error fetching engagements: {str(e)}",
            )


# ========================================
# API ENDPOINTS WITH CACHING
# ========================================


@router.get(
    "/me",
    summary="Get cached user context",
    description="Get complete user context with Redis caching and ETag support",
    response_description="User context with cache metadata",
)
async def get_cached_user_context(
    request: Request,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
    redis_cache: RedisCache = Depends(get_redis_cache),
    invalidation_service: CacheInvalidationService = Depends(
        get_cache_invalidation_service
    ),
) -> JSONResponse:
    """
    Get complete user context with Redis caching.

    This endpoint demonstrates:
    - Redis caching with proper tenant isolation
    - ETag generation for conditional requests
    - Cache metadata in response
    - Performance monitoring
    """
    try:
        # Extract tenant context from headers for security
        client_account_id = request.headers.get("X-Client-Account-ID")
        engagement_id = request.headers.get("X-Engagement-ID")

        # Create cached service
        service = CachedContextService(db, redis_cache, invalidation_service)

        # Get cached user context
        result = await service.get_user_context_cached(
            current_user, client_account_id, engagement_id
        )

        # Generate ETag for the response data
        data_str = json.dumps(result["data"], sort_keys=True, default=str)
        etag = hashlib.sha256(data_str.encode()).hexdigest()[:32]

        # Check for conditional request
        if_none_match = request.headers.get("If-None-Match")
        if if_none_match and if_none_match.strip('"') == etag:
            return Response(status_code=status.HTTP_304_NOT_MODIFIED)

        # Determine cache control based on whether data was cached
        if result["cache_metadata"]["cached"]:
            cache_control = "private, max-age=300"  # 5 minutes for cached data
            cache_status = "HIT"
        else:
            cache_control = "private, max-age=3600"  # 1 hour for fresh data
            cache_status = "MISS"

        # Create response with appropriate headers
        response = JSONResponse(
            content={
                "user_context": result["data"],
                "cache_metadata": result["cache_metadata"],
            }
        )

        response.headers["ETag"] = f'"{etag}"'
        response.headers["Cache-Control"] = cache_control
        response.headers["X-Cache"] = cache_status
        response.headers["Vary"] = "X-Client-Account-ID, X-Engagement-ID"

        if not result["cache_metadata"]["cached"]:
            response.headers["X-Fetch-Time"] = (
                f"{result['cache_metadata'].get('fetch_time_ms', 0):.2f}ms"
            )

        return response

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get cached user context: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error fetching user context: {str(e)}",
        )


@router.get(
    "/clients",
    summary="Get cached user clients",
    description="Get user's accessible clients with Redis caching",
)
async def get_cached_clients(
    request: Request,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
    redis_cache: RedisCache = Depends(get_redis_cache),
    invalidation_service: CacheInvalidationService = Depends(
        get_cache_invalidation_service
    ),
) -> JSONResponse:
    """Get user's accessible clients with caching."""
    try:
        client_account_id = request.headers.get("X-Client-Account-ID")

        service = CachedContextService(db, redis_cache, invalidation_service)
        result = await service.get_clients_cached(current_user, client_account_id)

        # Generate ETag
        data_str = json.dumps(result["data"], sort_keys=True, default=str)
        etag = hashlib.sha256(data_str.encode()).hexdigest()[:32]

        # Check conditional request
        if_none_match = request.headers.get("If-None-Match")
        if if_none_match and if_none_match.strip('"') == etag:
            return Response(status_code=status.HTTP_304_NOT_MODIFIED)

        # Create response
        response = JSONResponse(
            content={
                "clients": result["data"],
                "cache_metadata": result["cache_metadata"],
            }
        )

        response.headers["ETag"] = f'"{etag}"'
        response.headers["Cache-Control"] = "private, max-age=1800"  # 30 minutes
        response.headers["X-Cache"] = (
            "HIT" if result["cache_metadata"]["cached"] else "MISS"
        )

        return response

    except Exception as e:
        logger.error(f"Failed to get cached clients: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error fetching clients: {str(e)}",
        )


@router.get(
    "/engagements",
    summary="Get cached client engagements",
    description="Get client's engagements with Redis caching",
)
async def get_cached_engagements(
    client_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user),
    redis_cache: RedisCache = Depends(get_redis_cache),
    invalidation_service: CacheInvalidationService = Depends(
        get_cache_invalidation_service
    ),
) -> JSONResponse:
    """Get client's engagements with caching."""
    try:
        service = CachedContextService(db, redis_cache, invalidation_service)
        result = await service.get_engagements_cached(client_id, current_user)

        # Generate ETag
        data_str = json.dumps(result["data"], sort_keys=True, default=str)
        etag = hashlib.sha256(data_str.encode()).hexdigest()[:32]

        # Check conditional request
        if_none_match = request.headers.get("If-None-Match")
        if if_none_match and if_none_match.strip('"') == etag:
            return Response(status_code=status.HTTP_304_NOT_MODIFIED)

        # Create response
        response = JSONResponse(
            content={
                "engagements": result["data"],
                "cache_metadata": result["cache_metadata"],
            }
        )

        response.headers["ETag"] = f'"{etag}"'
        response.headers["Cache-Control"] = "private, max-age=1800"  # 30 minutes
        response.headers["X-Cache"] = (
            "HIT" if result["cache_metadata"]["cached"] else "MISS"
        )

        return response

    except Exception as e:
        logger.error(f"Failed to get cached engagements: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error fetching engagements: {str(e)}",
        )


@router.post(
    "/invalidate/user/{user_id}",
    summary="Invalidate user context cache",
    description="Manually invalidate user context cache for testing/admin purposes",
)
async def invalidate_user_context(
    user_id: str,
    request: Request,
    invalidation_service: CacheInvalidationService = Depends(
        get_cache_invalidation_service
    ),
    current_user: User = Depends(get_current_user),
) -> Dict[str, Any]:
    """Manually invalidate user context cache."""
    try:
        client_account_id = request.headers.get("X-Client-Account-ID")
        if not client_account_id:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="X-Client-Account-ID header is required",
            )

        # Invalidate user context
        count = await invalidation_service.on_user_updated(
            user_id,
            client_account_id,
            reason=f"Manual invalidation by user {current_user.id}",
            broadcast_event=True,
        )

        return {
            "success": True,
            "invalidated_keys": count,
            "message": f"Invalidated {count} cache keys for user {user_id}",
        }

    except Exception as e:
        logger.error(f"Failed to invalidate user context: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error invalidating cache: {str(e)}",
        )


@router.get(
    "/stats",
    summary="Get cache statistics",
    description="Get caching statistics and performance metrics",
)
async def get_cache_stats(
    redis_cache: RedisCache = Depends(get_redis_cache),
    invalidation_service: CacheInvalidationService = Depends(
        get_cache_invalidation_service
    ),
) -> Dict[str, Any]:
    """Get cache statistics and metrics."""
    try:
        # Get Redis cache stats (if available)
        redis_stats = {}
        if hasattr(redis_cache, "get_stats"):
            redis_stats = redis_cache.get_stats()

        # Get invalidation service stats
        invalidation_stats = invalidation_service.get_stats()

        return {
            "redis_cache": redis_stats,
            "invalidation_service": invalidation_stats,
            "timestamp": datetime.utcnow().isoformat(),
        }

    except Exception as e:
        logger.error(f"Failed to get cache stats: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error fetching cache stats: {str(e)}",
        )


__all__ = ["router", "CachedContextService"]
