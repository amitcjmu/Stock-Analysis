"""
Cache Key Utility Generators

This module contains utility functions for cache key manipulation, pattern matching,
hash generation, and TTL recommendations.

Generated by CC (Claude Code)
"""

import hashlib
from typing import List, Optional

from .base import (
    CACHE_VERSION,
    CASCADE_RELATIONSHIPS,
    CACHE_TYPE_PATTERNS,
    CacheKeyType,
)


class CacheKeyGenerators:
    """
    Utility functions for cache key generation, pattern matching, and manipulation.
    """

    @staticmethod
    def generate_pattern_key(pattern: str, **kwargs) -> str:
        """
        Generate cache keys from patterns with variable substitution.

        Args:
            pattern: Pattern with {variable} placeholders
            **kwargs: Variable values for substitution

        Returns:
            Formatted cache key with version prefix
        """
        formatted_pattern = pattern.format(**kwargs)
        if not formatted_pattern.startswith(CACHE_VERSION):
            return f"{CACHE_VERSION}:{formatted_pattern}"
        return formatted_pattern

    @staticmethod
    def get_cascade_patterns(primary_key: str) -> List[str]:
        """
        Get all cache key patterns that should be invalidated when primary_key changes.

        This supports the cascade invalidation logic in CacheCoherenceManager.

        Args:
            primary_key: The primary cache key that changed

        Returns:
            List of wildcard patterns for related keys to invalidate
        """
        patterns = []

        # Remove version prefix to match against patterns
        key_without_version = primary_key
        if primary_key.startswith(CACHE_VERSION + ":"):
            key_without_version = primary_key[len(CACHE_VERSION) + 1 :]

        # Extract entity values from the key
        parts = key_without_version.split(":")
        extracted_values = {}

        # Common entity extractions
        if "user:" in key_without_version:
            idx = parts.index("user") if "user" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["user_id"] = parts[idx + 1]

        if "client:" in key_without_version:
            idx = parts.index("client") if "client" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["client_id"] = parts[idx + 1]

        if "engagement:" in key_without_version:
            idx = parts.index("engagement") if "engagement" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["engagement_id"] = parts[idx + 1]

        if "flow:" in key_without_version:
            idx = parts.index("flow") if "flow" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["flow_id"] = parts[idx + 1]

        if "import:" in key_without_version:
            idx = parts.index("import") if "import" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["import_id"] = parts[idx + 1]

        if "asset:" in key_without_version:
            idx = parts.index("asset") if "asset" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["asset_id"] = parts[idx + 1]

        # Check each cascade relationship pattern
        for pattern_template, invalidation_patterns in CASCADE_RELATIONSHIPS.items():
            # Check if the key matches this pattern
            pattern_matches = True
            for part in pattern_template.split(":"):
                if part.startswith("{") and part.endswith("}"):
                    # This is a placeholder - check if we have the value
                    var_name = part[1:-1]
                    if var_name not in extracted_values:
                        pattern_matches = False
                        break
                elif part != "*" and part not in key_without_version:
                    pattern_matches = False
                    break

            if pattern_matches:
                # Generate invalidation patterns with substituted values
                for inv_pattern in invalidation_patterns:
                    final_pattern = inv_pattern
                    for var_name, var_value in extracted_values.items():
                        final_pattern = final_pattern.replace(
                            f"{{{var_name}}}", var_value
                        )
                    patterns.append(f"{CACHE_VERSION}:{final_pattern}")

        return list(set(patterns))  # Remove duplicates

    @staticmethod
    def get_cache_type(cache_key: str) -> Optional[CacheKeyType]:
        """
        Determine the cache type from a cache key for monitoring and metrics.

        Args:
            cache_key: The cache key to analyze

        Returns:
            CacheKeyType enum value or None if not recognized
        """
        # Remove version prefix for pattern matching
        key_without_version = cache_key
        if cache_key.startswith(CACHE_VERSION + ":"):
            key_without_version = cache_key[len(CACHE_VERSION) + 1 :]

        # Check each pattern in order of specificity
        for pattern, cache_type in CACHE_TYPE_PATTERNS.items():
            # Convert pattern to regex-like matching
            pattern_parts = pattern.split(":")
            key_parts = key_without_version.split(":")

            if len(pattern_parts) > len(key_parts):
                continue

            matches = True
            for i, pattern_part in enumerate(pattern_parts):
                if pattern_part == "*":
                    continue  # Wildcard matches anything
                elif i < len(key_parts) and pattern_part != key_parts[i]:
                    matches = False
                    break

            if matches:
                return cache_type

        return None

    @staticmethod
    def create_hash_key(base_key: str, data: str) -> str:
        """
        Create a hash-based cache key for large or complex data.
        Useful for caching query results with complex parameters.

        Args:
            base_key: Base cache key prefix
            data: Data to hash for uniqueness

        Returns:
            Cache key with hash suffix
        """
        data_hash = hashlib.sha256(data.encode()).hexdigest()[:16]
        return f"{base_key}:hash:{data_hash}"

    @staticmethod
    def get_ttl_recommendation(cache_key: str) -> int:
        """
        Get recommended TTL (in seconds) based on cache key type.

        Args:
            cache_key: The cache key to analyze

        Returns:
            Recommended TTL in seconds
        """
        # Import here to avoid circular dependency
        from .validators import AgentCacheStrategy

        # Check if this is an agent result key
        if ":agent:" in cache_key:
            # Extract agent name from key
            parts = cache_key.split(":")
            agent_idx = parts.index("agent") if "agent" in parts else -1
            if agent_idx >= 0 and agent_idx + 1 < len(parts):
                agent_name = parts[agent_idx + 1]
                # Use AgentCacheStrategy for agent-specific TTL
                return AgentCacheStrategy.get_agent_ttl(agent_name)

        # Otherwise use cache type
        cache_type = CacheKeyGenerators.get_cache_type(cache_key)

        ttl_map = {
            CacheKeyType.USER_CONTEXT: 3600,  # 1 hour
            CacheKeyType.FIELD_MAPPINGS: 120,  # 2 minutes
            CacheKeyType.FLOW_STATE: 300,  # 5 minutes
            CacheKeyType.CLIENT_DATA: 1800,  # 30 minutes
            CacheKeyType.ENGAGEMENT_DATA: 1800,  # 30 minutes
            CacheKeyType.ASSET_DATA: 900,  # 15 minutes
            CacheKeyType.IMPORT_DATA: 300,  # 5 minutes
            CacheKeyType.ADMIN_DATA: 300,  # 5 minutes
            CacheKeyType.AGENT_RESULTS: 1800,  # 30 minutes (default for unknown agents)
            CacheKeyType.AGENT_CONFIG: 3600,  # 1 hour (sensitive, encrypted)
            CacheKeyType.CREWAI_STATE: 300,  # 5 minutes (sensitive, encrypted)
            CacheKeyType.AGENT_TOOLS: 1800,  # 30 minutes (sensitive, encrypted)
            CacheKeyType.FLOW_CHECKPOINTS: 7200,  # 2 hours (expensive to regenerate)
            CacheKeyType.STATS: 1800,  # 30 minutes
        }

        return ttl_map.get(cache_type, 600)  # Default 10 min

    @staticmethod
    def agent_result_with_ttl(
        agent_id: str,
        agent_name: str,
        flow_id: str,
        client_account_id: str,
        engagement_id: str,
    ) -> tuple[str, int]:
        """
        Generate agent result cache key with recommended TTL.

        Returns:
            Tuple of (cache_key, ttl_seconds)
        """
        from .patterns import CacheKeys
        from .validators import AgentCacheStrategy

        key = CacheKeys.agent_result(
            agent_id, agent_name, flow_id, client_account_id, engagement_id
        )
        ttl = AgentCacheStrategy.get_agent_ttl(agent_name)
        return key, ttl
