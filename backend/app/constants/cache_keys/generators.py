"""
Cache Key Utility Generators

This module contains utility functions for cache key manipulation, pattern matching,
hash generation, and TTL recommendations.

Generated by CC (Claude Code)
"""

import hashlib
from typing import List, Optional

from .base import (
    CACHE_VERSION,
    CASCADE_RELATIONSHIPS,
    CACHE_TYPE_PATTERNS,
    CacheKeyType,
)


class CacheKeyGenerators:
    """
    Utility functions for cache key generation, pattern matching, and manipulation.
    """

    @staticmethod
    def generate_pattern_key(pattern: str, **kwargs) -> str:
        """
        Generate cache keys from patterns with variable substitution.

        Args:
            pattern: Pattern with {variable} placeholders
            **kwargs: Variable values for substitution

        Returns:
            Formatted cache key with version prefix
        """
        formatted_pattern = pattern.format(**kwargs)
        if not formatted_pattern.startswith(CACHE_VERSION):
            return f"{CACHE_VERSION}:{formatted_pattern}"
        return formatted_pattern

    @staticmethod
    def _extract_key_without_version(primary_key: str) -> str:
        """Remove version prefix from cache key."""
        if primary_key.startswith(CACHE_VERSION + ":"):
            return primary_key[len(CACHE_VERSION) + 1 :]
        return primary_key

    @staticmethod
    def _extract_entity_values(key_without_version: str) -> dict:
        """Extract entity values from cache key parts."""
        parts = key_without_version.split(":")
        extracted_values = {}

        # Entity mapping for extraction
        entity_mappings = {
            "user": "user_id",
            "client": "client_id",
            "engagement": "engagement_id",
            "flow": "flow_id",
            "import": "import_id",
            "asset": "asset_id",
        }

        for entity_name, value_key in entity_mappings.items():
            entity_key = f"{entity_name}:"
            if entity_key in key_without_version:
                idx = parts.index(entity_name) if entity_name in parts else -1
                if idx >= 0 and idx + 1 < len(parts):
                    extracted_values[value_key] = parts[idx + 1]

        return extracted_values

    @staticmethod
    def _pattern_matches_key(
        pattern_template: str, key_without_version: str, extracted_values: dict
    ) -> bool:
        """Check if a pattern template matches the cache key."""
        for part in pattern_template.split(":"):
            if part.startswith("{") and part.endswith("}"):
                # This is a placeholder - check if we have the value
                var_name = part[1:-1]
                if var_name not in extracted_values:
                    return False
            elif part != "*" and part not in key_without_version:
                return False
        return True

    @staticmethod
    def _generate_invalidation_patterns(
        invalidation_patterns: List[str], extracted_values: dict
    ) -> List[str]:
        """Generate invalidation patterns with substituted values."""
        patterns = []
        for inv_pattern in invalidation_patterns:
            final_pattern = inv_pattern
            for var_name, var_value in extracted_values.items():
                final_pattern = final_pattern.replace(f"{{{var_name}}}", var_value)
            patterns.append(f"{CACHE_VERSION}:{final_pattern}")
        return patterns

    @staticmethod
    def get_cascade_patterns(primary_key: str) -> List[str]:
        """
        Get all cache key patterns that should be invalidated when primary_key changes.

        This supports the cascade invalidation logic in CacheCoherenceManager.

        Args:
            primary_key: The primary cache key that changed

        Returns:
            List of wildcard patterns for related keys to invalidate
        """
        patterns = []

        # Remove version prefix to match against patterns
        key_without_version = CacheKeyGenerators._extract_key_without_version(
            primary_key
        )

        # Extract entity values from the key
        extracted_values = CacheKeyGenerators._extract_entity_values(
            key_without_version
        )

        # Check each cascade relationship pattern
        for pattern_template, invalidation_patterns in CASCADE_RELATIONSHIPS.items():
            # Check if the key matches this pattern
            if CacheKeyGenerators._pattern_matches_key(
                pattern_template, key_without_version, extracted_values
            ):
                # Generate invalidation patterns with substituted values
                generated_patterns = CacheKeyGenerators._generate_invalidation_patterns(
                    invalidation_patterns, extracted_values
                )
                patterns.extend(generated_patterns)

        return list(set(patterns))  # Remove duplicates

    @staticmethod
    def get_cache_type(cache_key: str) -> Optional[CacheKeyType]:
        """
        Determine the cache type from a cache key for monitoring and metrics.

        Args:
            cache_key: The cache key to analyze

        Returns:
            CacheKeyType enum value or None if not recognized
        """
        # Remove version prefix for pattern matching
        key_without_version = cache_key
        if cache_key.startswith(CACHE_VERSION + ":"):
            key_without_version = cache_key[len(CACHE_VERSION) + 1 :]

        # Check each pattern in order of specificity
        for pattern, cache_type in CACHE_TYPE_PATTERNS.items():
            # Convert pattern to regex-like matching
            pattern_parts = pattern.split(":")
            key_parts = key_without_version.split(":")

            if len(pattern_parts) > len(key_parts):
                continue

            matches = True
            for i, pattern_part in enumerate(pattern_parts):
                if pattern_part == "*":
                    continue  # Wildcard matches anything
                elif i < len(key_parts) and pattern_part != key_parts[i]:
                    matches = False
                    break

            if matches:
                return cache_type

        return None

    @staticmethod
    def create_hash_key(base_key: str, data: str) -> str:
        """
        Create a hash-based cache key for large or complex data.
        Useful for caching query results with complex parameters.

        Args:
            base_key: Base cache key prefix
            data: Data to hash for uniqueness

        Returns:
            Cache key with hash suffix
        """
        data_hash = hashlib.sha256(data.encode()).hexdigest()[:16]
        return f"{base_key}:hash:{data_hash}"

    @staticmethod
    def get_ttl_recommendation(cache_key: str) -> int:
        """
        Get recommended TTL (in seconds) based on cache key type.

        Args:
            cache_key: The cache key to analyze

        Returns:
            Recommended TTL in seconds
        """
        # Import here to avoid circular dependency
        from .validators import AgentCacheStrategy

        # Check if this is an agent result key
        if ":agent:" in cache_key:
            # Extract agent name from key
            parts = cache_key.split(":")
            agent_idx = parts.index("agent") if "agent" in parts else -1
            if agent_idx >= 0 and agent_idx + 1 < len(parts):
                agent_name = parts[agent_idx + 1]
                # Use AgentCacheStrategy for agent-specific TTL
                return AgentCacheStrategy.get_agent_ttl(agent_name)

        # Otherwise use cache type
        cache_type = CacheKeyGenerators.get_cache_type(cache_key)

        ttl_map = {
            CacheKeyType.USER_CONTEXT: 3600,  # 1 hour
            CacheKeyType.FIELD_MAPPINGS: 120,  # 2 minutes
            CacheKeyType.FLOW_STATE: 300,  # 5 minutes
            CacheKeyType.CLIENT_DATA: 1800,  # 30 minutes
            CacheKeyType.ENGAGEMENT_DATA: 1800,  # 30 minutes
            CacheKeyType.ASSET_DATA: 900,  # 15 minutes
            CacheKeyType.IMPORT_DATA: 300,  # 5 minutes
            CacheKeyType.ADMIN_DATA: 300,  # 5 minutes
            CacheKeyType.AGENT_RESULTS: 1800,  # 30 minutes (default for unknown agents)
            CacheKeyType.AGENT_CONFIG: 3600,  # 1 hour (sensitive, encrypted)
            CacheKeyType.CREWAI_STATE: 300,  # 5 minutes (sensitive, encrypted)
            CacheKeyType.AGENT_TOOLS: 1800,  # 30 minutes (sensitive, encrypted)
            CacheKeyType.FLOW_CHECKPOINTS: 7200,  # 2 hours (expensive to regenerate)
            CacheKeyType.STATS: 1800,  # 30 minutes
        }

        return ttl_map.get(cache_type, 600)  # Default 10 min

    @staticmethod
    def agent_result_with_ttl(
        agent_id: str,
        agent_name: str,
        flow_id: str,
        client_account_id: str,
        engagement_id: str,
    ) -> tuple[str, int]:
        """
        Generate agent result cache key with recommended TTL.

        Returns:
            Tuple of (cache_key, ttl_seconds)
        """
        from .patterns import CacheKeys
        from .validators import AgentCacheStrategy

        key = CacheKeys.agent_result(
            agent_id, agent_name, flow_id, client_account_id, engagement_id
        )
        ttl = AgentCacheStrategy.get_agent_ttl(agent_name)
        return key, ttl
