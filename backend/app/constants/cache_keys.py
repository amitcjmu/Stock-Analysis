"""
Cache Key Strategy for AI Force Migration Platform

This module provides a centralized, versioned cache key generation system with
multi-tenant isolation and coherence support. All cache keys include tenant context
and support cascade invalidation patterns.

ğŸ”’ Security: All keys include tenant isolation via client_account_id
âš¡ Performance: Optimized key structure for Redis memory efficiency
ğŸ¯ Coherence: Designed for cascade invalidation patterns
ğŸ“Š Analytics: Built-in cache metrics and monitoring support

Generated by CC (Claude Code)
"""

from typing import Optional, List, Dict, Set
from enum import Enum
import hashlib


# Cache version for schema evolution and invalidation
CACHE_VERSION = "v1"


class CacheKeyType(Enum):
    """
    Enum for different cache key types to support monitoring and metrics.
    """

    USER_CONTEXT = "user_context"
    FIELD_MAPPINGS = "field_mappings"
    FLOW_STATE = "flow_state"
    CLIENT_DATA = "client_data"
    ENGAGEMENT_DATA = "engagement_data"
    ASSET_DATA = "asset_data"
    IMPORT_DATA = "import_data"
    ADMIN_DATA = "admin_data"
    AGENT_RESULTS = "agent_results"
    AGENT_CONFIG = "agent_config"
    CREWAI_STATE = "crewai_state"
    AGENT_TOOLS = "agent_tools"
    FLOW_CHECKPOINTS = "flow_checkpoints"
    STATS = "stats"


# Structured cascade invalidation relationships
CASCADE_RELATIONSHIPS: Dict[str, Set[str]] = {
    # When user context changes, invalidate these patterns
    "user:{user_id}:context": {
        "user:{user_id}:*",
        "*:user:{user_id}:*",
        "admin:active_users",
        "admin:pending_approvals",
    },
    # When client data changes, invalidate these patterns
    "client:{client_id}": {
        "client:{client_id}:*",
        "*:client:{client_id}:*",
        "user:*:clients",
    },
    # When engagement changes, invalidate these patterns
    "engagement:{engagement_id}": {
        "*:engagement:{engagement_id}:*",
        "client:{client_id}:engagements",
        "user:*:client:{client_id}:engagement:{engagement_id}:*",
    },
    # When flow changes, invalidate these patterns
    "flow:{flow_id}": {
        "*:flow:{flow_id}:*",
        "*:engagement:{engagement_id}:flows",
        "user:*:*:active_flows",
    },
    # When field mappings change, invalidate these patterns
    "field_mappings:{import_id}": {
        "*:import:{import_id}:*",
        "field_mapping_stats:{import_id}",
        "field_mapping_suggestions:{import_id}",
    },
    # When assets change, invalidate these patterns
    "asset:{asset_id}": {
        "*:asset:{asset_id}:*",
        "asset_inventory:*",
        "asset_dependencies:{asset_id}",
        "asset_recommendations:{asset_id}",
    },
}

# Cache type mapping for simplified type detection
CACHE_TYPE_PATTERNS: Dict[str, CacheKeyType] = {
    "user:*:context": CacheKeyType.USER_CONTEXT,
    "field_mappings:*": CacheKeyType.FIELD_MAPPINGS,
    "flow:*": CacheKeyType.FLOW_STATE,
    "client:*:engagements": CacheKeyType.CLIENT_DATA,
    "client:*:users": CacheKeyType.CLIENT_DATA,
    "client:*:settings": CacheKeyType.CLIENT_DATA,
    "engagement:*": CacheKeyType.ENGAGEMENT_DATA,
    "asset:*": CacheKeyType.ASSET_DATA,
    "import:*": CacheKeyType.IMPORT_DATA,
    "admin:*": CacheKeyType.ADMIN_DATA,
    "agent:*:results": CacheKeyType.AGENT_RESULTS,
    "agent:*:config": CacheKeyType.AGENT_CONFIG,
    "agent:*:tools": CacheKeyType.AGENT_TOOLS,
    "crewai:*:state": CacheKeyType.CREWAI_STATE,
    "crewai:*:checkpoint": CacheKeyType.FLOW_CHECKPOINTS,
    "crew:*:state": CacheKeyType.CREWAI_STATE,
    "stats:*": CacheKeyType.STATS,
    "analytics:*": CacheKeyType.STATS,
}


class CacheKeys:
    """
    Centralized cache key generation with versioning, tenant isolation, and coherence support.

    Design Principles:
    - All keys include CACHE_VERSION for schema evolution
    - Multi-tenant isolation via client_account_id where applicable
    - Hierarchical structure for cascade invalidation
    - Consistent naming patterns for monitoring
    - Memory-efficient key lengths
    """

    # ========================================
    # USER CONTEXT CACHING
    # ========================================

    @staticmethod
    def user_context(user_id: str) -> str:
        """
        Cache key for complete user context (client, engagement, permissions).
        TTL: 1 hour (context rarely changes)
        Invalidation: on user role changes, client/engagement assignments
        """
        return f"{CACHE_VERSION}:user:context:{user_id}"

    @staticmethod
    def user_clients(user_id: str) -> str:
        """
        Cache key for user's accessible client accounts.
        TTL: 30 minutes
        Invalidation: on user-client association changes
        """
        return f"{CACHE_VERSION}:user:{user_id}:clients"

    @staticmethod
    def user_engagements(user_id: str, client_id: str) -> str:
        """
        Cache key for user's accessible engagements within a client.
        TTL: 30 minutes
        Invalidation: on engagement creation/deletion, user permissions
        """
        return f"{CACHE_VERSION}:user:{user_id}:client:{client_id}:engagements"

    @staticmethod
    def user_active_flows(user_id: str, client_id: str, engagement_id: str) -> str:
        """
        Cache key for user's active flows in an engagement.
        TTL: 5 minutes (flows change frequently)
        Invalidation: on flow state changes
        """
        return f"{CACHE_VERSION}:user:{user_id}:client:{client_id}:engagement:{engagement_id}:active_flows"

    @staticmethod
    def user_defaults(user_id: str) -> str:
        """
        Cache key for user's default client/engagement settings.
        TTL: 2 hours
        Invalidation: on user defaults update
        """
        return f"{CACHE_VERSION}:user:{user_id}:defaults"

    # ========================================
    # FIELD MAPPING CACHING
    # ========================================

    @staticmethod
    def field_mappings(import_id: str, client_id: str) -> str:
        """
        Cache key for field mappings of a data import.
        TTL: 2 minutes (changes during review process)
        Invalidation: on mapping approval/rejection, bulk operations
        """
        return f"{CACHE_VERSION}:client:{client_id}:field_mappings:{import_id}"

    @staticmethod
    def field_mapping_stats(import_id: str, client_id: str) -> str:
        """
        Cache key for field mapping statistics (approved/pending/rejected counts).
        TTL: 1 minute
        Invalidation: on any mapping status change
        """
        return f"{CACHE_VERSION}:client:{client_id}:mapping_stats:{import_id}"

    @staticmethod
    def field_mapping_suggestions(import_id: str, client_id: str) -> str:
        """
        Cache key for AI-generated field mapping suggestions.
        TTL: 1 hour (expensive to regenerate)
        Invalidation: on schema changes, manual mapping updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:mapping_suggestions:{import_id}"

    # ========================================
    # FLOW STATE CACHING
    # ========================================

    @staticmethod
    def flow_complete(flow_id: str, client_id: str, engagement_id: str) -> str:
        """
        Cache key for complete flow data with all relations.
        TTL: 5 minutes
        Invalidation: on flow state changes, phase transitions
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:flow:complete:{flow_id}"

    @staticmethod
    def flow_metadata(flow_id: str, client_id: str, engagement_id: str) -> str:
        """
        Cache key for flow metadata (status, phase, progress).
        TTL: 2 minutes
        Invalidation: on any flow updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:flow:metadata:{flow_id}"

    @staticmethod
    def flow_agent_results(flow_id: str, agent_type: str, client_id: str) -> str:
        """
        Cache key for agent execution results within a flow.
        TTL: varies by agent type (see AgentCacheStrategy)
        Invalidation: on agent re-execution, flow reset
        """
        return f"{CACHE_VERSION}:client:{client_id}:agent:{agent_type}:flow:{flow_id}:results"

    @staticmethod
    def flow_phase_data(
        flow_id: str, phase: str, client_id: str, engagement_id: str
    ) -> str:
        """
        Cache key for phase-specific data within a flow.
        TTL: 10 minutes
        Invalidation: on phase completion, data updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:flow:{flow_id}:phase:{phase}"

    # ========================================
    # CLIENT AND ENGAGEMENT CACHING
    # ========================================

    @staticmethod
    def client_engagements(client_id: str) -> str:
        """
        Cache key for all engagements within a client account.
        TTL: 30 minutes
        Invalidation: on engagement creation/deletion/updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagements"

    @staticmethod
    def client_users(client_id: str) -> str:
        """
        Cache key for all users with access to a client account.
        TTL: 15 minutes
        Invalidation: on user association changes
        """
        return f"{CACHE_VERSION}:client:{client_id}:users"

    @staticmethod
    def client_flows(client_id: str, engagement_id: str) -> str:
        """
        Cache key for all flows within an engagement.
        TTL: 10 minutes
        Invalidation: on flow creation/deletion
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:flows"

    @staticmethod
    def client_settings(client_id: str) -> str:
        """
        Cache key for client account settings and preferences.
        TTL: 1 hour
        Invalidation: on settings updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:settings"

    # ========================================
    # DATA IMPORT CACHING
    # ========================================

    @staticmethod
    def import_metadata(import_id: str, client_id: str, engagement_id: str) -> str:
        """
        Cache key for data import metadata and status.
        TTL: 5 minutes
        Invalidation: on import status changes
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:import:{import_id}:metadata"

    @staticmethod
    def import_validation_results(import_id: str, client_id: str) -> str:
        """
        Cache key for data import validation results.
        TTL: 30 minutes (expensive to regenerate)
        Invalidation: on data changes, re-validation
        """
        return f"{CACHE_VERSION}:client:{client_id}:import:{import_id}:validation"

    @staticmethod
    def import_schema(import_id: str, client_id: str) -> str:
        """
        Cache key for detected import data schema.
        TTL: 1 hour (rarely changes after detection)
        Invalidation: on schema re-detection
        """
        return f"{CACHE_VERSION}:client:{client_id}:import:{import_id}:schema"

    # ========================================
    # ASSET INVENTORY CACHING
    # ========================================

    @staticmethod
    def asset_inventory(client_id: str, engagement_id: str) -> str:
        """
        Cache key for complete asset inventory within an engagement.
        TTL: 15 minutes
        Invalidation: on asset creation/updates/deletion
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:assets"

    @staticmethod
    def asset_dependencies(asset_id: str, client_id: str, engagement_id: str) -> str:
        """
        Cache key for asset dependency relationships.
        TTL: 30 minutes
        Invalidation: on dependency analysis updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:asset:{asset_id}:dependencies"

    @staticmethod
    def asset_recommendations(asset_id: str, client_id: str, engagement_id: str) -> str:
        """
        Cache key for SIXR recommendations for an asset.
        TTL: 4 hours (expensive analysis)
        Invalidation: on asset updates, new analysis
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:asset:{asset_id}:recommendations"

    # ========================================
    # ADMIN AND ANALYTICS CACHING
    # ========================================

    @staticmethod
    def admin_active_users() -> str:
        """
        Cache key for admin view of all active users across platform.
        TTL: 5 minutes
        Invalidation: on user status changes
        """
        return f"{CACHE_VERSION}:admin:active_users"

    @staticmethod
    def admin_pending_approvals() -> str:
        """
        Cache key for admin view of pending user/client approvals.
        TTL: 2 minutes
        Invalidation: on approval status changes
        """
        return f"{CACHE_VERSION}:admin:pending_approvals"

    @staticmethod
    def client_analytics(client_id: str, metric: str, period: str) -> str:
        """
        Cache key for client analytics and metrics.
        TTL: 30 minutes for hourly, 6 hours for daily
        Invalidation: on metric recalculation
        """
        return f"{CACHE_VERSION}:client:{client_id}:analytics:{metric}:{period}"

    @staticmethod
    def platform_stats(metric: str, period: str) -> str:
        """
        Cache key for platform-wide statistics.
        TTL: 1 hour
        Invalidation: on stats recalculation
        """
        return f"{CACHE_VERSION}:platform:stats:{metric}:{period}"

    # ========================================
    # AGENT EXECUTION CACHING
    # ========================================

    @staticmethod
    def agent_analysis_results(agent_type: str, entity_id: str, client_id: str) -> str:
        """
        Cache key for agent analysis results on entities.
        TTL: varies by agent type and data volatility
        Invalidation: on entity changes, re-analysis
        """
        return f"{CACHE_VERSION}:client:{client_id}:agent:{agent_type}:analysis:{entity_id}"

    @staticmethod
    def agent_learning_patterns(agent_type: str, client_id: str) -> str:
        """
        Cache key for agent learning patterns specific to a client.
        TTL: 24 hours
        Invalidation: on learning model updates
        """
        return (
            f"{CACHE_VERSION}:client:{client_id}:agent:{agent_type}:learning_patterns"
        )

    @staticmethod
    def crew_execution_state(crew_id: str, flow_id: str, client_id: str) -> str:
        """
        Cache key for CrewAI execution state and progress.
        TTL: 1 minute (highly dynamic)
        Invalidation: on crew state changes
        """
        return f"{CACHE_VERSION}:client:{client_id}:crew:{crew_id}:flow:{flow_id}:state"

    # ========================================
    # CREWAI SECURITY-SENSITIVE CACHING
    # ========================================

    @staticmethod
    def agent_configuration(
        agent_id: str, agent_type: str, client_id: str
    ) -> str:
        """
        Cache key for agent configuration (REQUIRES ENCRYPTION).
        Contains sensitive tool configurations and API keys.
        TTL: 1 hour
        Invalidation: on agent config updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:agent:{agent_type}:config:{agent_id}"

    @staticmethod
    def agent_tool_config(
        agent_id: str, tool_name: str, client_id: str
    ) -> str:
        """
        Cache key for agent tool configuration (REQUIRES ENCRYPTION).
        Contains API keys, credentials, and sensitive parameters.
        TTL: 30 minutes
        Invalidation: on tool config updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:agent:{agent_id}:tool:{tool_name}:config"

    @staticmethod
    def flow_checkpoint(
        flow_id: str, checkpoint_id: str, client_id: str, engagement_id: str
    ) -> str:
        """
        Cache key for flow checkpoints (REQUIRES ENCRYPTION).
        TTL: 2 hours, Invalidation: on checkpoint updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:flow:{flow_id}:checkpoint:{checkpoint_id}"

    @staticmethod
    def agent_memory_context(
        agent_id: str, context_key: str, client_id: str
    ) -> str:
        """
        Cache key for agent memory and context (REQUIRES ENCRYPTION).
        Contains learned patterns and sensitive analysis data.
        TTL: 4 hours
        Invalidation: on memory updates
        """
        return f"{CACHE_VERSION}:client:{client_id}:agent:{agent_id}:memory:{context_key}"

    @staticmethod
    def crewai_flow_state(
        flow_id: str, phase: str, client_id: str, engagement_id: str
    ) -> str:
        """
        Cache key for complete CrewAI flow state (REQUIRES ENCRYPTION).
        Contains all flow data including sensitive tenant information.
        TTL: 5 minutes
        Invalidation: on flow state changes
        """
        return f"{CACHE_VERSION}:client:{client_id}:engagement:{engagement_id}:crewai:flow:{flow_id}:state:{phase}"

    # ========================================
    # CACHE PATTERN UTILITIES
    # ========================================

    @staticmethod
    def generate_pattern_key(pattern: str, **kwargs) -> str:
        """
        Generate cache keys from patterns with variable substitution.

        Args:
            pattern: Pattern with {variable} placeholders
            **kwargs: Variable values for substitution

        Returns:
            Formatted cache key with version prefix
        """
        formatted_pattern = pattern.format(**kwargs)
        if not formatted_pattern.startswith(CACHE_VERSION):
            return f"{CACHE_VERSION}:{formatted_pattern}"
        return formatted_pattern

    @staticmethod
    def get_cascade_patterns(primary_key: str) -> List[str]:
        """
        Get all cache key patterns that should be invalidated when primary_key changes.

        This supports the cascade invalidation logic in CacheCoherenceManager.

        Args:
            primary_key: The primary cache key that changed

        Returns:
            List of wildcard patterns for related keys to invalidate
        """
        patterns = []

        # Remove version prefix to match against patterns
        key_without_version = primary_key
        if primary_key.startswith(CACHE_VERSION + ":"):
            key_without_version = primary_key[len(CACHE_VERSION) + 1 :]

        # Extract entity values from the key
        parts = key_without_version.split(":")
        extracted_values = {}

        # Common entity extractions
        if "user:" in key_without_version:
            idx = parts.index("user") if "user" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["user_id"] = parts[idx + 1]

        if "client:" in key_without_version:
            idx = parts.index("client") if "client" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["client_id"] = parts[idx + 1]

        if "engagement:" in key_without_version:
            idx = parts.index("engagement") if "engagement" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["engagement_id"] = parts[idx + 1]

        if "flow:" in key_without_version:
            idx = parts.index("flow") if "flow" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["flow_id"] = parts[idx + 1]

        if "import:" in key_without_version:
            idx = parts.index("import") if "import" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["import_id"] = parts[idx + 1]

        if "asset:" in key_without_version:
            idx = parts.index("asset") if "asset" in parts else -1
            if idx >= 0 and idx + 1 < len(parts):
                extracted_values["asset_id"] = parts[idx + 1]

        # Check each cascade relationship pattern
        for pattern_template, invalidation_patterns in CASCADE_RELATIONSHIPS.items():
            # Check if the key matches this pattern
            pattern_matches = True
            for part in pattern_template.split(":"):
                if part.startswith("{") and part.endswith("}"):
                    # This is a placeholder - check if we have the value
                    var_name = part[1:-1]
                    if var_name not in extracted_values:
                        pattern_matches = False
                        break
                elif part != "*" and part not in key_without_version:
                    pattern_matches = False
                    break

            if pattern_matches:
                # Generate invalidation patterns with substituted values
                for inv_pattern in invalidation_patterns:
                    final_pattern = inv_pattern
                    for var_name, var_value in extracted_values.items():
                        final_pattern = final_pattern.replace(
                            f"{{{var_name}}}", var_value
                        )
                    patterns.append(f"{CACHE_VERSION}:{final_pattern}")

        return list(set(patterns))  # Remove duplicates

    @staticmethod
    def get_cache_type(cache_key: str) -> Optional[CacheKeyType]:
        """
        Determine the cache type from a cache key for monitoring and metrics.

        Args:
            cache_key: The cache key to analyze

        Returns:
            CacheKeyType enum value or None if not recognized
        """
        # Remove version prefix for pattern matching
        key_without_version = cache_key
        if cache_key.startswith(CACHE_VERSION + ":"):
            key_without_version = cache_key[len(CACHE_VERSION) + 1 :]

        # Check each pattern in order of specificity
        for pattern, cache_type in CACHE_TYPE_PATTERNS.items():
            # Convert pattern to regex-like matching
            pattern_parts = pattern.split(":")
            key_parts = key_without_version.split(":")

            if len(pattern_parts) > len(key_parts):
                continue

            matches = True
            for i, pattern_part in enumerate(pattern_parts):
                if pattern_part == "*":
                    continue  # Wildcard matches anything
                elif i < len(key_parts) and pattern_part != key_parts[i]:
                    matches = False
                    break

            if matches:
                return cache_type

        return None

    @staticmethod
    def create_hash_key(base_key: str, data: str) -> str:
        """
        Create a hash-based cache key for large or complex data.
        Useful for caching query results with complex parameters.

        Args:
            base_key: Base cache key prefix
            data: Data to hash for uniqueness

        Returns:
            Cache key with hash suffix
        """
        data_hash = hashlib.sha256(data.encode()).hexdigest()[:16]
        return f"{base_key}:hash:{data_hash}"

    @staticmethod
    def get_ttl_recommendation(cache_key: str) -> int:
        """
        Get recommended TTL (in seconds) based on cache key type.

        Args:
            cache_key: The cache key to analyze

        Returns:
            Recommended TTL in seconds
        """
        # Check if this is an agent result key
        if ":agent:" in cache_key:
            # Extract agent name from key
            parts = cache_key.split(":")
            agent_idx = parts.index("agent") if "agent" in parts else -1
            if agent_idx >= 0 and agent_idx + 1 < len(parts):
                agent_name = parts[agent_idx + 1]
                # Use AgentCacheStrategy for agent-specific TTL
                return AgentCacheStrategy.get_agent_ttl(agent_name)

        # Otherwise use cache type
        cache_type = CacheKeys.get_cache_type(cache_key)

        ttl_map = {
            CacheKeyType.USER_CONTEXT: 3600,  # 1 hour
            CacheKeyType.FIELD_MAPPINGS: 120,  # 2 minutes
            CacheKeyType.FLOW_STATE: 300,  # 5 minutes
            CacheKeyType.CLIENT_DATA: 1800,  # 30 minutes
            CacheKeyType.ENGAGEMENT_DATA: 1800,  # 30 minutes
            CacheKeyType.ASSET_DATA: 900,  # 15 minutes
            CacheKeyType.IMPORT_DATA: 300,  # 5 minutes
            CacheKeyType.ADMIN_DATA: 300,  # 5 minutes
            CacheKeyType.AGENT_RESULTS: 1800,  # 30 minutes (default for unknown agents)
            CacheKeyType.AGENT_CONFIG: 3600,  # 1 hour (sensitive, encrypted)
            CacheKeyType.CREWAI_STATE: 300,  # 5 minutes (sensitive, encrypted)
            CacheKeyType.AGENT_TOOLS: 1800,  # 30 minutes (sensitive, encrypted)
            CacheKeyType.FLOW_CHECKPOINTS: 7200,  # 2 hours (expensive to regenerate)
            CacheKeyType.STATS: 1800,  # 30 minutes
        }

        return ttl_map.get(cache_type, 600)  # Default 10 min

    @staticmethod
    def agent_result(
        agent_id: str,
        agent_name: str,
        flow_id: str,
        client_account_id: str,
        engagement_id: str,
    ) -> str:
        """
        Cache key for agent execution results.
        TTL: varies by agent type (see AgentCacheStrategy)
        Invalidation: on agent re-execution, flow reset
        """
        return f"{CACHE_VERSION}:client:{client_account_id}:engagement:{engagement_id}:agent:{agent_name}:flow:{flow_id}:result:{agent_id}"

    @staticmethod
    def agent_result_with_ttl(
        agent_id: str,
        agent_name: str,
        flow_id: str,
        client_account_id: str,
        engagement_id: str,
    ) -> tuple[str, int]:
        """
        Generate agent result cache key with recommended TTL.

        Returns:
            Tuple of (cache_key, ttl_seconds)
        """
        key = CacheKeys.agent_result(
            agent_id, agent_name, flow_id, client_account_id, engagement_id
        )
        ttl = AgentCacheStrategy.get_agent_ttl(agent_name)
        return key, ttl


class AgentCacheStrategy:
    """
    Agent-specific caching strategies based on agent behavior patterns.
    Different agents have different result volatility and computation costs.
    """

    AGENT_TTL_MAP = {
        # Fast, frequently changing agents
        "data_import_agent": 300,  # 5 minutes
        "validation_agent": 180,  # 3 minutes
        "progress_tracking_agent": 60,  # 1 minute
        # Medium volatility agents
        "field_mapping_agent": 1800,  # 30 minutes
        "data_cleansing_agent": 900,  # 15 minutes
        "gap_analysis_agent": 1200,  # 20 minutes
        # Expensive, stable analysis agents
        "asset_classification_agent": 3600,  # 1 hour
        "dependency_analysis_agent": 7200,  # 2 hours
        "sixr_recommendation_agent": 14400,  # 4 hours
        "learning_agent": 86400,  # 24 hours
    }

    @classmethod
    def get_agent_ttl(cls, agent_type: str) -> int:
        """Alias for get_ttl_for_agent for backward compatibility"""
        return cls.get_ttl_for_agent(agent_type)

    @classmethod
    def get_ttl_for_agent(cls, agent_type: str) -> int:
        """
        Get recommended TTL for specific agent results.

        Args:
            agent_type: Type/name of the agent

        Returns:
            TTL in seconds, default 30 minutes if agent not found
        """
        return cls.AGENT_TTL_MAP.get(agent_type, 1800)

    @classmethod
    def should_cache_agent_result(
        cls, agent_type: str, execution_time_seconds: float
    ) -> bool:
        """
        Determine if agent result should be cached based on execution cost.

        Args:
            agent_type: Type/name of the agent
            execution_time_seconds: How long the agent took to execute

        Returns:
            True if result should be cached
        """
        # Always cache if execution took more than 30 seconds
        if execution_time_seconds > 30:
            return True

        # Cache expensive agents even if they're fast
        expensive_agents = {
            "sixr_recommendation_agent",
            "dependency_analysis_agent",
            "asset_classification_agent",
            "learning_agent",
        }

        return agent_type in expensive_agents


class SensitiveDataMarkers:
    """
    Markers to identify cache keys that contain sensitive data requiring encryption.
    Used by SecureCache to automatically encrypt/decrypt sensitive data.
    """

    # Cache key patterns that always contain sensitive data
    SENSITIVE_PATTERNS = {
        ":agent:",
        ":crewai:",
        ":flow:",
        ":user:",
        ":client:",
        "config",
        "tool",
        "memory",
        "state",
        "checkpoint",
        "context",
        "settings",
    }

    # Cache key segments that indicate sensitive data
    SENSITIVE_SEGMENTS = {
        "config",
        "credential",
        "token",
        "secret",
        "memory",
        "checkpoint",
        "context",
        "settings",
    }

    @classmethod
    def requires_encryption(cls, cache_key: str) -> bool:
        """
        Determine if a cache key contains sensitive data requiring encryption.

        Args:
            cache_key: The cache key to analyze

        Returns:
            True if the key contains sensitive data
        """
        # Check against sensitive patterns
        for pattern in cls.SENSITIVE_PATTERNS:
            if pattern in cache_key:
                return True

        # Check for sensitive segments
        key_lower = cache_key.lower()
        for segment in cls.SENSITIVE_SEGMENTS:
            if f":{segment}:" in key_lower or key_lower.endswith(f":{segment}"):
                return True

        return False

    @classmethod
    def get_encryption_context(cls, cache_key: str) -> Dict[str, str]:
        """
        Extract encryption context from cache key for additional security.

        Args:
            cache_key: The cache key to analyze

        Returns:
            Dictionary with encryption context metadata
        """
        parts = cache_key.split(":")
        context = {}

        # Extract tenant context for encryption key derivation
        if "client:" in cache_key:
            client_idx = parts.index("client") if "client" in parts else -1
            if client_idx >= 0 and client_idx + 1 < len(parts):
                context["client_id"] = parts[client_idx + 1]

        if "engagement:" in cache_key:
            engagement_idx = parts.index("engagement") if "engagement" in parts else -1
            if engagement_idx >= 0 and engagement_idx + 1 < len(parts):
                context["engagement_id"] = parts[engagement_idx + 1]

        if "user:" in cache_key:
            user_idx = parts.index("user") if "user" in parts else -1
            if user_idx >= 0 and user_idx + 1 < len(parts):
                context["user_id"] = parts[user_idx + 1]

        return context


# Export commonly used cache key generators for easy imports
__all__ = [
    "CACHE_VERSION", 
    "CacheKeys", 
    "CacheKeyType", 
    "AgentCacheStrategy",
    "SensitiveDataMarkers"
]
