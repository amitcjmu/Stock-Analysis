"""
Data Normalization Service

This module contains the DataNormalizationService class for normalizing
data values and ensuring consistency across different platforms.

Generated by CC (Claude Code)
"""

import logging
import re
from datetime import datetime
from typing import Any, Dict, List, Optional

from sqlalchemy.ext.asyncio import AsyncSession

from app.core.context import RequestContext

from .base import DataType

logger = logging.getLogger(__name__)


class DataNormalizationService:
    """
    Service for normalizing data values and ensuring consistency.

    This service handles:
    - Value standardization (e.g., status values, boolean conversions)
    - Unit conversions (e.g., storage sizes, memory)
    - Format standardization (e.g., dates, hostnames)
    - Data deduplication and consolidation
    """

    # Standard status mappings
    STATUS_MAPPINGS = {
        "running": ["running", "active", "online", "up", "started", "healthy", "ok"],
        "stopped": ["stopped", "inactive", "offline", "down", "shutdown", "halted"],
        "error": ["error", "failed", "fault", "critical", "unhealthy"],
        "warning": ["warning", "degraded", "impaired", "alert"],
        "unknown": ["unknown", "undefined", "n/a", "not available"],
    }

    # Standard environment mappings
    ENVIRONMENT_MAPPINGS = {
        "production": ["production", "prod", "prd", "live"],
        "staging": ["staging", "stage", "stg", "uat", "preprod", "pre-prod"],
        "development": ["development", "dev", "develop"],
        "test": ["test", "testing", "tst", "qa"],
        "disaster_recovery": ["dr", "disaster recovery", "backup"],
    }

    def __init__(self, db: AsyncSession, context: RequestContext):
        """
        Initialize the Data Normalization Service.

        Args:
            db: Database session
            context: Request context
        """
        self.db = db
        self.context = context

    async def normalize_dataset(
        self,
        dataset: List[Dict[str, Any]],
        data_type: DataType,
        normalization_config: Optional[Dict[str, Any]] = None,
    ) -> List[Dict[str, Any]]:
        """
        Normalize a complete dataset.

        Args:
            dataset: List of data records to normalize
            data_type: Type of data being normalized
            normalization_config: Optional normalization configuration

        Returns:
            List of normalized data records
        """
        normalized_data = []

        for record in dataset:
            normalized_record = await self.normalize_record(
                record, data_type, normalization_config
            )
            normalized_data.append(normalized_record)

        # Remove duplicates if configured
        if normalization_config and normalization_config.get(
            "remove_duplicates", False
        ):
            normalized_data = self._remove_duplicates(
                normalized_data,
                normalization_config.get("duplicate_key_fields", ["hostname"]),
            )

        return normalized_data

    async def normalize_record(
        self,
        record: Dict[str, Any],
        data_type: DataType,
        normalization_config: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Normalize a single data record.

        Args:
            record: Data record to normalize
            data_type: Type of data being normalized
            normalization_config: Optional normalization configuration

        Returns:
            Normalized data record
        """
        normalized = record.copy()

        # Apply standard normalizations
        normalized = self._normalize_status_values(normalized)
        normalized = self._normalize_environment_values(normalized)
        normalized = self._normalize_boolean_values(normalized)
        normalized = self._normalize_memory_values(normalized)
        normalized = self._normalize_storage_values(normalized)
        normalized = self._normalize_hostnames(normalized)
        normalized = self._normalize_dates(normalized)

        # Apply data type specific normalizations
        if data_type == DataType.SERVER:
            normalized = self._normalize_server_data(normalized)
        elif data_type == DataType.APPLICATION:
            normalized = self._normalize_application_data(normalized)
        elif data_type == DataType.DATABASE:
            normalized = self._normalize_database_data(normalized)

        # Apply custom normalizations
        if normalization_config and "custom_rules" in normalization_config:
            normalized = self._apply_custom_normalizations(
                normalized, normalization_config["custom_rules"]
            )

        return normalized

    def _normalize_status_values(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Normalize status values to standard terms."""
        status_fields = [
            "status",
            "state",
            "power_state",
            "operational_status",
            "health",
        ]

        for field in status_fields:
            if field in data and data[field]:
                value = str(data[field]).lower().strip()
                for standard_status, variations in self.STATUS_MAPPINGS.items():
                    if value in variations:
                        data[field] = standard_status
                        break

        return data

    def _normalize_environment_values(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Normalize environment values to standard terms."""
        env_fields = ["environment", "env", "tier", "stage"]

        for field in env_fields:
            if field in data and data[field]:
                value = str(data[field]).lower().strip()
                for standard_env, variations in self.ENVIRONMENT_MAPPINGS.items():
                    if value in variations:
                        data[field] = standard_env
                        break

        return data

    def _normalize_boolean_values(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Normalize boolean values."""
        boolean_true = ["true", "yes", "y", "1", "on", "enabled", "active"]
        boolean_false = ["false", "no", "n", "0", "off", "disabled", "inactive"]

        for key, value in data.items():
            if isinstance(value, str):
                value_lower = value.lower().strip()
                if value_lower in boolean_true:
                    data[key] = True
                elif value_lower in boolean_false:
                    data[key] = False

        return data

    def _normalize_memory_values(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Normalize memory values to GB."""
        memory_fields = ["memory", "memory_gb", "ram", "total_memory"]

        for field in memory_fields:
            if field in data:
                value = data[field]
                if isinstance(value, str):
                    # Extract numeric value and unit
                    match = re.match(r"(\d+\.?\d*)\s*([A-Za-z]+)?", value)
                    if match:
                        num = float(match.group(1))
                        unit = match.group(2).upper() if match.group(2) else "GB"

                        # Convert to GB
                        if unit == "MB":
                            data[field] = round(num / 1024, 2)
                        elif unit == "KB":
                            data[field] = round(num / (1024 * 1024), 2)
                        elif unit == "TB":
                            data[field] = round(num * 1024, 2)
                        else:
                            data[field] = round(num, 2)

        return data

    def _normalize_storage_values(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Normalize storage values to GB."""
        storage_fields = ["disk", "storage", "disk_size", "storage_gb", "size_gb"]

        for field in storage_fields:
            if field in data:
                value = data[field]
                if isinstance(value, str):
                    # Extract numeric value and unit
                    match = re.match(r"(\d+\.?\d*)\s*([A-Za-z]+)?", value)
                    if match:
                        num = float(match.group(1))
                        unit = match.group(2).upper() if match.group(2) else "GB"

                        # Convert to GB
                        if unit == "MB":
                            data[field] = round(num / 1024, 2)
                        elif unit == "TB":
                            data[field] = round(num * 1024, 2)
                        else:
                            data[field] = round(num, 2)

        return data

    def _normalize_hostnames(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Normalize hostname formats."""
        hostname_fields = ["hostname", "host_name", "server_name", "fqdn"]

        for field in hostname_fields:
            if field in data and data[field]:
                # Convert to lowercase and strip whitespace
                data[field] = str(data[field]).lower().strip()

                # Remove common domain suffixes if not FQDN field
                if field != "fqdn" and "." in data[field]:
                    data[field] = data[field].split(".")[0]

        return data

    def _normalize_dates(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Normalize date formats to ISO 8601."""
        date_fields = ["created_at", "updated_at", "last_seen", "discovered_at"]

        for field in date_fields:
            if field in data and data[field]:
                normalized_date = self._parse_date(data[field])
                if normalized_date:
                    data[field] = normalized_date

        return data

    def _parse_date(self, date_value: Any) -> Optional[str]:
        """Parse various date formats to ISO 8601."""
        if isinstance(date_value, datetime):
            return date_value.isoformat()

        if isinstance(date_value, str):
            # Try common date formats
            formats = [
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%dT%H:%M:%S",
                "%Y-%m-%dT%H:%M:%SZ",
                "%Y-%m-%d",
                "%m/%d/%Y",
                "%d/%m/%Y",
                "%m-%d-%Y",
                "%d-%m-%Y",
            ]

            for fmt in formats:
                try:
                    dt = datetime.strptime(date_value, fmt)
                    return dt.isoformat()
                except ValueError:
                    continue

        return None

    def _normalize_server_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Apply server-specific normalizations."""
        # Normalize CPU count
        if "cpu_count" in data:
            try:
                data["cpu_count"] = int(data["cpu_count"])
            except (ValueError, TypeError):
                pass

        # Normalize OS names
        if "operating_system" in data and data["operating_system"]:
            os_name = str(data["operating_system"]).lower()
            if "windows" in os_name:
                data["os_family"] = "windows"
            elif "linux" in os_name or "ubuntu" in os_name or "centos" in os_name:
                data["os_family"] = "linux"
            elif "aix" in os_name:
                data["os_family"] = "aix"
            elif "solaris" in os_name:
                data["os_family"] = "solaris"
            else:
                data["os_family"] = "other"

        return data

    def _normalize_application_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Apply application-specific normalizations."""
        # Normalize criticality values
        if "criticality" in data and data["criticality"]:
            criticality = str(data["criticality"]).lower()
            criticality_map = {
                "critical": ["critical", "high", "1", "mission critical"],
                "high": ["important", "2", "business critical"],
                "medium": ["medium", "moderate", "3", "standard"],
                "low": ["low", "minimal", "4", "non-critical"],
            }

            for standard, variations in criticality_map.items():
                if criticality in variations:
                    data["criticality"] = standard
                    break

        return data

    def _normalize_database_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Apply database-specific normalizations."""
        # Normalize database types
        if "db_type" in data and data["db_type"]:
            db_type = str(data["db_type"]).lower()
            type_map = {
                "oracle": ["oracle", "ora", "oracle database"],
                "mysql": ["mysql", "mariadb"],
                "postgresql": ["postgresql", "postgres", "pg"],
                "sqlserver": ["sql server", "mssql", "microsoft sql server"],
                "mongodb": ["mongodb", "mongo"],
                "redis": ["redis", "redis cache"],
                "elasticsearch": ["elasticsearch", "elastic"],
            }

            for standard, variations in type_map.items():
                if any(var in db_type for var in variations):
                    data["db_type"] = standard
                    break

        return data

    def _apply_custom_normalizations(
        self, data: Dict[str, Any], rules: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Apply custom normalization rules."""
        for rule in rules:
            field = rule.get("field")
            normalization_type = rule.get("type")

            if field in data:
                if normalization_type == "uppercase":
                    data[field] = str(data[field]).upper()
                elif normalization_type == "lowercase":
                    data[field] = str(data[field]).lower()
                elif normalization_type == "trim":
                    data[field] = str(data[field]).strip()
                elif normalization_type == "replace":
                    old_value = rule.get("old_value")
                    new_value = rule.get("new_value")
                    if old_value and new_value:
                        data[field] = str(data[field]).replace(old_value, new_value)

        return data

    def _remove_duplicates(
        self, dataset: List[Dict[str, Any]], key_fields: List[str]
    ) -> List[Dict[str, Any]]:
        """Remove duplicate records based on key fields."""
        seen = set()
        unique_data = []
        for record in dataset:
            # Create composite key from specified fields
            key_values = [str(record[field]) for field in key_fields if field in record]
            if key_values:
                key = "|".join(key_values)
                if key not in seen:
                    seen.add(key)
                    unique_data.append(record)
        return unique_data
