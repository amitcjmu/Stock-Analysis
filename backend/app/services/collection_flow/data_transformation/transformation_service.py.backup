"""
Data Transformation Service

This module contains the DataTransformationService class for transforming
raw collected data into standardized formats.

Generated by CC (Claude Code)
"""

import logging
import re
from datetime import datetime
from typing import Any, Callable, Dict, List, Optional

from sqlalchemy.ext.asyncio import AsyncSession

from app.core.context import RequestContext

from .base import DataType, TransformationResult, TransformationRule

logger = logging.getLogger(__name__)


class DataTransformationService:
    """
    Service for transforming raw collected data into standardized formats.

    This service handles:
    - Field mapping and renaming
    - Value conversions and formatting
    - Data structure transformations
    - Complex rule-based transformations
    """

    # Standard field mappings for common platforms
    STANDARD_FIELD_MAPPINGS = {
        "server": {
            "hostname": ["name", "host_name", "server_name", "computer_name", "fqdn"],
            "ip_address": ["ip", "ipaddress", "ip_addr", "primary_ip", "management_ip"],
            "operating_system": ["os", "os_name", "operating_system_name", "platform"],
            "os_version": ["os_version", "version", "os_release", "kernel_version"],
            "cpu_count": ["cpu", "cpus", "processor_count", "vcpus", "cores"],
            "memory_gb": ["memory", "ram", "total_memory", "memory_size"],
            "status": ["state", "power_state", "operational_status", "status"],
            "environment": ["env", "environment_type", "tier", "stage"],
            "location": ["datacenter", "dc", "site", "region", "zone"],
            "serial_number": ["serial", "service_tag", "asset_tag"],
            "model": ["hardware_model", "server_model", "platform_model"],
            "manufacturer": ["vendor", "make", "manufacturer_name"],
        },
        "application": {
            "app_name": ["name", "application_name", "app", "service_name"],
            "version": ["app_version", "release", "build"],
            "status": ["state", "health", "operational_status"],
            "environment": ["env", "stage", "tier"],
            "owner": ["app_owner", "business_owner", "contact"],
            "criticality": ["priority", "importance", "business_criticality"],
            "technology": ["tech_stack", "platform", "framework"],
            "url": ["endpoint", "base_url", "service_url"],
            "port": ["service_port", "listen_port", "app_port"],
        },
        "database": {
            "db_name": ["database_name", "name", "sid", "instance_name"],
            "db_type": ["engine", "database_type", "platform", "vendor"],
            "version": ["db_version", "engine_version", "release"],
            "host": ["hostname", "server", "db_host"],
            "port": ["db_port", "listen_port", "service_port"],
            "size_gb": ["database_size", "size", "allocated_storage"],
            "status": ["state", "availability", "health_status"],
        },
    }

    def __init__(self, db: AsyncSession, context: RequestContext):
        """
        Initialize the Data Transformation Service.

        Args:
            db: Database session
            context: Request context
        """
        self.db = db
        self.context = context
        self._transformation_rules: Dict[str, List[Callable]] = {}

    async def transform_data(
        self,
        raw_data: Dict[str, Any],
        data_type: DataType,
        source_platform: str,
        transformation_config: Optional[Dict[str, Any]] = None,
    ) -> TransformationResult:
        """
        Transform raw data into normalized format.

        Args:
            raw_data: Raw data to transform
            data_type: Type of data being transformed
            source_platform: Source platform name
            transformation_config: Optional transformation configuration

        Returns:
            TransformationResult with transformed data
        """
        try:
            # Apply platform-specific transformations
            platform_transformed = await self._apply_platform_transformations(
                raw_data, source_platform
            )

            # Apply standard field mappings
            field_mapped = self._apply_field_mappings(platform_transformed, data_type)

            # Apply custom transformation rules
            if transformation_config:
                custom_transformed = await self._apply_custom_transformations(
                    field_mapped, transformation_config
                )
            else:
                custom_transformed = field_mapped

            # Validate transformed data
            validation_errors = self._validate_transformed_data(
                custom_transformed, data_type
            )

            return TransformationResult(
                success=len(validation_errors) == 0,
                transformed_data=custom_transformed,
                validation_errors=validation_errors,
                transformation_metadata={
                    "source_platform": source_platform,
                    "data_type": data_type.value,
                    "transformation_timestamp": datetime.utcnow().isoformat(),
                    "rules_applied": (
                        transformation_config.get("rules", [])
                        if transformation_config
                        else []
                    ),
                },
            )

        except Exception as e:
            logger.error(f"Data transformation failed: {str(e)}")
            return TransformationResult(
                success=False, validation_errors=[f"Transformation error: {str(e)}"]
            )

    async def _apply_platform_transformations(
        self, data: Dict[str, Any], platform: str
    ) -> Dict[str, Any]:
        """Apply platform-specific transformations."""
        transformed = data.copy()

        # ServiceNow transformations
        if platform.lower() == "servicenow":
            transformed = self._transform_servicenow_data(transformed)

        # VMware transformations
        elif platform.lower() in ["vmware", "vcenter", "vmware_vcenter"]:
            transformed = self._transform_vmware_data(transformed)

        # AWS transformations
        elif platform.lower() == "aws":
            transformed = self._transform_aws_data(transformed)

        # Add more platform-specific transformations as needed

        return transformed

    def _transform_servicenow_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Transform ServiceNow specific data formats."""
        transformed = {}

        for key, value in data.items():
            # Handle ServiceNow reference fields
            if (
                isinstance(value, dict)
                and "value" in value
                and "display_value" in value
            ):
                # Use display value for human-readable fields
                transformed[key] = value.get("display_value", value.get("value"))
            # Handle ServiceNow datetime format
            elif key in ["sys_created_on", "sys_updated_on"] and isinstance(value, str):
                transformed[key] = self._parse_servicenow_datetime(value)
            else:
                transformed[key] = value

        return transformed

    def _transform_vmware_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Transform VMware specific data formats."""
        transformed = {}

        for key, value in data.items():
            # Convert VMware memory values (usually in MB) to GB
            if key in ["memorySizeMB", "memory_size_mb"] and isinstance(
                value, (int, float)
            ):
                transformed["memory_gb"] = round(value / 1024, 2)
            # Handle VMware MoRef IDs
            elif key == "vm" and isinstance(value, dict) and "_moId" in value:
                transformed["vm_id"] = value["_moId"]
            else:
                transformed[key] = value

        return transformed

    def _transform_aws_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Transform AWS specific data formats."""
        transformed = {}

        for key, value in data.items():
            # Handle AWS tags
            if key == "Tags" and isinstance(value, list):
                transformed["tags"] = {tag["Key"]: tag["Value"] for tag in value}
            # Handle AWS instance state
            elif key == "State" and isinstance(value, dict):
                transformed["status"] = value.get("Name", "unknown")
            else:
                transformed[key] = value

        return transformed

    def _apply_field_mappings(
        self, data: Dict[str, Any], data_type: DataType
    ) -> Dict[str, Any]:
        """Apply standard field mappings based on data type."""
        if data_type.value not in self.STANDARD_FIELD_MAPPINGS:
            return data

        mappings = self.STANDARD_FIELD_MAPPINGS[data_type.value]
        transformed = {}
        used_fields = set()

        # Apply mappings
        for standard_field, possible_fields in mappings.items():
            for field in possible_fields:
                if field in data and field not in used_fields:
                    transformed[standard_field] = data[field]
                    used_fields.add(field)
                    break

        # Include unmapped fields
        for key, value in data.items():
            if key not in used_fields and key not in transformed:
                transformed[key] = value

        return transformed

    async def _apply_custom_transformations(
        self, data: Dict[str, Any], config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Apply custom transformation rules."""
        transformed = data.copy()
        rules = config.get("rules", [])

        for rule in rules:
            rule_type = rule.get("type")

            if rule_type == TransformationRule.FIELD_MAPPING.value:
                transformed = self._apply_field_mapping_rule(transformed, rule)

            elif rule_type == TransformationRule.VALUE_CONVERSION.value:
                transformed = self._apply_value_conversion_rule(transformed, rule)

            elif rule_type == TransformationRule.FIELD_SPLIT.value:
                transformed = self._apply_field_split_rule(transformed, rule)

            elif rule_type == TransformationRule.FIELD_MERGE.value:
                transformed = self._apply_field_merge_rule(transformed, rule)

            elif rule_type == TransformationRule.REGEX_EXTRACT.value:
                transformed = self._apply_regex_extract_rule(transformed, rule)

            elif rule_type == TransformationRule.CONDITIONAL.value:
                transformed = self._apply_conditional_rule(transformed, rule)

        return transformed

    def _apply_field_mapping_rule(
        self, data: Dict[str, Any], rule: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Apply field mapping transformation rule."""
        source_field = rule.get("source_field")
        target_field = rule.get("target_field")

        if source_field in data:
            data[target_field] = data[source_field]
            if rule.get("remove_source", False):
                del data[source_field]

        return data

    def _apply_value_conversion_rule(
        self, data: Dict[str, Any], rule: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Apply value conversion transformation rule."""
        field = rule.get("field")
        conversion_type = rule.get("conversion_type")

        if field in data:
            value = data[field]

            if conversion_type == "uppercase":
                data[field] = str(value).upper()
            elif conversion_type == "lowercase":
                data[field] = str(value).lower()
            elif conversion_type == "int":
                try:
                    data[field] = int(value)
                except (ValueError, TypeError):
                    pass
            elif conversion_type == "float":
                try:
                    data[field] = float(value)
                except (ValueError, TypeError):
                    pass
            elif conversion_type == "bool":
                data[field] = str(value).lower() in ["true", "yes", "1", "on"]
            elif conversion_type == "bytes_to_gb":
                try:
                    data[field] = round(float(value) / (1024**3), 2)
                except (ValueError, TypeError):
                    pass

        return data

    def _apply_field_split_rule(
        self, data: Dict[str, Any], rule: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Apply field split transformation rule."""
        source_field = rule.get("source_field")
        delimiter = rule.get("delimiter", " ")
        target_fields = rule.get("target_fields", [])

        if source_field in data and isinstance(data[source_field], str):
            parts = data[source_field].split(delimiter)
            for i, target_field in enumerate(target_fields):
                if i < len(parts):
                    data[target_field] = parts[i].strip()

        return data

    def _apply_field_merge_rule(
        self, data: Dict[str, Any], rule: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Apply field merge transformation rule."""
        source_fields = rule.get("source_fields", [])
        target_field = rule.get("target_field")
        delimiter = rule.get("delimiter", " ")

        values = []
        for field in source_fields:
            if field in data and data[field]:
                values.append(str(data[field]))

        if values:
            data[target_field] = delimiter.join(values)

        return data

    def _apply_regex_extract_rule(
        self, data: Dict[str, Any], rule: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Apply regex extraction transformation rule."""
        source_field = rule.get("source_field")
        pattern = rule.get("pattern")
        target_field = rule.get("target_field")

        if source_field in data and pattern:
            try:
                match = re.search(pattern, str(data[source_field]))
                if match:
                    if match.groups():
                        data[target_field] = match.group(1)
                    else:
                        data[target_field] = match.group(0)
            except re.error:
                logger.error(f"Invalid regex pattern: {pattern}")

        return data

    def _apply_conditional_rule(
        self, data: Dict[str, Any], rule: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Apply conditional transformation rule."""
        condition = rule.get("condition", {})
        field = condition.get("field")
        operator = condition.get("operator")
        value = condition.get("value")

        if field in data:
            field_value = data[field]
            condition_met = False

            if operator == "equals":
                condition_met = field_value == value
            elif operator == "not_equals":
                condition_met = field_value != value
            elif operator == "contains":
                condition_met = str(value) in str(field_value)
            elif operator == "greater_than":
                try:
                    condition_met = float(field_value) > float(value)
                except (ValueError, TypeError):
                    pass
            elif operator == "less_than":
                try:
                    condition_met = float(field_value) < float(value)
                except (ValueError, TypeError):
                    pass

            if condition_met:
                # Apply transformation if condition is met
                transform = rule.get("transform", {})
                target_field = transform.get("field")
                target_value = transform.get("value")
                if target_field:
                    data[target_field] = target_value

        return data

    def _validate_transformed_data(
        self, data: Dict[str, Any], data_type: DataType
    ) -> List[str]:
        """Validate transformed data for completeness and correctness."""
        errors = []

        # Define required fields by data type
        required_fields = {
            DataType.SERVER: ["hostname", "ip_address", "operating_system"],
            DataType.APPLICATION: ["app_name", "version"],
            DataType.DATABASE: ["db_name", "db_type", "host"],
        }

        # Check required fields
        if data_type in required_fields:
            for field in required_fields[data_type]:
                if field not in data or not data[field]:
                    errors.append(f"Required field '{field}' is missing or empty")

        # Validate field formats
        if "ip_address" in data:
            if not self._is_valid_ip(data["ip_address"]):
                errors.append(f"Invalid IP address format: {data['ip_address']}")

        if "memory_gb" in data:
            try:
                memory = float(data["memory_gb"])
                if memory < 0:
                    errors.append("Memory value cannot be negative")
            except (ValueError, TypeError):
                errors.append(f"Invalid memory value: {data['memory_gb']}")

        return errors

    def _is_valid_ip(self, ip: str) -> bool:
        """Validate IP address format."""
        try:
            parts = ip.split(".")
            return len(parts) == 4 and all(0 <= int(part) <= 255 for part in parts)
        except (ValueError, AttributeError):
            return False

    def _parse_servicenow_datetime(self, datetime_str: str) -> str:
        """Parse ServiceNow datetime format to ISO format."""
        try:
            # ServiceNow format: YYYY-MM-DD HH:MM:SS
            dt = datetime.strptime(datetime_str, "%Y-%m-%d %H:%M:%S")
            return dt.isoformat()
        except ValueError:
            return datetime_str
