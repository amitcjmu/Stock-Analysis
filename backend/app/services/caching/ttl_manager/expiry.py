"""
Expiry logic and refresh handlers for TTL management.

This module contains background refresh processing, task scheduling,
and expiry management logic.

Generated by CC (Claude Code)
"""

import asyncio
import time
from collections import deque
from datetime import datetime, timedelta
from typing import Any, Callable, Dict, Optional

from app.core.logging import get_logger
from .base import RefreshTask, RefreshPriority, CacheAccessPattern, TTLMetrics

logger = get_logger(__name__)


class RefreshTaskScheduler:
    """Manages background refresh task scheduling and execution"""

    def __init__(self, max_concurrent_refreshes: int = 5):
        self.max_concurrent_refreshes = max_concurrent_refreshes
        self.refresh_queues: Dict[RefreshPriority, deque] = {
            priority: deque() for priority in RefreshPriority
        }
        self.active_refresh_tasks: Dict[str, RefreshTask] = {}
        self.metrics: Optional[TTLMetrics] = None

    def schedule_refresh(
        self,
        cache_key: str,
        refresh_callback: Callable[[str], Any],
        priority: RefreshPriority = RefreshPriority.MEDIUM,
        delay_seconds: int = 0,
    ) -> str:
        """
        Schedule background refresh for a cache key.

        Args:
            cache_key: Key to refresh
            refresh_callback: Function to call for refresh
            priority: Refresh priority
            delay_seconds: Delay before refresh

        Returns:
            Task ID for tracking
        """
        scheduled_time = datetime.utcnow() + timedelta(seconds=delay_seconds)

        task = RefreshTask(
            cache_key=cache_key,
            priority=priority,
            refresh_callback=refresh_callback,
            scheduled_time=scheduled_time,
        )

        self.refresh_queues[priority].append(task)
        if self.metrics:
            self.metrics.refresh_tasks_scheduled += 1

        logger.debug(f"Scheduled refresh for {cache_key} with priority {priority.name}")
        return f"refresh_{int(time.time() * 1000)}_{cache_key}"

    def schedule_predictive_refresh(
        self,
        cache_key: str,
        refresh_callback: Callable[[str], Any],
        access_patterns: Dict[str, CacheAccessPattern],
    ) -> Optional[str]:
        """Schedule predictive refresh based on access patterns"""
        pattern = access_patterns.get(cache_key)
        if not pattern:
            return None

        next_access = pattern.predict_next_access()
        if not next_access:
            return None

        # Schedule refresh slightly before predicted access
        refresh_time = next_access - timedelta(minutes=5)  # 5 minutes buffer
        if refresh_time <= datetime.utcnow():
            return None

        delay_seconds = (refresh_time - datetime.utcnow()).total_seconds()
        priority = (
            RefreshPriority.HIGH if pattern.is_hot_data else RefreshPriority.MEDIUM
        )

        return self.schedule_refresh(
            cache_key=cache_key,
            refresh_callback=refresh_callback,
            priority=priority,
            delay_seconds=int(delay_seconds),
        )

    async def process_refresh_queues(self) -> None:
        """Process refresh tasks from priority queues"""
        if len(self.active_refresh_tasks) >= self.max_concurrent_refreshes:
            return

        # Process from highest priority to lowest
        for priority in RefreshPriority:
            queue = self.refresh_queues[priority]

            while (
                queue and len(self.active_refresh_tasks) < self.max_concurrent_refreshes
            ):
                task = queue.popleft()

                if task.is_due:
                    # Execute refresh task
                    self.active_refresh_tasks[task.cache_key] = task
                    asyncio.create_task(self._execute_refresh_task(task))
                else:
                    # Put it back for later
                    queue.appendleft(task)
                    break

    async def _execute_refresh_task(self, task: RefreshTask) -> None:
        """Execute a refresh task"""
        try:
            # Call the refresh callback
            if asyncio.iscoroutinefunction(task.refresh_callback):
                await task.refresh_callback(task.cache_key)
            else:
                task.refresh_callback(task.cache_key)

            if self.metrics:
                self.metrics.refresh_tasks_completed += 1
                self.metrics.cache_hits_prevented += 1  # Estimate

            logger.debug(f"Completed refresh task for {task.cache_key}")

        except Exception as e:
            logger.error(f"Refresh task failed for {task.cache_key}: {e}")
            task.retry_count += 1
            if self.metrics:
                self.metrics.refresh_tasks_failed += 1

            # Retry if appropriate
            if task.should_retry:
                # Reschedule with delay
                task.scheduled_time = datetime.utcnow() + timedelta(
                    seconds=60
                )  # 1 minute delay
                self.refresh_queues[RefreshPriority.LOW].append(task)

        finally:
            # Remove from active tasks
            self.active_refresh_tasks.pop(task.cache_key, None)

    def get_queue_stats(self) -> Dict[str, int]:
        """Get statistics about refresh queues"""
        return {
            priority.name: len(queue) for priority, queue in self.refresh_queues.items()
        }


class BackgroundProcessor:
    """Handles background processing tasks for TTL management"""

    def __init__(self, scheduler: RefreshTaskScheduler):
        self.scheduler = scheduler
        self._processing_task: Optional[asyncio.Task] = None
        self._metrics_task: Optional[asyncio.Task] = None
        self._shutdown_event = asyncio.Event()

        # System metrics for load-aware processing
        self.system_load_history: deque = deque(maxlen=100)
        self.memory_usage_history: deque = deque(maxlen=100)

    async def start(self) -> None:
        """Start background processing"""
        if self._processing_task is not None:
            logger.warning("Background processor already started")
            return

        self._shutdown_event.clear()
        self._processing_task = asyncio.create_task(self._background_processing())
        self._metrics_task = asyncio.create_task(self._metrics_collection())

        logger.info("Background processor started")

    async def stop(self) -> None:
        """Stop background processing"""
        if self._processing_task is None:
            return

        logger.info("Stopping background processor...")
        self._shutdown_event.set()

        try:
            if self._processing_task:
                await asyncio.wait_for(self._processing_task, timeout=10.0)
            if self._metrics_task:
                await asyncio.wait_for(self._metrics_task, timeout=5.0)
        except asyncio.TimeoutError:
            logger.warning("Background processor shutdown timeout")
            if self._processing_task:
                self._processing_task.cancel()
            if self._metrics_task:
                self._metrics_task.cancel()

        self._processing_task = None
        self._metrics_task = None
        logger.info("Background processor stopped")

    async def _background_processing(self) -> None:
        """Main background processing loop"""
        logger.info("Starting background processing loop")

        while not self._shutdown_event.is_set():
            try:
                # Process refresh queues
                await self.scheduler.process_refresh_queues()

                # Small delay to prevent tight loop
                await asyncio.sleep(1.0)  # 1 second

            except Exception as e:
                logger.error(f"Error in background processing: {e}")
                await asyncio.sleep(5.0)  # Longer delay on error

        logger.info("Background processing loop stopped")

    async def _metrics_collection(self) -> None:
        """Background task to collect system metrics"""
        logger.info("Starting metrics collection")

        while not self._shutdown_event.is_set():
            try:
                # Collect system metrics
                system_load = self._get_current_system_load()
                memory_pressure = self._get_memory_pressure()

                self.system_load_history.append(system_load)
                self.memory_usage_history.append(memory_pressure)

                # Sleep for 30 seconds between collections
                await asyncio.sleep(30.0)

            except Exception as e:
                logger.error(f"Error in metrics collection: {e}")
                await asyncio.sleep(60.0)  # Longer delay on error

        logger.info("Metrics collection stopped")

    def _get_current_system_load(self) -> float:
        """Get current system load (0.0 to 1.0)"""
        try:
            import psutil

            return psutil.cpu_percent(interval=0.1) / 100.0
        except ImportError:
            return 0.5

    def _get_memory_pressure(self) -> float:
        """Get current memory pressure (0.0 to 1.0)"""
        try:
            import psutil

            memory = psutil.virtual_memory()
            return memory.percent / 100.0
        except ImportError:
            return 0.5

    def is_running(self) -> bool:
        """Check if background processing is active"""
        return self._processing_task is not None and not self._processing_task.done()

    async def health_check(self) -> Dict[str, Any]:
        """Perform health check on background processor"""
        return {
            "background_processing_active": self.is_running(),
            "metrics_collection_active": (
                self._metrics_task is not None and not self._metrics_task.done()
            ),
            "active_refresh_tasks": len(self.scheduler.active_refresh_tasks),
            "max_concurrent_refreshes": self.scheduler.max_concurrent_refreshes,
            "queue_stats": self.scheduler.get_queue_stats(),
        }
