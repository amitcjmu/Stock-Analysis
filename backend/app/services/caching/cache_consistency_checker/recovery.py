"""
Cache Consistency Recovery Operations

This module implements recovery and audit operations for cache consistency:
- Scheduled consistency audit loops
- Bulk consistency checking with concurrency control
- Automated recovery procedures
- Audit report generation and analysis
- Background task management

ðŸ”’ Security: Secure audit operations with proper access controls
âš¡ Performance: Efficient bulk operations with resource management
ðŸŽ¯ Coherence: Comprehensive recovery strategies for all failure scenarios

Generated by CC (Claude Code)
"""

import asyncio
import time
from datetime import datetime
from typing import Any, Dict, List, Optional

from app.core.logging import get_logger
from app.services.caching.redis_cache import RedisCache

from .base import (
    ConsistencyAuditReport,
    ConsistencyCheckResult,
    ConsistencyCheckType,
    ConsistencyConfiguration,
    ConsistencyStatus,
    create_default_configuration,
)
from .conflict_resolvers import ConflictResolver
from .exceptions import ConsistencyAuditError
from .monitors import ConsistencyMonitor
from .policy_engine import PolicyEngine
from .synchronizers import DataSynchronizer
from .validators import ConsistencyValidator

logger = get_logger(__name__)


class BulkConsistencyChecker:
    """Handles bulk consistency checking operations with concurrency control"""

    def __init__(
        self,
        validator: ConsistencyValidator,
        config: ConsistencyConfiguration,
        policy_engine: Optional[PolicyEngine] = None,
    ):
        self.validator = validator
        self.config = config
        self.policy_engine = policy_engine or PolicyEngine(config)

    async def check_bulk_consistency(
        self,
        cache_keys: List[str],
        check_type: ConsistencyCheckType = ConsistencyCheckType.BASIC,
        client_account_id: Optional[str] = None,
        database_value_getter=None,
    ) -> List[ConsistencyCheckResult]:
        """Check consistency of multiple cache keys in batches"""
        results = []

        if not cache_keys:
            logger.info("No cache keys provided for bulk consistency check")
            return results

        logger.info(f"Starting bulk consistency check for {len(cache_keys)} keys")

        # Process in batches to avoid overwhelming the system
        for i in range(0, len(cache_keys), self.config.batch_size):
            batch = cache_keys[i : i + self.config.batch_size]
            logger.debug(
                f"Processing batch {i//self.config.batch_size + 1}: {len(batch)} keys"
            )

            # Process batch concurrently but with limited concurrency
            semaphore = asyncio.Semaphore(self.config.max_concurrent_checks)

            async def check_with_semaphore(key: str) -> ConsistencyCheckResult:
                async with semaphore:
                    return await self._check_single_key_with_policy(
                        key, check_type, client_account_id, database_value_getter
                    )

            batch_tasks = [check_with_semaphore(key) for key in batch]
            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)

            # Handle results and exceptions
            for key, result in zip(batch, batch_results):
                if isinstance(result, Exception):
                    logger.error(f"Consistency check failed for {key}: {result}")
                    results.append(
                        ConsistencyCheckResult(
                            cache_key=key,
                            status=ConsistencyStatus.CORRUPTED,
                            check_type=check_type,
                            details=f"Check failed: {result}",
                        )
                    )
                else:
                    results.append(result)

            # Small delay between batches to reduce system load
            if i + self.config.batch_size < len(cache_keys):
                await asyncio.sleep(0.1)

        logger.info(f"Completed bulk consistency check: {len(results)} results")
        return results

    async def _check_single_key_with_policy(
        self,
        cache_key: str,
        check_type: ConsistencyCheckType,
        client_account_id: Optional[str],
        database_value_getter,
    ) -> ConsistencyCheckResult:
        """Check single key with policy evaluation"""
        try:
            # Create context for policy evaluation
            context = {
                "cache_key": cache_key,
                "client_account_id": client_account_id,
                "check_type": check_type,
            }

            # Check if this check should be deferred
            if self.policy_engine.should_defer_check(context):
                return ConsistencyCheckResult(
                    cache_key=cache_key,
                    status=ConsistencyStatus.CONSISTENT,  # Assume consistent for deferred checks
                    check_type=check_type,
                    details="Check deferred by policy",
                    confidence=0.5,
                )

            # Determine appropriate check type based on policies
            policy_check_type = self.policy_engine.determine_check_type(context)
            actual_check_type = (
                policy_check_type if policy_check_type != check_type else check_type
            )

            # Perform the consistency check
            if actual_check_type == ConsistencyCheckType.BASIC:
                result = await self.validator.check_basic_consistency(
                    cache_key, client_account_id
                )
            elif actual_check_type == ConsistencyCheckType.DEEP:
                result = await self.validator.check_deep_consistency(
                    cache_key, client_account_id, database_value_getter
                )
            elif actual_check_type == ConsistencyCheckType.CHECKSUM:
                result = await self.validator.check_checksum_consistency(
                    cache_key, client_account_id, database_value_getter
                )
            elif actual_check_type == ConsistencyCheckType.SCHEMA_VALIDATION:
                result = await self.validator.check_schema_consistency(
                    cache_key, client_account_id
                )
            else:
                result = await self.validator.check_basic_consistency(
                    cache_key, client_account_id
                )

            return result

        except Exception as e:
            logger.error(f"Policy-based consistency check failed for {cache_key}: {e}")
            return ConsistencyCheckResult(
                cache_key=cache_key,
                status=ConsistencyStatus.CORRUPTED,
                check_type=check_type,
                details=f"Policy check failed: {e}",
                confidence=0.0,
            )


class AuditReportGenerator:
    """Generates comprehensive audit reports"""

    def __init__(self, config: ConsistencyConfiguration):
        self.config = config

    def generate_audit_report(
        self,
        audit_id: str,
        start_time: datetime,
        cache_keys: List[str],
        results: List[ConsistencyCheckResult],
        repair_results: List[bool],
    ) -> ConsistencyAuditReport:
        """Generate comprehensive audit report"""
        report = ConsistencyAuditReport(
            audit_id=audit_id,
            start_time=start_time,
            end_time=datetime.utcnow(),
            total_keys_checked=len(cache_keys),
            detailed_results=results,
        )

        # Aggregate results by status
        for result in results:
            if result.status == ConsistencyStatus.CONSISTENT:
                report.consistent_keys += 1
            elif result.status == ConsistencyStatus.INCONSISTENT:
                report.inconsistent_keys += 1
            elif result.status == ConsistencyStatus.CORRUPTED:
                report.corrupted_keys += 1
            elif result.status == ConsistencyStatus.MISSING:
                report.missing_keys += 1
            elif result.status == ConsistencyStatus.ORPHANED:
                report.orphaned_keys += 1

        # Process repair results
        report.repairs_attempted = len(repair_results)
        report.repairs_successful = sum(1 for success in repair_results if success)
        report.repairs_failed = report.repairs_attempted - report.repairs_successful

        # Calculate performance metrics
        report.total_execution_time_ms = report.duration_seconds * 1000

        # Performance impact analysis
        if results:
            avg_check_time = sum(r.execution_time_ms for r in results) / len(results)
            max_check_time = max(r.execution_time_ms for r in results)

            report.performance_impact = {
                "average_check_time_ms": avg_check_time,
                "max_check_time_ms": max_check_time,
                "total_check_time_ms": sum(r.execution_time_ms for r in results),
                "throughput_checks_per_second": len(results)
                / max(report.duration_seconds, 1),
            }

        logger.info(
            f"Generated audit report {audit_id}: "
            f"consistency_score={report.consistency_score:.2%}, "
            f"repairs={report.repairs_successful}/{report.repairs_attempted}"
        )

        return report

    def analyze_audit_trends(
        self, reports: List[ConsistencyAuditReport]
    ) -> Dict[str, Any]:
        """Analyze trends across multiple audit reports"""
        if not reports:
            return {"error": "No audit reports provided"}

        trend_analysis = {
            "total_reports": len(reports),
            "time_range": {
                "start": min(report.start_time for report in reports).isoformat(),
                "end": max(
                    report.end_time for report in reports if report.end_time
                ).isoformat(),
            },
            "consistency_trend": [],
            "repair_success_trend": [],
            "performance_trend": [],
            "summary": {},
        }

        # Calculate trends
        for report in sorted(reports, key=lambda r: r.start_time):
            trend_analysis["consistency_trend"].append(
                {
                    "timestamp": report.start_time.isoformat(),
                    "score": report.consistency_score,
                }
            )

            trend_analysis["repair_success_trend"].append(
                {
                    "timestamp": report.start_time.isoformat(),
                    "rate": report.repair_success_rate,
                }
            )

            if report.performance_impact:
                trend_analysis["performance_trend"].append(
                    {
                        "timestamp": report.start_time.isoformat(),
                        "avg_check_time": report.performance_impact.get(
                            "average_check_time_ms", 0
                        ),
                    }
                )

        # Summary statistics
        avg_consistency = sum(r.consistency_score for r in reports) / len(reports)
        avg_repair_rate = sum(r.repair_success_rate for r in reports) / len(reports)

        trend_analysis["summary"] = {
            "average_consistency_score": avg_consistency,
            "average_repair_success_rate": avg_repair_rate,
            "total_checks_performed": sum(r.total_keys_checked for r in reports),
            "total_repairs_attempted": sum(r.repairs_attempted for r in reports),
            "total_repairs_successful": sum(r.repairs_successful for r in reports),
        }

        return trend_analysis


class ScheduledAuditManager:
    """Manages scheduled consistency audits"""

    def __init__(
        self,
        redis_cache: RedisCache,
        data_synchronizer: DataSynchronizer,
        monitor: ConsistencyMonitor,
        config: Optional[ConsistencyConfiguration] = None,
    ):
        self.redis_cache = redis_cache
        self.data_synchronizer = data_synchronizer
        self.monitor = monitor
        self.config = config or create_default_configuration()

        # Initialize components
        self.validator = ConsistencyValidator(redis_cache)
        self.policy_engine = PolicyEngine(self.config)
        self.conflict_resolver = ConflictResolver(redis_cache, data_synchronizer)
        self.bulk_checker = BulkConsistencyChecker(
            self.validator, self.config, self.policy_engine
        )
        self.report_generator = AuditReportGenerator(self.config)

        # Background processing
        self._audit_task: Optional[asyncio.Task] = None
        self._shutdown_event = asyncio.Event()
        self.audit_history: List[ConsistencyAuditReport] = []

    async def start_scheduled_audits(self) -> None:
        """Start scheduled consistency audits"""
        if self._audit_task is not None:
            logger.warning("Scheduled audits already running")
            return

        self._shutdown_event.clear()
        self._audit_task = asyncio.create_task(self._scheduled_audit_loop())
        logger.info("Scheduled consistency audits started")

    async def stop_scheduled_audits(self) -> None:
        """Stop scheduled consistency audits"""
        if self._audit_task is None:
            return

        logger.info("Stopping scheduled consistency audits...")
        self._shutdown_event.set()

        try:
            await asyncio.wait_for(self._audit_task, timeout=30.0)
        except asyncio.TimeoutError:
            logger.warning("Audit task shutdown timeout")
            self._audit_task.cancel()

        self._audit_task = None
        logger.info("Scheduled consistency audits stopped")

    async def run_full_consistency_audit(
        self,
        client_account_id: Optional[str] = None,
        check_type: ConsistencyCheckType = ConsistencyCheckType.DEEP,
    ) -> ConsistencyAuditReport:
        """
        Run comprehensive consistency audit across all cache entries.

        Args:
            client_account_id: Specific client to audit (None for platform-wide)
            check_type: Type of consistency check to perform

        Returns:
            ConsistencyAuditReport with comprehensive results
        """
        audit_id = f"audit_{int(time.time() * 1000)}"
        start_time = datetime.utcnow()

        logger.info(f"Starting consistency audit {audit_id}")

        try:
            # Get all cache keys to check
            cache_keys = await self.data_synchronizer.get_all_cache_keys(
                client_account_id
            )

            if not cache_keys:
                logger.info(f"No cache keys found for audit {audit_id}")
                return self.report_generator.generate_audit_report(
                    audit_id, start_time, [], [], []
                )

            # Perform bulk consistency check
            results = await self.bulk_checker.check_bulk_consistency(
                cache_keys,
                check_type,
                client_account_id,
                self.data_synchronizer.get_database_value,
            )

            # Record results in monitor
            for result in results:
                self.monitor.record_check_result(result)

            # Attempt repairs for inconsistent entries
            inconsistent_results = [r for r in results if r.needs_repair]
            repair_results = []

            if inconsistent_results:
                logger.info(
                    f"Attempting to repair {len(inconsistent_results)} inconsistencies"
                )
                repair_start_time = time.time()

                repair_results = (
                    await self.conflict_resolver.resolve_bulk_inconsistencies(
                        inconsistent_results
                    )
                )

                repair_duration = (time.time() - repair_start_time) * 1000
                self.monitor.record_repair_result(sum(repair_results), repair_duration)

            # Generate comprehensive report
            report = self.report_generator.generate_audit_report(
                audit_id, start_time, cache_keys, results, repair_results
            )

            # Record audit completion
            self.monitor.record_audit_completion(report.duration_seconds)

            # Store in history
            self.audit_history.append(report)

            # Keep only recent history
            if len(self.audit_history) > 100:
                self.audit_history = self.audit_history[-100:]

            logger.info(
                f"Completed consistency audit {audit_id}: "
                f"{report.consistent_keys}/{report.total_keys_checked} consistent, "
                f"{report.repairs_successful}/{report.repairs_attempted} repairs successful"
            )

            return report

        except Exception as e:
            logger.error(f"Consistency audit {audit_id} failed: {e}")
            raise ConsistencyAuditError(
                f"Audit {audit_id} failed: {e}",
                audit_id=audit_id,
                details={"error": str(e), "start_time": start_time.isoformat()},
            )

    async def _scheduled_audit_loop(self) -> None:
        """Background loop for scheduled consistency audits"""
        logger.info("Starting scheduled consistency audit loop")

        while not self._shutdown_event.is_set():
            try:
                # Wait for next audit interval
                await asyncio.wait_for(
                    self._shutdown_event.wait(),
                    timeout=self.config.default_check_interval_hours * 3600,
                )

                # If we're here due to shutdown event, break
                if self._shutdown_event.is_set():
                    break

            except asyncio.TimeoutError:
                # Timeout reached - time for next audit
                pass

            try:
                # Run consistency audit
                logger.info("Starting scheduled consistency audit")
                report = await self.run_full_consistency_audit()

                # Log audit results
                logger.info(
                    f"Scheduled audit completed: "
                    f"consistency_score={report.consistency_score:.2%}, "
                    f"repairs={report.repairs_successful}/{report.repairs_attempted}"
                )

                # Record any inconsistency patterns
                for result in report.detailed_results:
                    if result.needs_repair:
                        self.policy_engine.record_inconsistency_pattern(
                            result.cache_key
                        )

            except Exception as e:
                logger.error(f"Scheduled audit failed: {e}")
                # Continue with next iteration

        logger.info("Scheduled consistency audit loop stopped")

    def get_audit_history(self, limit: int = 10) -> List[ConsistencyAuditReport]:
        """Get recent audit history"""
        return self.audit_history[-limit:] if self.audit_history else []

    def get_audit_trends(self) -> Dict[str, Any]:
        """Get audit trend analysis"""
        return self.report_generator.analyze_audit_trends(self.audit_history)

    def is_audit_running(self) -> bool:
        """Check if scheduled audits are running"""
        return self._audit_task is not None and not self._audit_task.done()


# Export all recovery classes
__all__ = [
    "BulkConsistencyChecker",
    "AuditReportGenerator",
    "ScheduledAuditManager",
]
