"""
Cache Consistency Validator Utilities

This module contains utility classes for cache data validation:
- Schema validation utilities
- Data format validators
- Common field validators
- Type-specific validation helpers

ðŸ”’ Security: Robust data validation with comprehensive error handling
âš¡ Performance: Efficient validation with minimal overhead
ðŸŽ¯ Coherence: Structured validation approach for all cache data types

Generated by CC (Claude Code)
"""

import hashlib
import json
from typing import Any, Dict

from app.constants.cache_keys import CacheKeyType, CacheKeys
from app.core.logging import get_logger

from .base import validate_data_size

logger = get_logger(__name__)


class CacheKeyParser:
    """Parser for extracting entity information from cache keys"""

    @staticmethod
    def parse_cache_key(cache_key: str) -> Any:
        """Parse cache key to extract entity information"""
        from .base import EntityInfo

        if not cache_key or not isinstance(cache_key, str):
            return None

        # Split the cache key by colons
        parts = cache_key.split(":")
        if len(parts) < 2:
            return None

        # Simple pattern matching - this could be enhanced
        entity_type = parts[0]
        entity_id = parts[1] if len(parts) > 1 else "unknown"
        data_type = parts[2] if len(parts) > 2 else "default"

        # Extract client_account_id if present in the key pattern
        client_account_id = None
        if "client" in cache_key.lower():
            # Look for client account patterns
            for part in parts:
                if part.startswith("client_"):
                    client_account_id = part.replace("client_", "")
                    break

        return EntityInfo(
            entity_type=entity_type,
            entity_id=entity_id,
            data_type=data_type,
            client_account_id=client_account_id,
        )


class DataComparator:
    """Utility for comparing cache and database data"""

    @staticmethod
    def compare_data(cache_data: Any, db_data: Any) -> bool:
        """Compare cache data with database data"""
        try:
            # Normalize both data for comparison
            cache_normalized = DataComparator._normalize_data(cache_data)
            db_normalized = DataComparator._normalize_data(db_data)

            return cache_normalized == db_normalized

        except Exception as e:
            logger.error(f"Data comparison failed: {e}")
            return False

    @staticmethod
    def _normalize_data(data: Any) -> Any:
        """Normalize data for consistent comparison"""
        if data is None:
            return None

        if isinstance(data, dict):
            # Remove timestamp fields that might vary
            normalized = data.copy()
            for key in ["created_at", "updated_at", "last_accessed"]:
                normalized.pop(key, None)
            return normalized

        elif isinstance(data, list):
            return [DataComparator._normalize_data(item) for item in data]

        else:
            return data

    @staticmethod
    def calculate_checksum(data: Any) -> str:
        """Calculate checksum for data"""
        try:
            # Convert data to a consistent string representation
            if isinstance(data, dict):
                # Sort keys for consistent ordering
                sorted_data = json.dumps(data, sort_keys=True, default=str)
            else:
                sorted_data = json.dumps(data, default=str)

            return hashlib.sha256(sorted_data.encode()).hexdigest()[:16]

        except Exception:
            return hashlib.sha256(str(data).encode()).hexdigest()[:16]


class SchemaValidator:
    """Schema validation for cached data"""

    @staticmethod
    def validate_cache_data_schema(cache_key: str, cache_value: Any) -> Dict[str, Any]:
        """Validate cache data against expected schema"""
        result = {"valid": True, "errors": []}

        # Basic validation
        if not SchemaValidator._validate_basic_structure(cache_value, result):
            return result

        # Validate based on cache type
        SchemaValidator._validate_by_cache_type(cache_key, cache_value, result)

        # Validate common fields
        SchemaValidator._validate_common_fields(cache_value, result)

        return result

    @staticmethod
    def _validate_basic_structure(cache_value: Any, result: Dict[str, Any]) -> bool:
        """Validate basic data structure and serializability"""
        try:
            # Check if data is serializable
            json.dumps(cache_value, default=str)

            # Check data size
            if not validate_data_size(cache_value):
                result["valid"] = False
                result["errors"].append("Data size exceeds maximum allowed limit")
                return False

            return True

        except Exception as e:
            result["valid"] = False
            result["errors"].append(f"Serialization error: {e}")
            return False

    @staticmethod
    def _validate_by_cache_type(
        cache_key: str, cache_value: Any, result: Dict[str, Any]
    ) -> None:
        """Validate data based on cache key type"""
        cache_type = CacheKeys.get_cache_type(cache_key)

        if cache_type == CacheKeyType.USER_CONTEXT:
            if not isinstance(cache_value, dict):
                result["valid"] = False
                result["errors"].append("User context must be a dictionary")
            elif "user_id" not in cache_value:
                result["valid"] = False
                result["errors"].append("User context must contain user_id")

        elif cache_type == CacheKeyType.CLIENT_SETTINGS:
            if not isinstance(cache_value, dict):
                result["valid"] = False
                result["errors"].append("Client settings must be a dictionary")

    @staticmethod
    def _validate_common_fields(cache_value: Any, result: Dict[str, Any]) -> None:
        """Validate common fields across all cache types"""
        if not isinstance(cache_value, dict):
            return

        # Check for required timestamp fields
        if "updated_at" in cache_value:
            try:
                from datetime import datetime

                datetime.fromisoformat(cache_value["updated_at"])
            except (ValueError, TypeError):
                result["valid"] = False
                result["errors"].append("Invalid timestamp format in updated_at")

        # Check for valid ID fields
        id_fields = ["id", "user_id", "client_id", "engagement_id", "flow_id"]
        for field in id_fields:
            if field in cache_value:
                if not isinstance(cache_value[field], (str, int)):
                    result["valid"] = False
                    result["errors"].append(
                        f"Invalid {field} format - must be string or int"
                    )


# Export all validator utility classes
__all__ = [
    "CacheKeyParser",
    "DataComparator",
    "SchemaValidator",
]
