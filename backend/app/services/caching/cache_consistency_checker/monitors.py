"""
Cache Consistency Monitors

This module implements monitoring and metrics collection for cache consistency:
- Real-time consistency metrics tracking
- Health check implementations
- Performance monitoring and alerting
- System resource usage monitoring

ðŸ”’ Security: Secure metrics collection without exposing sensitive data
âš¡ Performance: Lightweight monitoring with minimal system overhead
ðŸŽ¯ Coherence: Comprehensive monitoring coverage for all consistency operations

Generated by CC (Claude Code)
"""

import time
from collections import deque
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from app.core.logging import get_logger

from .base import (
    ConsistencyCheckResult,
    ConsistencyMetrics,
    ConsistencyStatus,
    create_default_metrics,
)
from .exceptions import MetricsCollectionError

logger = get_logger(__name__)


class PerformanceMetrics:
    """Tracks performance metrics for consistency operations"""

    def __init__(self, max_samples: int = 1000):
        self.max_samples = max_samples
        self.check_times: deque = deque(maxlen=max_samples)
        self.repair_times: deque = deque(maxlen=max_samples)
        self.audit_times: deque = deque(maxlen=max_samples)
        self.memory_usage: deque = deque(maxlen=max_samples)

    def record_check_time(self, duration_ms: float) -> None:
        """Record consistency check execution time"""
        self.check_times.append({"duration_ms": duration_ms, "timestamp": time.time()})

    def record_repair_time(self, duration_ms: float) -> None:
        """Record repair operation execution time"""
        self.repair_times.append({"duration_ms": duration_ms, "timestamp": time.time()})

    def record_audit_time(self, duration_seconds: float) -> None:
        """Record audit operation execution time"""
        self.audit_times.append(
            {"duration_seconds": duration_seconds, "timestamp": time.time()}
        )

    def record_memory_usage(self, memory_mb: float) -> None:
        """Record memory usage"""
        self.memory_usage.append({"memory_mb": memory_mb, "timestamp": time.time()})

    def get_check_time_stats(self) -> Dict[str, float]:
        """Get check time statistics"""
        if not self.check_times:
            return {"avg": 0, "min": 0, "max": 0, "p95": 0, "p99": 0}

        times = [entry["duration_ms"] for entry in self.check_times]
        times.sort()

        return {
            "avg": sum(times) / len(times),
            "min": times[0],
            "max": times[-1],
            "p95": times[int(len(times) * 0.95)] if len(times) > 20 else times[-1],
            "p99": times[int(len(times) * 0.99)] if len(times) > 100 else times[-1],
        }

    def get_repair_time_stats(self) -> Dict[str, float]:
        """Get repair time statistics"""
        if not self.repair_times:
            return {"avg": 0, "min": 0, "max": 0, "p95": 0, "p99": 0}

        times = [entry["duration_ms"] for entry in self.repair_times]
        times.sort()

        return {
            "avg": sum(times) / len(times),
            "min": times[0],
            "max": times[-1],
            "p95": times[int(len(times) * 0.95)] if len(times) > 20 else times[-1],
            "p99": times[int(len(times) * 0.99)] if len(times) > 100 else times[-1],
        }

    def get_memory_stats(self) -> Dict[str, float]:
        """Get memory usage statistics"""
        if not self.memory_usage:
            return {"avg": 0, "min": 0, "max": 0, "current": 0}

        memory_values = [entry["memory_mb"] for entry in self.memory_usage]
        return {
            "avg": sum(memory_values) / len(memory_values),
            "min": min(memory_values),
            "max": max(memory_values),
            "current": memory_values[-1] if memory_values else 0,
        }


class AlertManager:
    """Manages alerts for consistency issues"""

    def __init__(self):
        self.alert_thresholds = {
            "consistency_score_low": 0.9,
            "repair_success_rate_low": 0.8,
            "check_time_high_ms": 5000,
            "memory_usage_high_mb": 500,
            "quarantine_items_high": 1000,
        }
        self.active_alerts: Dict[str, Dict[str, Any]] = {}
        self.alert_history: deque = deque(maxlen=1000)

    def check_alerts(
        self,
        consistency_score: float,
        repair_rate: float,
        quarantine_count: int,
        check_stats: Dict[str, float],
    ) -> List[Dict[str, Any]]:
        """Check all alert conditions and return alerts"""
        alerts = []

        if consistency_score < self.alert_thresholds["consistency_score_low"]:
            alerts.append(
                {
                    "type": "consistency_score_low",
                    "severity": "high",
                    "message": f"Consistency score is low: {consistency_score:.2%}",
                    "value": consistency_score,
                }
            )

        if repair_rate < self.alert_thresholds["repair_success_rate_low"]:
            alerts.append(
                {
                    "type": "repair_success_rate_low",
                    "severity": "medium",
                    "message": f"Repair success rate is low: {repair_rate:.2%}",
                    "value": repair_rate,
                }
            )

        if check_stats.get("p95", 0) > self.alert_thresholds["check_time_high_ms"]:
            alerts.append(
                {
                    "type": "check_time_high",
                    "severity": "medium",
                    "message": f"Check time P95 is high: {check_stats['p95']:.1f}ms",
                    "value": check_stats["p95"],
                }
            )

        if quarantine_count > self.alert_thresholds["quarantine_items_high"]:
            alerts.append(
                {
                    "type": "quarantine_items_high",
                    "severity": "medium",
                    "message": f"High number of quarantined items: {quarantine_count}",
                    "value": quarantine_count,
                }
            )

        self.process_alerts(alerts)
        return self.get_active_alerts()

    def process_alerts(self, alerts: List[Dict[str, Any]]) -> None:
        """Process and manage active alerts"""
        current_time = datetime.utcnow()

        for alert in alerts:
            alert_key = alert["type"]
            alert["timestamp"] = current_time.isoformat()
            self.active_alerts[alert_key] = alert
            self.alert_history.append(alert.copy())

            # Log alert based on severity
            if alert["severity"] == "high":
                logger.error(f"ALERT: {alert['message']}")
            elif alert["severity"] == "medium":
                logger.warning(f"ALERT: {alert['message']}")
            else:
                logger.info(f"ALERT: {alert['message']}")

    def get_active_alerts(self) -> List[Dict[str, Any]]:
        """Get list of active alerts"""
        return list(self.active_alerts.values())

    def get_alert_history(self, hours: int = 24) -> List[Dict[str, Any]]:
        """Get alert history for specified time period"""
        cutoff_time = datetime.utcnow() - timedelta(hours=hours)

        filtered_history = []
        for alert in self.alert_history:
            try:
                alert_time = datetime.fromisoformat(alert["timestamp"])
                if alert_time >= cutoff_time:
                    filtered_history.append(alert)
            except (ValueError, KeyError):
                continue

        return filtered_history


class HealthChecker:
    """Performs health checks on the consistency checker system"""

    def __init__(self):
        self.last_health_check: Optional[datetime] = None
        self.health_status = "unknown"

    async def perform_health_check(
        self,
        metrics: ConsistencyMetrics,
        performance_metrics: PerformanceMetrics,
        quarantine_count: int,
        scheduled_audits_running: bool,
    ) -> Dict[str, Any]:
        """Perform comprehensive health check"""
        try:
            self.last_health_check = datetime.utcnow()

            health = {
                "status": "healthy",
                "timestamp": self.last_health_check.isoformat(),
                "scheduled_audits_running": scheduled_audits_running,
                "total_checks_performed": metrics.total_checks,
                "quarantined_items": quarantine_count,
                "recent_consistency_score": 0.0,
                "issues": [],
                "recommendations": [],
            }

            # Calculate recent consistency score
            if metrics.total_checks > 0:
                consistent_count = metrics.status_distribution[
                    ConsistencyStatus.CONSISTENT
                ]
                health["recent_consistency_score"] = (
                    consistent_count / metrics.total_checks
                ) * 100

            # Performance metrics
            health["performance"] = {
                "check_times": performance_metrics.get_check_time_stats(),
                "repair_times": performance_metrics.get_repair_time_stats(),
                "memory_usage": performance_metrics.get_memory_stats(),
            }

            # Check for issues and generate recommendations
            issues = []
            recommendations = []

            if health["recent_consistency_score"] < 90:
                issues.append(
                    f"Low consistency score: {health['recent_consistency_score']:.1f}%"
                )
                recommendations.append("Consider running a full consistency audit")
                health["status"] = "warning"

            if quarantine_count > 100:
                issues.append(f"High number of quarantined items: {quarantine_count}")
                recommendations.append(
                    "Review quarantined items and clean up expired entries"
                )
                if health["status"] == "healthy":
                    health["status"] = "warning"

            if not scheduled_audits_running:
                issues.append("Scheduled audits not running")
                recommendations.append(
                    "Start scheduled audits to maintain consistency monitoring"
                )
                if health["status"] == "healthy":
                    health["status"] = "degraded"

            health["issues"] = issues
            health["recommendations"] = recommendations
            self.health_status = health["status"]
            return health

        except Exception as e:
            logger.error(f"Health check failed: {e}")
            raise MetricsCollectionError(
                f"Health check failed: {e}", metric_type="health_check"
            )

    def is_healthy(self) -> bool:
        """Check if system is currently healthy"""
        return self.health_status == "healthy"

    def get_health_summary(self) -> Dict[str, Any]:
        """Get summary health information"""
        return {
            "status": self.health_status,
            "last_check": (
                self.last_health_check.isoformat() if self.last_health_check else None
            ),
        }


class ConsistencyMonitor:
    """Main monitoring orchestrator for cache consistency"""

    def __init__(self, max_recent_results: int = 1000):
        self.metrics = create_default_metrics()
        self.performance_metrics = PerformanceMetrics()
        self.alert_manager = AlertManager()
        self.health_checker = HealthChecker()
        self.recent_results: deque = deque(maxlen=max_recent_results)

    def record_check_result(self, result: ConsistencyCheckResult) -> None:
        """Record a consistency check result"""
        try:
            self.metrics.update_check(result)
            self.performance_metrics.record_check_time(result.execution_time_ms)
            self.recent_results.append(result)
        except Exception as e:
            logger.error(f"Failed to record check result: {e}")

    def record_repair_result(self, success: bool, duration_ms: float = 0) -> None:
        """Record a repair operation result"""
        try:
            self.metrics.update_repair(success)
            if duration_ms > 0:
                self.performance_metrics.record_repair_time(duration_ms)
        except Exception as e:
            logger.error(f"Failed to record repair result: {e}")

    def record_audit_completion(self, duration_seconds: float) -> None:
        """Record audit completion"""
        try:
            self.metrics.last_audit_time = datetime.utcnow()
            self.performance_metrics.record_audit_time(duration_seconds)
        except Exception as e:
            logger.error(f"Failed to record audit completion: {e}")

    def record_memory_usage(self, memory_mb: float) -> None:
        """Record current memory usage"""
        try:
            self.performance_metrics.record_memory_usage(memory_mb)
        except Exception as e:
            logger.error(f"Failed to record memory usage: {e}")

    def check_alerts(self, quarantine_count: int = 0) -> List[Dict[str, Any]]:
        """Check for alerts and return active alerts"""
        try:
            # Calculate current metrics
            consistency_score = 0.0
            repair_rate = 0.0

            if self.metrics.total_checks > 0:
                consistency_score = (
                    self.metrics.status_distribution[ConsistencyStatus.CONSISTENT]
                    / self.metrics.total_checks
                )

            if self.metrics.repairs_attempted > 0:
                repair_rate = (
                    self.metrics.repairs_successful / self.metrics.repairs_attempted
                )

            check_stats = self.performance_metrics.get_check_time_stats()

            return self.alert_manager.check_alerts(
                consistency_score, repair_rate, quarantine_count, check_stats
            )

        except Exception as e:
            logger.error(f"Alert checking failed: {e}")
            return []

    async def get_health_status(
        self, quarantine_count: int = 0, scheduled_audits_running: bool = False
    ) -> Dict[str, Any]:
        """Get comprehensive health status"""
        return await self.health_checker.perform_health_check(
            self.metrics,
            self.performance_metrics,
            quarantine_count,
            scheduled_audits_running,
        )

    def get_comprehensive_metrics(self) -> Dict[str, Any]:
        """Get comprehensive metrics including performance data"""
        return {
            "total_checks": self.metrics.total_checks,
            "average_execution_time_ms": self.metrics.average_execution_time_ms,
            "checks_by_type": {
                check_type.value: count
                for check_type, count in self.metrics.checks_by_type.items()
            },
            "status_distribution": {
                status.value: count
                for status, count in self.metrics.status_distribution.items()
            },
            "consistency_score": (
                self.metrics.status_distribution[ConsistencyStatus.CONSISTENT]
                / max(self.metrics.total_checks, 1)
                * 100
            ),
            "repairs": {
                "attempted": self.metrics.repairs_attempted,
                "successful": self.metrics.repairs_successful,
                "success_rate": (
                    self.metrics.repairs_successful
                    / max(self.metrics.repairs_attempted, 1)
                    * 100
                ),
            },
            "performance": {
                "check_times": self.performance_metrics.get_check_time_stats(),
                "repair_times": self.performance_metrics.get_repair_time_stats(),
                "memory_usage": self.performance_metrics.get_memory_stats(),
            },
        }

    def reset_metrics(self) -> None:
        """Reset all metrics"""
        self.metrics = create_default_metrics()
        self.recent_results.clear()
        logger.info("Consistency metrics reset")


# Export all monitoring classes
__all__ = [
    "PerformanceMetrics",
    "AlertManager",
    "HealthChecker",
    "ConsistencyMonitor",
]
