"""
Time-based cache invalidation strategies.

This module implements time-based cache invalidation including:
- TTL expiration with strategic refresh windows
- Sliding expiration for frequently accessed data
- Predictive refresh based on usage patterns
- Background refresh operations

Generated by CC (Claude Code)
"""

import time
from collections import defaultdict
from datetime import datetime, timedelta
from typing import Dict, List

from app.constants.cache_keys import CacheKeys
from app.core.logging import get_logger

from .base import (
    BaseInvalidationStrategy,
    InvalidationEvent,
    InvalidationResult,
    InvalidationTrigger,
)

logger = get_logger(__name__)


class TimeBasedInvalidationStrategy(BaseInvalidationStrategy):
    """
    Handles time-based cache invalidation including:
    - TTL expiration
    - Strategic refresh windows
    - Sliding expiration for frequently accessed data
    - Predictive refresh based on usage patterns
    """

    def __init__(self, redis_cache):
        super().__init__(redis_cache)
        self.refresh_window_ratio = 0.1  # Refresh when 10% of TTL remains
        self.access_pattern_cache: Dict[str, List[datetime]] = defaultdict(list)
        self.max_access_history = 100  # Keep last 100 access times

    def can_handle(self, event: InvalidationEvent) -> bool:
        """Handle TTL expiration and background refresh events"""
        return event.trigger in [
            InvalidationTrigger.TTL_EXPIRATION,
            InvalidationTrigger.BACKGROUND_REFRESH,
        ]

    async def invalidate(self, event: InvalidationEvent) -> InvalidationResult:
        """Execute time-based invalidation"""
        start_time = time.time()

        try:
            if event.trigger == InvalidationTrigger.TTL_EXPIRATION:
                return await self._handle_ttl_expiration(event)
            elif event.trigger == InvalidationTrigger.BACKGROUND_REFRESH:
                return await self._handle_background_refresh(event)
            else:
                return InvalidationResult(
                    success=False,
                    keys_invalidated=0,
                    execution_time_ms=(time.time() - start_time) * 1000,
                    strategy_used=self.get_strategy_name(),
                    errors=[f"Unsupported trigger: {event.trigger}"],
                )

        except Exception as e:
            logger.error(f"Time-based invalidation failed: {e}")
            return InvalidationResult(
                success=False,
                keys_invalidated=0,
                execution_time_ms=(time.time() - start_time) * 1000,
                strategy_used=self.get_strategy_name(),
                errors=[str(e)],
            )

    async def _handle_ttl_expiration(
        self, event: InvalidationEvent
    ) -> InvalidationResult:
        """Handle TTL-based expiration"""
        start_time = time.time()
        keys_invalidated = 0

        # Generate cache keys for the entity
        cache_keys = self._generate_entity_cache_keys(event)

        # Remove expired keys from Redis and update statistics
        for cache_key in cache_keys:
            try:
                deleted = await self.redis_cache.delete(cache_key)
                if deleted:
                    keys_invalidated += 1
                    logger.debug(f"Expired cache key: {cache_key}")
            except Exception as e:
                logger.error(f"Failed to delete expired key {cache_key}: {e}")

        execution_time = (time.time() - start_time) * 1000

        return InvalidationResult(
            success=True,
            keys_invalidated=keys_invalidated,
            execution_time_ms=execution_time,
            strategy_used=self.get_strategy_name(),
            metadata={"trigger": "ttl_expiration", "entity_type": event.entity_type},
        )

    async def _handle_background_refresh(
        self, event: InvalidationEvent
    ) -> InvalidationResult:
        """Handle background refresh operations"""
        start_time = time.time()
        keys_invalidated = 0

        # Check if keys are within refresh window
        cache_keys = self._generate_entity_cache_keys(event)

        for cache_key in cache_keys:
            try:
                # Check if key exists and get TTL
                if await self.redis_cache.exists(cache_key):
                    # For background refresh, we mark keys for refresh but don't delete them
                    # This allows the application to refresh data proactively
                    await self._mark_for_refresh(cache_key, event)
                    keys_invalidated += 1
            except Exception as e:
                logger.error(
                    f"Failed to process background refresh for {cache_key}: {e}"
                )

        execution_time = (time.time() - start_time) * 1000

        return InvalidationResult(
            success=True,
            keys_invalidated=keys_invalidated,
            execution_time_ms=execution_time,
            strategy_used=self.get_strategy_name(),
            metadata={
                "trigger": "background_refresh",
                "entity_type": event.entity_type,
            },
        )

    async def _mark_for_refresh(self, cache_key: str, event: InvalidationEvent) -> None:
        """Mark cache key for background refresh"""
        refresh_key = f"{cache_key}:refresh_pending"
        await self.redis_cache.set(
            refresh_key,
            {
                "marked_at": datetime.utcnow().isoformat(),
                "event": event.to_dict(),
            },
            ttl=300,
        )  # 5 minute refresh window

    def _generate_entity_cache_keys(self, event: InvalidationEvent) -> List[str]:
        """Generate relevant cache keys for an entity"""
        cache_keys = []

        if event.entity_type == "user":
            cache_keys.extend(
                [
                    CacheKeys.user_context(event.entity_id),
                    CacheKeys.user_clients(event.entity_id),
                    CacheKeys.user_defaults(event.entity_id),
                ]
            )

            if event.client_account_id:
                cache_keys.append(
                    CacheKeys.user_engagements(event.entity_id, event.client_account_id)
                )

        elif event.entity_type == "client":
            cache_keys.extend(
                [
                    CacheKeys.client_engagements(event.entity_id),
                    CacheKeys.client_users(event.entity_id),
                    CacheKeys.client_settings(event.entity_id),
                ]
            )

        elif event.entity_type == "engagement" and event.client_account_id:
            cache_keys.extend(
                [
                    CacheKeys.client_flows(event.client_account_id, event.entity_id),
                ]
            )

        return cache_keys

    def track_access_pattern(self, cache_key: str) -> None:
        """Track access patterns for predictive refresh"""
        now = datetime.utcnow()
        access_history = self.access_pattern_cache[cache_key]

        # Add current access time
        access_history.append(now)

        # Keep only recent access times
        if len(access_history) > self.max_access_history:
            access_history.pop(0)

        # Clean up old access times (older than 24 hours)
        cutoff_time = now - timedelta(hours=24)
        self.access_pattern_cache[cache_key] = [
            access_time for access_time in access_history if access_time > cutoff_time
        ]

    def should_refresh_early(
        self, cache_key: str, current_ttl: int, original_ttl: int
    ) -> bool:
        """Determine if cache should be refreshed before expiration"""
        # Check if within refresh window
        refresh_threshold = original_ttl * self.refresh_window_ratio
        if current_ttl > refresh_threshold:
            return False

        # Check access patterns for frequently accessed keys
        access_history = self.access_pattern_cache.get(cache_key, [])
        if len(access_history) < 5:  # Not enough data
            return False

        # Calculate access frequency in last hour
        one_hour_ago = datetime.utcnow() - timedelta(hours=1)
        recent_accesses = [
            access_time for access_time in access_history if access_time > one_hour_ago
        ]

        # Refresh early if accessed more than 10 times in last hour
        return len(recent_accesses) > 10


__all__ = [
    "TimeBasedInvalidationStrategy",
]
