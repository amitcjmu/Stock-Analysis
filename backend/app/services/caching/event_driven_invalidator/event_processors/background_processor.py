"""
Background event processing for cache invalidation.

Generated by CC (Claude Code)
"""

import asyncio
import time
from collections import deque
from typing import TYPE_CHECKING

from app.core.logging import get_logger

if TYPE_CHECKING:
    from app.services.caching.cache_invalidation_manager import CacheInvalidationManager

from ..events import CacheInvalidationEvent

logger = get_logger(__name__)


class BackgroundEventProcessor:
    """Handles background processing of cache invalidation events."""

    def __init__(
        self,
        invalidation_manager: "CacheInvalidationManager",
        event_queue: deque,
        shutdown_event: asyncio.Event,
        batch_size: int = 50,
        batch_timeout_ms: int = 100,
    ):
        """
        Initialize background event processor.

        Args:
            invalidation_manager: Cache invalidation manager
            event_queue: Queue of events to process
            shutdown_event: Event to signal shutdown
            batch_size: Maximum events per batch
            batch_timeout_ms: Maximum wait time for batch
        """
        self.invalidation_manager = invalidation_manager
        self.event_queue = event_queue
        self.shutdown_event = shutdown_event
        self.batch_size = batch_size
        self.batch_timeout_ms = batch_timeout_ms
        self.last_batch_time = time.time()
        self._processing_task = None

    async def start_processing(self) -> None:
        """Start background event processing."""
        if self._processing_task is None:
            self.shutdown_event.clear()
            self._processing_task = asyncio.create_task(self._background_processing())

    async def stop_processing(self) -> None:
        """Stop background event processing."""
        if self._processing_task:
            self.shutdown_event.set()
            try:
                await asyncio.wait_for(self._processing_task, timeout=10.0)
            except asyncio.TimeoutError:
                logger.warning("Background processor shutdown timeout")
                self._processing_task.cancel()
            finally:
                self._processing_task = None

    async def _background_processing(self) -> None:
        """Background task to process queued events"""
        logger.info("Starting event processing background task")

        while not self.shutdown_event.is_set():
            try:
                # Process events in batches
                await self._process_event_batch()

                # Small delay to prevent tight loop
                await asyncio.sleep(0.01)  # 10ms

            except Exception as e:
                logger.error(f"Error in event processing: {e}")
                await asyncio.sleep(0.1)  # Longer delay on error

        # Process remaining events before shutdown
        await self._drain_remaining_events()
        logger.info("Event processing background task stopped")

    async def _process_event_batch(self) -> None:
        """Process a batch of events"""
        if not self.event_queue:
            return

        # Check if we should process a batch
        current_time = time.time()
        should_process_batch = (
            len(self.event_queue) >= self.batch_size
            or (current_time - self.last_batch_time) * 1000 >= self.batch_timeout_ms
        )

        if not should_process_batch:
            return

        # Collect batch
        batch = []
        batch_size = min(self.batch_size, len(self.event_queue))

        for _ in range(batch_size):
            if self.event_queue:
                batch.append(self.event_queue.popleft())

        if not batch:
            return

        # Process batch
        start_time = time.time()

        for cache_event in batch:
            await self._process_single_event(cache_event)

        processing_time = (time.time() - start_time) * 1000
        self.last_batch_time = current_time

        logger.debug(
            f"Processed batch of {len(batch)} events in {processing_time:.2f}ms"
        )

    async def _process_single_event(self, event: CacheInvalidationEvent) -> None:
        """Process a single cache invalidation event"""
        start_time = time.time()

        try:
            # Convert to InvalidationEvent and submit to manager
            invalidation_event = event.to_invalidation_event()

            # Submit to invalidation manager (non-blocking)
            task_id = await self.invalidation_manager.invalidate(
                trigger=invalidation_event.trigger,
                entity_type=invalidation_event.entity_type,
                entity_id=invalidation_event.entity_id,
                client_account_id=invalidation_event.client_account_id,
                user_id=invalidation_event.user_id,
                engagement_id=invalidation_event.engagement_id,
                priority=invalidation_event.priority,
                metadata=invalidation_event.metadata,
                wait_for_completion=False,  # Non-blocking
            )

            logger.debug(
                f"Submitted invalidation task {task_id} for event {event.entity_type}:{event.entity_id}"
            )

        except Exception as e:
            logger.error(
                f"Failed to process event {event.entity_type}:{event.entity_id}: {e}"
            )

        # Update statistics
        processing_time_ms = (time.time() - start_time) * 1000

        # Log performance metrics if enabled
        if processing_time_ms > 100:  # Log slow events
            logger.warning(
                f"Slow event processing: {event.entity_type}:{event.entity_id} "
                f"took {processing_time_ms:.2f}ms"
            )

    async def _drain_remaining_events(self) -> None:
        """Process all remaining events during shutdown"""
        if not self.event_queue:
            return

        logger.info(f"Draining {len(self.event_queue)} remaining events...")

        batch = []
        while self.event_queue:
            batch.append(self.event_queue.popleft())

        for event in batch:
            try:
                await self._process_single_event(event)
            except Exception as e:
                logger.error(f"Error draining event: {e}")

        logger.info("Finished draining remaining events")
