"""
Main EventDrivenInvalidator class for cache invalidation processing

This module contains the core EventDrivenInvalidator class that manages
event-driven cache invalidation with SQLAlchemy ORM integration.

Generated by CC (Claude Code)
"""

import asyncio
import time
from collections import deque
from typing import Any, Callable, Dict, List, Optional, TYPE_CHECKING

from app.core.config import settings
from app.core.logging import get_logger
from app.services.caching.invalidation_strategies import (
    InvalidationPriority,
    InvalidationTrigger,
)

if TYPE_CHECKING:
    from app.services.caching.cache_invalidation_manager import CacheInvalidationManager

from .base import EventProcessingStats, EventSource
from .detectors import EntityChangeDetector
from .events import CacheInvalidationEvent
from .event_processors import BackgroundEventProcessor
from .orm_listeners import SQLAlchemyEventListeners

logger = get_logger(__name__)


class EventDrivenInvalidator:
    """
    Event-driven cache invalidator that listens for various events and
    triggers appropriate cache invalidation strategies.

    Features:
    - SQLAlchemy ORM event listeners for database changes
    - User action event processing
    - Bulk operation handling with batching
    - Real-time event processing with minimal latency
    - Comprehensive event tracking and metrics
    """

    def __init__(self, invalidation_manager: "CacheInvalidationManager"):
        self.invalidation_manager = invalidation_manager
        self.stats = EventProcessingStats()

        # Event processing configuration
        self.batch_size = getattr(settings, "CACHE_INVALIDATION_BATCH_SIZE", 50)
        self.batch_timeout_ms = getattr(
            settings, "CACHE_INVALIDATION_BATCH_TIMEOUT_MS", 100
        )
        self.deduplication_window_ms = getattr(
            settings, "CACHE_INVALIDATION_DEDUPLICATION_WINDOW_MS", 5000
        )

        # Event processing state
        self.event_queue = deque()
        self.recent_events = deque(
            maxlen=1000
        )  # Keep last 1000 events for deduplication
        self.event_filters: List[Callable[[CacheInvalidationEvent], bool]] = []
        self._shutdown_event = asyncio.Event()

        # Component initialization
        self._entity_change_detector = EntityChangeDetector()
        self._orm_listeners = SQLAlchemyEventListeners(
            self._entity_change_detector, self._queue_event
        )
        self._background_processor = BackgroundEventProcessor(
            invalidation_manager,
            self.event_queue,
            self._shutdown_event,
            self.batch_size,
            self.batch_timeout_ms,
        )

        logger.info(
            f"EventDrivenInvalidator initialized with batch_size={self.batch_size}"
        )

    def start(self) -> None:
        """Start the event-driven invalidator"""
        self._orm_listeners.register_orm_listeners()
        asyncio.create_task(self._background_processor.start_processing())
        logger.info("EventDrivenInvalidator started")

    async def stop(self) -> None:
        """Stop the event-driven invalidator"""
        logger.info("Stopping EventDrivenInvalidator...")
        await self._background_processor.stop_processing()
        self._orm_listeners.unregister_orm_listeners()
        logger.info("EventDrivenInvalidator stopped")

    def add_event_filter(
        self, filter_func: Callable[[CacheInvalidationEvent], bool]
    ) -> None:
        """Add an event filter function"""
        self.event_filters.append(filter_func)

    def emit_user_login_event(
        self,
        user_id: str,
        client_account_id: str,
        engagement_id: Optional[str] = None,
        session_id: Optional[str] = None,
        ip_address: Optional[str] = None,
    ) -> None:
        """Emit user login event for cache invalidation"""
        event = CacheInvalidationEvent(
            source=EventSource.USER_SESSION,
            trigger=InvalidationTrigger.USER_LOGIN,
            entity_type="user_session",
            entity_id=session_id or user_id,
            client_account_id=client_account_id,
            user_id=user_id,
            engagement_id=engagement_id,
            operation="LOGIN",
            metadata={
                "session_id": session_id,
                "ip_address": ip_address,
            },
            priority=InvalidationPriority.HIGH,
        )
        self._queue_event(event)

    def emit_user_logout_event(
        self,
        user_id: str,
        client_account_id: str,
        engagement_id: Optional[str] = None,
        session_id: Optional[str] = None,
    ) -> None:
        """Emit user logout event for cache invalidation"""
        event = CacheInvalidationEvent(
            source=EventSource.USER_SESSION,
            trigger=InvalidationTrigger.USER_LOGOUT,
            entity_type="user_session",
            entity_id=session_id or user_id,
            client_account_id=client_account_id,
            user_id=user_id,
            engagement_id=engagement_id,
            operation="LOGOUT",
            metadata={"session_id": session_id},
            priority=InvalidationPriority.MEDIUM,
        )
        self._queue_event(event)

    def emit_user_context_change_event(
        self,
        user_id: str,
        client_account_id: str,
        engagement_id: Optional[str] = None,
        old_context: Optional[Dict[str, Any]] = None,
        new_context: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Emit user context change event"""
        event = CacheInvalidationEvent(
            source=EventSource.USER_ACTION,
            trigger=InvalidationTrigger.USER_CONTEXT_CHANGE,
            entity_type="user_context",
            entity_id=user_id,
            client_account_id=client_account_id,
            user_id=user_id,
            engagement_id=engagement_id,
            operation="CONTEXT_CHANGE",
            old_values=old_context,
            new_values=new_context,
            priority=InvalidationPriority.MEDIUM,
        )
        self._queue_event(event)

    def emit_user_role_change_event(
        self,
        user_id: str,
        client_account_id: str,
        engagement_id: Optional[str] = None,
        old_roles: Optional[List[str]] = None,
        new_roles: Optional[List[str]] = None,
    ) -> None:
        """Emit user role change event"""
        event = CacheInvalidationEvent(
            source=EventSource.USER_ACTION,
            trigger=InvalidationTrigger.USER_PERMISSION_CHANGE,
            entity_type="user_roles",
            entity_id=user_id,
            client_account_id=client_account_id,
            user_id=user_id,
            engagement_id=engagement_id,
            operation="ROLE_CHANGE",
            old_values={"roles": old_roles} if old_roles else None,
            new_values={"roles": new_roles} if new_roles else None,
            priority=InvalidationPriority.HIGH,
        )
        self._queue_event(event)

    def emit_security_event(
        self,
        event_type: str,
        client_account_id: str,
        user_id: Optional[str] = None,
        engagement_id: Optional[str] = None,
        entity_type: Optional[str] = None,
        entity_id: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Emit security-related event for cache invalidation"""
        event = CacheInvalidationEvent(
            source=EventSource.SECURITY,
            trigger=InvalidationTrigger.SECURITY_EVENT,
            entity_type=entity_type or "security_event",
            entity_id=entity_id or f"security_{int(time.time())}",
            client_account_id=client_account_id,
            user_id=user_id,
            engagement_id=engagement_id,
            operation=event_type.upper(),
            metadata=metadata or {},
            priority=InvalidationPriority.CRITICAL,
        )
        self._queue_event(event)

    def emit_bulk_data_change_event(
        self,
        entity_type: str,
        operation: str,
        client_account_id: str,
        affected_count: int,
        user_id: Optional[str] = None,
        engagement_id: Optional[str] = None,
        entity_filter: Optional[Dict[str, Any]] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Emit bulk data change event for cache invalidation"""
        event = CacheInvalidationEvent(
            source=EventSource.BULK_OPERATION,
            trigger=InvalidationTrigger.BULK_DATA_CHANGE,
            entity_type=entity_type,
            entity_id=f"bulk_{operation}_{int(time.time())}",
            client_account_id=client_account_id,
            user_id=user_id,
            engagement_id=engagement_id,
            operation=operation.upper(),
            metadata={
                "affected_count": affected_count,
                "entity_filter": entity_filter,
                **(metadata or {}),
            },
            priority=InvalidationPriority.HIGH,
        )
        self._queue_event(event)

    def get_stats(self) -> Dict[str, Any]:
        """Get event processing statistics"""
        return {
            "total_events_processed": self.stats.total_events_processed,
            "total_events_failed": self.stats.total_events_failed,
            "average_processing_time_ms": self.stats.get_average_processing_time_ms(),
            "events_by_source": dict(self.stats.events_by_source),
            "events_by_trigger": dict(self.stats.events_by_trigger),
            "queue_size": len(self.event_queue),
            "recent_events_count": len(self.recent_events),
        }

    def reset_stats(self) -> None:
        """Reset event processing statistics"""
        self.stats = EventProcessingStats()

    def _queue_event(self, event: CacheInvalidationEvent) -> None:
        """Queue event for processing with deduplication"""
        # Check if this is a duplicate recent event
        if self._is_duplicate_event(event):
            logger.debug(
                f"Skipping duplicate event: {event.entity_type}:{event.entity_id}"
            )
            return

        # Apply filters
        for filter_func in self.event_filters:
            try:
                if not filter_func(event):
                    logger.debug(
                        f"Event filtered out: {event.entity_type}:{event.entity_id}"
                    )
                    return
            except Exception as e:
                logger.error(f"Event filter error: {e}")

        # Add to queue
        self.event_queue.append(event)
        self.recent_events.append(event)

        logger.debug(
            f"Queued event: {event.trigger.value} for {event.entity_type}:{event.entity_id}"
        )

    def _is_duplicate_event(self, event: CacheInvalidationEvent) -> bool:
        """Check if event is a duplicate of a recent event"""
        from datetime import timedelta

        cutoff_time = event.timestamp - timedelta(
            milliseconds=self.deduplication_window_ms
        )

        for recent_event in reversed(self.recent_events):  # Check most recent first
            if recent_event.timestamp < cutoff_time:
                break  # No need to check older events

            if (
                recent_event.trigger == event.trigger
                and recent_event.entity_type == event.entity_type
                and recent_event.entity_id == event.entity_id
                and recent_event.client_account_id == event.client_account_id
                and recent_event.operation == event.operation
            ):
                return True

        return False
