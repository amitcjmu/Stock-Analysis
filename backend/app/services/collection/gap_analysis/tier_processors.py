"""Tier processing methods for gap analysis.

Contains tier_1 programmatic scan and tier_2 AI analysis implementations.
Split from service.py for file length compliance (<400 lines per file).
"""

import logging
from typing import Any, Dict, List

from sqlalchemy.ext.asyncio import AsyncSession

from app.services.persistent_agents.tenant_scoped_agent_pool import (
    TenantScopedAgentPool,
)

from .gap_persistence import persist_ai_questionnaires, persist_gaps
from .output_parser import parse_task_output
from .task_builder import build_task_description

logger = logging.getLogger(__name__)


class TierProcessorMixin:
    """Mixin providing tier processing methods for GapAnalysisService."""

    async def _run_tier_1_programmatic_scan(
        self, selected_asset_ids: List[str], collection_flow_id: str, db: AsyncSession
    ) -> Dict[str, Any]:
        """Run tier_1 programmatic gap scanner (fast, no AI)."""
        from app.services.collection.programmatic_gap_scanner import (
            ProgrammaticGapScanner,
        )

        scanner = ProgrammaticGapScanner()
        result = await scanner.scan_assets_for_gaps(
            selected_asset_ids=selected_asset_ids,
            collection_flow_id=collection_flow_id,
            client_account_id=self.client_account_id,
            engagement_id=self.engagement_id,
            db=db,
        )

        # Programmatic scanner returns different format, need to adapt
        # Scanner persists gaps internally and returns gaps list
        gaps_list = result.get("gaps", [])

        # Group gaps by priority for compatibility with existing format
        gaps_by_priority = {"critical": [], "high": [], "medium": [], "low": []}
        for gap in gaps_list:
            priority = gap.get("priority", 3)
            if priority == 1:
                gaps_by_priority["critical"].append(gap)
            elif priority == 2:
                gaps_by_priority["high"].append(gap)
            elif priority == 3:
                gaps_by_priority["medium"].append(gap)
            else:
                gaps_by_priority["low"].append(gap)

        return {
            "gaps": gaps_by_priority,
            "questionnaire": {
                "sections": []
            },  # Programmatic scanner doesn't generate questionnaires
            "summary": result.get("summary", {}),
        }

    async def _run_tier_2_ai_analysis(
        self, assets: List, collection_flow_id: str, db: AsyncSession
    ) -> Dict[str, Any]:
        """Run tier_2 AI agent analysis (slower, intelligent)."""
        logger.debug("üîß Creating persistent agent - Type: gap_analysis_specialist")
        agent = await TenantScopedAgentPool.get_or_create_agent(
            client_id=self.client_account_id,
            engagement_id=self.engagement_id,
            agent_type="gap_analysis_specialist",
        )
        logger.info(
            f"‚úÖ Agent created: {agent.role if hasattr(agent, 'role') else 'gap_analysis_specialist'}"
        )

        # Create and execute task
        task_description = build_task_description(assets)
        logger.debug(f"üìù Task description length: {len(task_description)} chars")

        task_output = await self._execute_agent_task(agent, task_description)
        logger.debug(f"üì§ Task output received: {str(task_output)[:200]}...")

        # Parse result
        result_dict = parse_task_output(task_output)
        total_gaps = sum(
            len(v) if isinstance(v, list) else 0
            for v in result_dict.get("gaps", {}).values()
        )
        questionnaire_sections = len(
            result_dict.get("questionnaire", {}).get("sections", [])
        )
        logger.info(
            f"üìä Parsed result - Gaps: {total_gaps}, "
            f"Questionnaire sections: {questionnaire_sections}"
        )

        # Persist gaps to database
        logger.debug("üíæ Persisting gaps to database...")
        gaps_count = await persist_gaps(result_dict, assets, db, collection_flow_id)
        result_dict["summary"]["gaps_persisted"] = gaps_count

        # ‚úÖ NEW: Persist AI-generated questionnaires to database
        questionnaire_sections = result_dict.get("questionnaire", {}).get(
            "sections", []
        )
        if questionnaire_sections and len(questionnaire_sections) > 0:
            logger.info(
                f"üíæ Persisting {len(questionnaire_sections)} AI-generated questionnaire sections..."
            )
            questionnaire_count = await persist_ai_questionnaires(
                result_dict=result_dict,
                collection_flow_id=collection_flow_id,
                db=db,
            )
            result_dict["summary"]["questionnaires_persisted"] = questionnaire_count
            logger.info(
                f"‚úÖ Persisted {questionnaire_count} AI-generated questionnaires"
            )
        else:
            logger.warning(
                "‚ö†Ô∏è No questionnaire sections generated by AI - skipping persistence"
            )
            result_dict["summary"]["questionnaires_persisted"] = 0

        return result_dict
