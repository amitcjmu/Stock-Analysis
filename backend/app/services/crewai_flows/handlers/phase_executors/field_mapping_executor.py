"""
Field Mapping Executor - Backward Compatibility Wrapper

This file maintains backward compatibility with existing code while using
the new modular field mapping executor implementation. The original complex
1207-line implementation has been modularized into specialized components
for better maintainability and reduced complexity.

The modular implementation is located at:
/backend/app/services/field_mapping_executor/

This wrapper ensures ZERO breaking changes while leveraging the new
architecture that provides:
- Reduced cyclomatic complexity (each module <400 lines, complexity <10)
- Better separation of concerns
- Improved testability
- Enhanced maintainability
- Cleaner error handling

For new code, consider importing directly from:
from app.services.field_mapping_executor import FieldMappingExecutor
"""

import logging
from typing import Any, Dict, List, Optional
from datetime import datetime

# Import the modular implementation
from app.services.field_mapping_executor import (
    FieldMappingExecutor as ModularFieldMappingExecutor,
)
from app.services.field_mapping_executor import (
    FieldMappingExecutorError,
    MappingParseError,
    ValidationError,
    CrewExecutionError,
    TransformationError,
)

# Import base executor for inheritance compatibility
from .base_phase_executor import BasePhaseExecutor

logger = logging.getLogger(__name__)

# CrewAI Flow availability detection for compatibility
CREWAI_FLOW_AVAILABLE = False
try:
    # Flow and LLM imports will be used when needed
    CREWAI_FLOW_AVAILABLE = True
    logger.info("âœ… CrewAI Flow and LLM imports available")
except ImportError as e:
    logger.warning(f"CrewAI Flow not available: {e}")
except Exception as e:
    logger.warning(f"CrewAI imports failed: {e}")


class FieldMappingExecutor(BasePhaseExecutor):
    """
    Backward compatibility wrapper for the modular FieldMappingExecutor.

    This class maintains the exact same interface as the original implementation
    while using the new modular architecture under the hood. It ensures zero
    breaking changes for existing code.

    The modular implementation provides:
    - Specialized parsers for different response formats
    - Comprehensive validation with multiple strategies
    - Intelligent mapping engine with similarity calculations
    - Robust transformation and database persistence
    - Business rules engine with clarification generation
    - Structured response formatting

    All functionality is preserved while significantly reducing complexity
    and improving maintainability.
    """

    def __init__(self, state, crew_manager, flow_bridge=None):
        """Initialize with backward compatibility support."""
        super().__init__(state, crew_manager, flow_bridge)

        # Extract context from state for modular executor
        client_account_id = getattr(state, "client_account_id", None)
        engagement_id = getattr(state, "engagement_id", None)

        # Initialize the modular executor with proper error handling
        # The modular executor will be used through our wrapper methods
        try:
            # Try to initialize with the fixed modular executor
            self._modular_executor = ModularFieldMappingExecutor(
                storage_manager=getattr(self, "storage_manager", None),
                agent_pool=getattr(self, "agent_pool", None),
                client_account_id=client_account_id or "unknown",
                engagement_id=engagement_id or "unknown",
            )
            logger.info("Successfully initialized modular executor")
        except Exception as e:
            logger.error(f"Could not initialize modular executor: {e}", exc_info=True)
            # Set to None and handle execution through fallback
            self._modular_executor = None

        logger.info(
            f"FieldMappingExecutor (compatibility wrapper) initialized for client {client_account_id}"
        )

    def get_phase_name(self) -> str:
        """Get the name of this phase - maintains compatibility."""
        return "attribute_mapping"

    def get_progress_percentage(self) -> float:
        """Get the progress percentage when this phase completes."""
        return 16.7  # 1/6 phases

    def _get_phase_timeout(self) -> Optional[int]:
        """Override timeout for field mapping - needs more time for LLM processing."""
        return 300  # 5 minutes for standard crew with multiple agents

    async def execute_with_crew(self, crew_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute field mapping using CrewAI crew - compatibility wrapper.

        This method maintains the original interface while using the modular
        implementation for actual execution.
        """
        try:
            logger.info(
                f"Executing field mapping with crew for engagement {self.engagement_id}"
            )

            # Create a mock state object from crew_input
            mock_state = self._convert_crew_input_to_state(crew_input)

            # Get async database session
            from app.db.session import get_db

            db_session_generator = get_db()
            db_session = await db_session_generator.__anext__()

            try:
                # Execute using modular implementation if available
                if self._modular_executor:
                    result = await self._modular_executor.execute_phase(
                        mock_state, db_session
                    )
                    # Convert result back to expected format
                    return self._convert_result_to_crew_format(result)
                else:
                    # Fallback execution when modular executor is not available
                    logger.warning(
                        "Modular executor not available, using direct crew execution"
                    )
                    result = await self._execute_with_crew_fallback(crew_input)
                    return result

            finally:
                await db_session.close()

        except Exception as e:
            logger.error(f"Field mapping execution failed: {str(e)}")
            # Return compatible error format
            return {
                "success": False,
                "error": str(e),
                "phase_name": self.get_phase_name(),
                "timestamp": datetime.utcnow().isoformat(),
            }

    def _convert_crew_input_to_state(self, crew_input: Dict[str, Any]) -> Any:
        """Convert legacy crew_input format to UnifiedDiscoveryFlowState."""
        from app.schemas.unified_discovery_flow_state import UnifiedDiscoveryFlowState

        # Extract data from crew_input
        engagement_id = getattr(self.state, "engagement_id", "unknown")
        client_account_id = getattr(self.state, "client_account_id", "unknown")
        flow_id = crew_input.get("flow_id", f"compat_{engagement_id}")
        discovery_data = crew_input.get("discovery_data", {})

        # Ensure discovery_data has required fields
        if "sample_data" not in discovery_data:
            discovery_data["sample_data"] = crew_input.get("sample_data", [])
        if "detected_columns" not in discovery_data:
            discovery_data["detected_columns"] = crew_input.get("detected_columns", [])
        if "data_source_info" not in discovery_data:
            discovery_data["data_source_info"] = crew_input.get("data_source_info", {})

        # Create state object
        mock_state = UnifiedDiscoveryFlowState(
            flow_id=flow_id,
            client_account_id=client_account_id,
            engagement_id=engagement_id,
            flow_type="unified_discovery",
            current_phase="field_mapping",
            discovery_data=discovery_data,
            field_mappings=crew_input.get("previous_mappings", []),
        )

        return mock_state

    def _convert_result_to_crew_format(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """Convert modular execution result to legacy crew format."""
        return {
            "success": result.get("success", True),
            "mappings": result.get("mappings", []),
            "confidence_scores": result.get("confidence_scores", {}),
            "clarifications": result.get("clarifications", []),
            "validation_errors": result.get("validation_errors", []),
            "phase_name": self.get_phase_name(),
            "next_phase": result.get("next_phase", "data_transformation"),
            "timestamp": result.get("timestamp", datetime.utcnow().isoformat()),
            "execution_metadata": result.get("execution_metadata", {}),
            "raw_response": result.get("raw_response", ""),
        }

    async def execute_field_mapping(
        self, flow_state: Any, db_session: Any
    ) -> Dict[str, Any]:
        """
        Direct execution method - maintains original interface.

        This method provides backward compatibility for code that calls
        execute_field_mapping directly instead of using the crew interface.
        """
        try:
            logger.info(
                f"Executing field mapping directly for flow {getattr(flow_state, 'flow_id', 'unknown')}"
            )

            # Use modular executor directly if available
            if self._modular_executor:
                result = await self._modular_executor.execute_phase(
                    flow_state, db_session
                )
            else:
                # Fallback to basic execution if modular executor not available
                logger.warning(
                    "Modular executor not available for direct execution, using basic execution"
                )
                # Convert flow_state to crew_input format and use fallback
                crew_input = {
                    "flow_id": getattr(flow_state, "flow_id", "unknown"),
                    "discovery_data": getattr(flow_state, "discovery_data", {}),
                    "sample_data": getattr(flow_state, "discovery_data", {}).get(
                        "sample_data", []
                    ),
                    "detected_columns": getattr(flow_state, "discovery_data", {}).get(
                        "detected_columns", []
                    ),
                    "data_source_info": getattr(flow_state, "discovery_data", {}).get(
                        "data_source_info", {}
                    ),
                    "previous_mappings": getattr(flow_state, "field_mappings", []),
                }
                result = await self._execute_with_crew_fallback(crew_input)

            logger.info("Field mapping completed successfully")
            return result

        except Exception as e:
            logger.error(f"Direct field mapping execution failed: {str(e)}")
            raise FieldMappingExecutorError(
                f"Field mapping execution failed: {str(e)}"
            ) from e

    # Additional compatibility methods
    def get_supported_flow_types(self) -> List[str]:
        """Return the flow types supported by this executor."""
        return ["unified_discovery", "field_mapping", "data_mapping"]

    async def validate_input(self, input_data: Dict[str, Any]) -> bool:
        """Validate input data for field mapping."""
        try:
            required_fields = ["sample_data", "detected_columns"]

            for field in required_fields:
                if field not in input_data:
                    logger.warning(f"Missing required field: {field}")
                    return False

            if not input_data.get("sample_data"):
                logger.warning("Empty sample_data provided")
                return False

            if not input_data.get("detected_columns"):
                logger.warning("Empty detected_columns provided")
                return False

            return True

        except Exception as e:
            logger.error(f"Input validation failed: {str(e)}")
            return False

    def get_execution_context(self) -> Dict[str, Any]:
        """Get execution context for field mapping."""
        return {
            "phase_name": self.get_phase_name(),
            "client_account_id": self.client_account_id,
            "engagement_id": self.engagement_id,
            "timeout": self._get_phase_timeout(),
            "crewai_available": CREWAI_FLOW_AVAILABLE,
            "modular_implementation": True,
            "backward_compatible": True,
        }

    def _prepare_crew_input(self) -> Dict[str, Any]:
        """Prepare input data for crew execution - required by BasePhaseExecutor."""
        try:
            # Extract data from the current state
            discovery_data = getattr(self.state, "discovery_data", {})
            field_mappings = getattr(self.state, "field_mappings", [])
            raw_data = getattr(self.state, "raw_data", [])

            crew_input = {
                "flow_id": getattr(self.state, "flow_id", None),
                "discovery_data": discovery_data,
                "sample_data": discovery_data.get("sample_data", raw_data),
                "detected_columns": discovery_data.get("detected_columns", []),
                "data_source_info": discovery_data.get("data_source_info", {}),
                "previous_mappings": field_mappings,
                "mapping_type": "field_mapping",
            }

            logger.info(
                f"Prepared crew input with {len(crew_input.get('sample_data', []))} sample records"
            )
            return crew_input

        except Exception as e:
            logger.error(f"Failed to prepare crew input: {str(e)}")
            # Return minimal valid input
            return {
                "flow_id": getattr(self.state, "flow_id", "unknown"),
                "discovery_data": {},
                "sample_data": [],
                "detected_columns": [],
                "data_source_info": {},
                "previous_mappings": [],
                "mapping_type": "field_mapping",
            }

    async def _store_results(self, results: Dict[str, Any]):
        """Store execution results in state - required by BasePhaseExecutor."""
        try:
            logger.info(
                f"Storing field mapping results with keys: {list(results.keys())}"
            )

            # Store mappings in state
            if "mappings" in results:
                self.state.field_mappings = results["mappings"]
                logger.info(f"Stored {len(results['mappings'])} field mappings")

            # Store confidence scores
            if "confidence_scores" in results:
                if not hasattr(self.state, "field_mapping_metadata"):
                    self.state.field_mapping_metadata = {}
                self.state.field_mapping_metadata["confidence_scores"] = results[
                    "confidence_scores"
                ]

            # Store clarifications
            if "clarifications" in results:
                if not hasattr(self.state, "field_mapping_metadata"):
                    self.state.field_mapping_metadata = {}
                self.state.field_mapping_metadata["clarifications"] = results[
                    "clarifications"
                ]

            # Store validation errors if any
            if "validation_errors" in results and results["validation_errors"]:
                logger.warning(
                    f"Field mapping validation errors: {results['validation_errors']}"
                )
                if not hasattr(self.state, "validation_errors"):
                    self.state.validation_errors = []
                self.state.validation_errors.extend(results["validation_errors"])

            # Store execution metadata
            if "execution_metadata" in results:
                if not hasattr(self.state, "field_mapping_metadata"):
                    self.state.field_mapping_metadata = {}
                self.state.field_mapping_metadata.update(results["execution_metadata"])

            logger.info("Field mapping results stored successfully in state")

        except Exception as e:
            logger.error(f"Failed to store field mapping results: {str(e)}")
            # Don't raise exception to avoid breaking the flow
            # Just log the error and continue

    async def execute_suggestions_only(
        self, input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Execute field mapping in suggestions-only mode for re-analysis."""
        try:
            logger.info("Executing field mapping in suggestions-only mode")

            # Prepare crew input with current state data
            crew_input = self._prepare_crew_input()

            # Override with any provided input data
            crew_input.update(input_data)

            # Execute field mapping with crew
            result = await self.execute_with_crew(crew_input)

            if result and result.get("success", True):
                logger.info("Field mapping suggestions generated successfully")
                return result
            else:
                logger.error(
                    f"Field mapping suggestions failed: {result.get('error', 'Unknown error')}"
                )
                return {
                    "success": False,
                    "error": result.get("error", "Field mapping suggestions failed"),
                    "mappings": [],
                    "clarifications": [],
                }

        except Exception as e:
            logger.error(f"Field mapping suggestions execution failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "mappings": [],
                "clarifications": [],
            }

    async def _execute_with_crew_fallback(
        self, crew_input: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Fallback execution when modular executor is not available."""
        try:
            logger.info("Executing field mapping fallback with direct crew manager")

            # Use the crew manager to create and execute a field mapping crew
            phase_name = self.get_phase_name()
            crew = self.crew_manager.create_crew_on_demand(phase_name)

            if not crew:
                raise RuntimeError(f"Could not create crew for {phase_name}")

            # Execute the crew with the input data
            # Note: This is a simplified fallback that may not have all the sophistication
            # of the modular executor, but it maintains basic functionality
            # CRITICAL FIX: Pass the timeout to avoid 15-second global timeout
            timeout = self._get_phase_timeout()
            logger.info(f"Executing crew with timeout: {timeout} seconds")

            # Set crew configuration with proper timeout
            crew.max_time = timeout
            crew_result = await crew.kickoff_async(inputs=crew_input)

            # Process the result into expected format
            if hasattr(crew_result, "raw") and crew_result.raw:
                # Try to parse structured response
                import json

                try:
                    if "{" in crew_result.raw and "}" in crew_result.raw:
                        start = crew_result.raw.find("{")
                        end = crew_result.raw.rfind("}") + 1
                        json_str = crew_result.raw[start:end]
                        parsed_result = json.loads(json_str)

                        return {
                            "success": True,
                            "mappings": parsed_result.get("mappings", []),
                            "confidence_scores": parsed_result.get(
                                "confidence_scores", {}
                            ),
                            "clarifications": parsed_result.get("clarifications", []),
                            "validation_errors": [],
                            "phase_name": phase_name,
                            "next_phase": "data_transformation",
                            "timestamp": datetime.utcnow().isoformat(),
                            "execution_metadata": {"fallback_used": True},
                            "raw_response": crew_result.raw,
                        }
                except json.JSONDecodeError:
                    pass

            # If we can't parse JSON, try to extract mappings from raw text
            logger.warning(
                "Could not parse JSON from crew result, attempting text extraction"
            )

            # Extract field mappings from raw text if available
            extracted_mappings = []
            if hasattr(crew_result, "raw") and crew_result.raw:
                # Look for patterns like "field_name -> target_field" or "field_name: target_field"
                import re

                lines = crew_result.raw.split("\n")
                for line in lines:
                    # Match patterns like "Device_ID -> asset_id" or "Device_ID: asset_id"
                    match = re.search(r"(\w+)\s*(?:->|:|=>|maps to)\s*(\w+)", line)
                    if match:
                        source_field = match.group(1)
                        target_field = match.group(2)
                        extracted_mappings.append(
                            {
                                "source_field": source_field,
                                "target_field": target_field,
                                "confidence": 0.7,  # Default confidence for text-extracted mappings
                                "status": "suggested",
                            }
                        )
                        logger.info(
                            f"Extracted mapping: {source_field} -> {target_field}"
                        )

            if extracted_mappings:
                logger.info(
                    f"Successfully extracted {len(extracted_mappings)} mappings from raw text"
                )
            else:
                logger.error("No mappings could be extracted from crew result")

            return {
                "success": True if extracted_mappings else False,
                "mappings": extracted_mappings,
                "confidence_scores": {},
                "clarifications": [],
                "validation_errors": (
                    []
                    if extracted_mappings
                    else ["No mappings extracted from crew result"]
                ),
                "phase_name": phase_name,
                "next_phase": "data_transformation",
                "timestamp": datetime.utcnow().isoformat(),
                "execution_metadata": {
                    "fallback_used": True,
                    "raw_result": str(crew_result),
                },
                "raw_response": str(crew_result),
            }

        except Exception as e:
            logger.error(f"Field mapping fallback execution failed: {str(e)}")
            return {
                "success": False,
                "error": f"Fallback execution failed: {str(e)}",
                "mappings": [],
                "clarifications": [],
                "validation_errors": [str(e)],
                "phase_name": self.get_phase_name(),
                "timestamp": datetime.utcnow().isoformat(),
            }


# Export original class name for complete backward compatibility
__all__ = [
    "FieldMappingExecutor",
    "FieldMappingExecutorError",
    "MappingParseError",
    "ValidationError",
    "CrewExecutionError",
    "TransformationError",
    "CREWAI_FLOW_AVAILABLE",
]

# Legacy aliases for backward compatibility
AttributeMappingExecutor = FieldMappingExecutor
MappingExecutor = FieldMappingExecutor
