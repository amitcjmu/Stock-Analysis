"""
Storage Manager Cache Manager Module

Provides caching strategies, performance monitoring, and intelligent
cache management for storage operations. This module handles cache
hierarchies, eviction policies, and cache warming strategies.
"""

import asyncio
import time
from collections import deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional

from app.core.logging import get_logger

from .base import BaseStorageBackend

logger = get_logger(__name__)


class CacheStrategy(str, Enum):
    """Cache strategy types"""

    LRU = "lru"  # Least Recently Used
    LFU = "lfu"  # Least Frequently Used
    FIFO = "fifo"  # First In, First Out
    TTL = "ttl"  # Time To Live based
    ADAPTIVE = "adaptive"  # Adaptive strategy based on usage patterns


class CacheLevel(str, Enum):
    """Cache hierarchy levels"""

    L1 = "l1"  # Fast in-memory cache
    L2 = "l2"  # Redis cache
    L3 = "l3"  # Database cache
    PERSISTENT = "persistent"  # Long-term storage


@dataclass
class CacheEntry:
    """Represents a cache entry with metadata"""

    key: str
    value: Any
    created_at: datetime = field(default_factory=datetime.utcnow)
    last_accessed: datetime = field(default_factory=datetime.utcnow)
    access_count: int = 0
    ttl: Optional[int] = None
    size_estimate: int = 0
    cache_level: CacheLevel = CacheLevel.L1
    metadata: Dict[str, Any] = field(default_factory=dict)

    @property
    def is_expired(self) -> bool:
        """Check if cache entry is expired"""
        if self.ttl is None:
            return False
        return datetime.utcnow() > self.created_at + timedelta(seconds=self.ttl)

    @property
    def age_seconds(self) -> float:
        """Get age of cache entry in seconds"""
        return (datetime.utcnow() - self.created_at).total_seconds()

    def touch(self):
        """Update access information"""
        self.last_accessed = datetime.utcnow()
        self.access_count += 1


@dataclass
class CachePerformanceMetrics:
    """Cache performance metrics"""

    hits: int = 0
    misses: int = 0
    evictions: int = 0
    invalidations: int = 0
    errors: int = 0
    total_requests: int = 0
    average_response_time_ms: float = 0.0
    cache_utilization: float = 0.0
    last_reset: datetime = field(default_factory=datetime.utcnow)

    @property
    def hit_rate(self) -> float:
        """Calculate cache hit rate as percentage"""
        if self.total_requests == 0:
            return 0.0
        return (self.hits / self.total_requests) * 100

    @property
    def miss_rate(self) -> float:
        """Calculate cache miss rate as percentage"""
        return 100.0 - self.hit_rate

    def reset(self):
        """Reset all metrics"""
        self.hits = 0
        self.misses = 0
        self.evictions = 0
        self.invalidations = 0
        self.errors = 0
        self.total_requests = 0
        self.average_response_time_ms = 0.0
        self.cache_utilization = 0.0
        self.last_reset = datetime.utcnow()


class CacheEvictionPolicy:
    """Base class for cache eviction policies"""

    def __init__(self, strategy: CacheStrategy = CacheStrategy.LRU):
        self.strategy = strategy

    def should_evict(self, entries: Dict[str, CacheEntry], max_size: int) -> List[str]:
        """Determine which keys should be evicted"""
        if len(entries) <= max_size:
            return []

        num_to_evict = len(entries) - max_size

        if self.strategy == CacheStrategy.LRU:
            return self._evict_lru(entries, num_to_evict)
        elif self.strategy == CacheStrategy.LFU:
            return self._evict_lfu(entries, num_to_evict)
        elif self.strategy == CacheStrategy.FIFO:
            return self._evict_fifo(entries, num_to_evict)
        elif self.strategy == CacheStrategy.TTL:
            return self._evict_ttl(entries, num_to_evict)
        elif self.strategy == CacheStrategy.ADAPTIVE:
            return self._evict_adaptive(entries, num_to_evict)
        else:
            return self._evict_lru(entries, num_to_evict)  # Default to LRU

    def _evict_lru(
        self, entries: Dict[str, CacheEntry], num_to_evict: int
    ) -> List[str]:
        """Evict least recently used entries"""
        sorted_entries = sorted(entries.items(), key=lambda x: x[1].last_accessed)
        return [key for key, _ in sorted_entries[:num_to_evict]]

    def _evict_lfu(
        self, entries: Dict[str, CacheEntry], num_to_evict: int
    ) -> List[str]:
        """Evict least frequently used entries"""
        sorted_entries = sorted(entries.items(), key=lambda x: x[1].access_count)
        return [key for key, _ in sorted_entries[:num_to_evict]]

    def _evict_fifo(
        self, entries: Dict[str, CacheEntry], num_to_evict: int
    ) -> List[str]:
        """Evict first in, first out entries"""
        sorted_entries = sorted(entries.items(), key=lambda x: x[1].created_at)
        return [key for key, _ in sorted_entries[:num_to_evict]]

    def _evict_ttl(
        self, entries: Dict[str, CacheEntry], num_to_evict: int
    ) -> List[str]:
        """Evict entries based on TTL (expired first, then closest to expiry)"""
        expired = [key for key, entry in entries.items() if entry.is_expired]

        if len(expired) >= num_to_evict:
            return expired[:num_to_evict]

        # If not enough expired entries, evict those closest to expiry
        non_expired = [
            (key, entry) for key, entry in entries.items() if not entry.is_expired
        ]
        sorted_by_expiry = sorted(
            non_expired,
            key=lambda x: x[1].created_at + timedelta(seconds=x[1].ttl or 3600),
        )

        remaining_to_evict = num_to_evict - len(expired)
        additional_evictions = [key for key, _ in sorted_by_expiry[:remaining_to_evict]]

        return expired + additional_evictions

    def _evict_adaptive(
        self, entries: Dict[str, CacheEntry], num_to_evict: int
    ) -> List[str]:
        """Adaptive eviction based on access patterns and age"""
        # First evict expired entries
        expired = [key for key, entry in entries.items() if entry.is_expired]

        if len(expired) >= num_to_evict:
            return expired[:num_to_evict]

        # Calculate eviction scores based on multiple factors
        scores = {}
        for key, entry in entries.items():
            if entry.is_expired:
                continue

            # Score based on: age, access frequency, and last access time
            age_score = entry.age_seconds / 3600  # Normalize to hours
            frequency_score = 1.0 / max(entry.access_count, 1)  # Lower is worse
            recency_score = (
                datetime.utcnow() - entry.last_accessed
            ).total_seconds() / 3600

            # Combined score (higher means more likely to evict)
            combined_score = age_score + frequency_score + recency_score
            scores[key] = combined_score

        # Sort by score and evict highest scoring entries
        sorted_by_score = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        remaining_to_evict = num_to_evict - len(expired)
        additional_evictions = [key for key, _ in sorted_by_score[:remaining_to_evict]]

        return expired + additional_evictions


class MultiLevelCache:
    """
    Multi-level cache manager with hierarchical storage.

    Implements a cache hierarchy with different levels (L1, L2, L3)
    each with different performance characteristics and capacity.
    """

    def __init__(
        self,
        l1_backend: Optional[BaseStorageBackend] = None,
        l2_backend: Optional[BaseStorageBackend] = None,
        l3_backend: Optional[BaseStorageBackend] = None,
        l1_max_size: int = 1000,
        l2_max_size: int = 10000,
        l3_max_size: int = 100000,
        eviction_strategy: CacheStrategy = CacheStrategy.LRU,
    ):
        self.backends = {
            CacheLevel.L1: l1_backend,
            CacheLevel.L2: l2_backend,
            CacheLevel.L3: l3_backend,
        }

        self.max_sizes = {
            CacheLevel.L1: l1_max_size,
            CacheLevel.L2: l2_max_size,
            CacheLevel.L3: l3_max_size,
        }

        self.eviction_policy = CacheEvictionPolicy(eviction_strategy)
        self.metrics = {level: CachePerformanceMetrics() for level in CacheLevel}

        # In-memory cache entries for tracking metadata
        self.cache_entries: Dict[CacheLevel, Dict[str, CacheEntry]] = {
            level: {} for level in CacheLevel
        }

        self._lock = asyncio.Lock()
        self._response_times = deque(maxlen=1000)  # Track recent response times

    async def get(self, key: str) -> Optional[Any]:
        """Get value from multi-level cache"""
        start_time = time.time()

        try:
            async with self._lock:
                # Try each cache level in order
                for level in [CacheLevel.L1, CacheLevel.L2, CacheLevel.L3]:
                    if self.backends[level] is None:
                        continue

                    metrics = self.metrics[level]
                    metrics.total_requests += 1

                    try:
                        # Check if we have metadata for this key
                        if key in self.cache_entries[level]:
                            entry = self.cache_entries[level][key]

                            # Check if expired
                            if entry.is_expired:
                                await self._invalidate_key(key, level)
                                metrics.invalidations += 1
                                continue

                            # Update access info
                            entry.touch()

                        # Try to get from backend
                        value = await self.backends[level].get(key)

                        if value is not None:
                            # Cache hit
                            metrics.hits += 1

                            # Promote to higher cache levels if not already there
                            await self._promote_to_higher_levels(key, value, level)

                            return value
                        else:
                            metrics.misses += 1

                    except Exception as e:
                        metrics.errors += 1
                        logger.error(f"Error getting key {key} from {level}: {e}")
                        continue

                # Not found in any cache level
                return None

        finally:
            # Track response time
            response_time = (time.time() - start_time) * 1000
            self._response_times.append(response_time)
            self._update_average_response_time()

    async def set(
        self,
        key: str,
        value: Any,
        ttl: Optional[int] = None,
        target_level: CacheLevel = CacheLevel.L1,
    ) -> bool:
        """Set value in multi-level cache"""
        start_time = time.time()

        try:
            async with self._lock:
                # Start from target level and propagate down
                success = False

                for level in [CacheLevel.L1, CacheLevel.L2, CacheLevel.L3]:
                    if level.value < target_level.value:
                        continue

                    if self.backends[level] is None:
                        continue

                    try:
                        # Check capacity and evict if necessary
                        await self._ensure_capacity(level)

                        # Set in backend
                        if await self.backends[level].set(key, value, ttl):
                            # Create cache entry metadata
                            entry = CacheEntry(
                                key=key,
                                value=value,
                                ttl=ttl,
                                cache_level=level,
                                size_estimate=len(str(value)),
                            )

                            self.cache_entries[level][key] = entry
                            success = True

                    except Exception as e:
                        self.metrics[level].errors += 1
                        logger.error(f"Error setting key {key} in {level}: {e}")
                        continue

                return success

        finally:
            response_time = (time.time() - start_time) * 1000
            self._response_times.append(response_time)
            self._update_average_response_time()

    async def delete(self, key: str) -> bool:
        """Delete value from all cache levels"""
        async with self._lock:
            success = False

            # Remove from all levels
            for level in [CacheLevel.L1, CacheLevel.L2, CacheLevel.L3]:
                if self.backends[level] is None:
                    continue

                try:
                    if await self.backends[level].delete(key):
                        success = True

                    # Remove metadata
                    if key in self.cache_entries[level]:
                        del self.cache_entries[level][key]
                        self.metrics[level].invalidations += 1

                except Exception as e:
                    self.metrics[level].errors += 1
                    logger.error(f"Error deleting key {key} from {level}: {e}")

            return success

    async def clear(self, level: Optional[CacheLevel] = None) -> bool:
        """Clear cache at specified level or all levels"""
        async with self._lock:
            levels_to_clear = (
                [level] if level else [CacheLevel.L1, CacheLevel.L2, CacheLevel.L3]
            )

            success = True
            for cache_level in levels_to_clear:
                if self.backends[cache_level] is None:
                    continue

                try:
                    if not await self.backends[cache_level].clear():
                        success = False

                    # Clear metadata
                    self.cache_entries[cache_level].clear()

                except Exception as e:
                    self.metrics[cache_level].errors += 1
                    logger.error(f"Error clearing {cache_level}: {e}")
                    success = False

            return success

    async def _promote_to_higher_levels(
        self, key: str, value: Any, current_level: CacheLevel
    ):
        """Promote frequently accessed items to higher cache levels"""
        higher_levels = []

        if current_level in [CacheLevel.L2, CacheLevel.L3]:
            higher_levels.append(CacheLevel.L1)
        if current_level == CacheLevel.L3:
            higher_levels.append(CacheLevel.L2)

        for level in higher_levels:
            if self.backends[level] is None:
                continue

            try:
                # Check if already exists in higher level
                if key not in self.cache_entries[level]:
                    await self._ensure_capacity(level)
                    await self.backends[level].set(key, value)

                    # Copy metadata from lower level
                    if key in self.cache_entries[current_level]:
                        original_entry = self.cache_entries[current_level][key]
                        new_entry = CacheEntry(
                            key=key,
                            value=value,
                            ttl=original_entry.ttl,
                            cache_level=level,
                            size_estimate=original_entry.size_estimate,
                        )
                        self.cache_entries[level][key] = new_entry

            except Exception as e:
                logger.error(f"Error promoting key {key} to {level}: {e}")

    async def _ensure_capacity(self, level: CacheLevel):
        """Ensure cache level has capacity for new entries"""
        max_size = self.max_sizes[level]
        entries = self.cache_entries[level]

        if len(entries) >= max_size:
            # Need to evict entries
            keys_to_evict = self.eviction_policy.should_evict(entries, max_size - 1)

            for key in keys_to_evict:
                await self._invalidate_key(key, level)
                self.metrics[level].evictions += 1

    async def _invalidate_key(self, key: str, level: CacheLevel):
        """Invalidate a key from specified cache level"""
        try:
            if self.backends[level] is not None:
                await self.backends[level].delete(key)

            if key in self.cache_entries[level]:
                del self.cache_entries[level][key]

        except Exception as e:
            logger.error(f"Error invalidating key {key} from {level}: {e}")

    def _update_average_response_time(self):
        """Update average response time across all levels"""
        if self._response_times:
            avg_time = sum(self._response_times) / len(self._response_times)
            for metrics in self.metrics.values():
                metrics.average_response_time_ms = avg_time

    async def get_performance_stats(self) -> Dict[str, Any]:
        """Get comprehensive performance statistics"""
        stats = {}

        for level, metrics in self.metrics.items():
            level_stats = {
                "hit_rate": metrics.hit_rate,
                "miss_rate": metrics.miss_rate,
                "total_requests": metrics.total_requests,
                "hits": metrics.hits,
                "misses": metrics.misses,
                "evictions": metrics.evictions,
                "invalidations": metrics.invalidations,
                "errors": metrics.errors,
                "average_response_time_ms": metrics.average_response_time_ms,
                "entry_count": len(self.cache_entries[level]),
                "max_size": self.max_sizes[level],
                "utilization": len(self.cache_entries[level])
                / self.max_sizes[level]
                * 100,
            }

            # Add backend-specific stats if available
            if self.backends[level] is not None:
                try:
                    backend_stats = self.backends[level].get_stats()
                    level_stats["backend_stats"] = backend_stats
                except Exception:
                    pass

            stats[level.value] = level_stats

        return stats

    async def health_check(self) -> Dict[str, Any]:
        """Perform health check on all cache levels"""
        health = {
            "overall_status": "healthy",
            "levels": {},
            "issues": [],
        }

        healthy_levels = 0
        total_levels = 0

        for level in [CacheLevel.L1, CacheLevel.L2, CacheLevel.L3]:
            if self.backends[level] is None:
                continue

            total_levels += 1

            try:
                level_health = await self.backends[level].health_check()
                health["levels"][level.value] = level_health

                if level_health.get("available", False):
                    healthy_levels += 1
                else:
                    health["issues"].append(f"{level.value} cache is not available")

            except Exception as e:
                health["levels"][level.value] = {
                    "available": False,
                    "error": str(e),
                }
                health["issues"].append(f"{level.value} cache health check failed: {e}")

        # Determine overall status
        if healthy_levels == 0:
            health["overall_status"] = "critical"
        elif healthy_levels < total_levels:
            health["overall_status"] = "degraded"

        return health


# Utility functions
def create_multi_level_cache(
    l1_backend: Optional[BaseStorageBackend] = None,
    l2_backend: Optional[BaseStorageBackend] = None,
    l3_backend: Optional[BaseStorageBackend] = None,
    **kwargs,
) -> MultiLevelCache:
    """Factory function to create multi-level cache"""
    return MultiLevelCache(
        l1_backend=l1_backend, l2_backend=l2_backend, l3_backend=l3_backend, **kwargs
    )
