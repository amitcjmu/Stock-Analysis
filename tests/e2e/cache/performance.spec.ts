/**
 * Cache Performance Test Suite
 *
 * Performance validation tests to ensure caching implementation achieves:
 * - 70%+ reduction in API calls
 * - 50%+ reduction in page load times
 * - Sub-50ms cache response times
 * - Efficient memory usage
 * - High cache hit ratios
 *
 * Generated by CC (Claude Code)
 */

import { test, expect, Page } from '@playwright/test';
import { PerformanceMonitor } from './utils/performance-monitor';
import { CacheTestUtils } from './utils/cache-test-utils';

test.describe('Cache Performance', () => {
  let monitor: PerformanceMonitor;
  let cacheUtils: CacheTestUtils;
  let page: Page;

  test.beforeEach(async ({ page: testPage }) => {
    page = testPage;
    monitor = new PerformanceMonitor(page);
    cacheUtils = new CacheTestUtils(page);

    await monitor.startMonitoring();
    await cacheUtils.clearAllCaches();

    // Set up authentication
    await page.goto('/login');
    await page.fill('[data-testid="email-input"]', 'demo@example.com');
    await page.fill('[data-testid="password-input"]', 'demo123');
    await page.click('[data-testid="login-button"]');
    await page.waitForURL('**/dashboard', { timeout: 10000 });
  });

  test.afterEach(async () => {
    monitor.stopMonitoring();
    cacheUtils.cleanup();

    const metrics = await monitor.getMetrics();
    console.log('Performance Metrics:', {
      totalApiCalls: metrics.totalApiCalls,
      cacheHitRatio: `${(metrics.cacheHitRatio * 100).toFixed(1)}%`,
      averageResponseTime: `${metrics.averageResponseTime.toFixed(1)}ms`,
      pageLoadTime: `${metrics.pageLoadTime.toFixed(0)}ms`
    });
  });

  test('should reduce API calls by 70% with caching enabled', async () => {
    // Test journey: Dashboard -> Discovery -> Field Mappings -> Back to Dashboard
    const testJourney = [
      '/dashboard',
      '/discovery/flows',
      '/discovery/field-mappings',
      '/dashboard'  // Return to trigger cache hits
    ];

    // Phase 1: Baseline measurement without cache
    await cacheUtils.setFeatureFlags({
      USE_REDIS_CACHE: false,
      USE_BROWSER_CACHE: false
    });

    await page.reload();
    monitor.reset();
    await monitor.startMonitoring();

    // Execute journey without cache
    for (const url of testJourney) {
      await page.goto(url);
      await page.waitForLoadState('networkidle');
      await page.waitForTimeout(1000); // Allow time for API calls
    }

    const baselineMetrics = await monitor.captureBaseline();
    console.log('Baseline API calls (no cache):', baselineMetrics.totalApiCalls);

    // Phase 2: Measurement with cache enabled
    await cacheUtils.setFeatureFlags({
      USE_REDIS_CACHE: true,
      USE_BROWSER_CACHE: true
    });

    await page.reload();
    await cacheUtils.clearAllCaches();
    monitor.reset();
    await monitor.startMonitoring();

    // Execute same journey with cache
    for (const url of testJourney) {
      await page.goto(url);
      await page.waitForLoadState('networkidle');
      await page.waitForTimeout(1000); // Allow time for cache operations
    }

    const cachedMetrics = await monitor.getMetrics();
    console.log('Cached API calls:', cachedMetrics.totalApiCalls);

    // Calculate reduction
    const apiCallReduction = baselineMetrics.totalApiCalls > 0
      ? 1 - (cachedMetrics.totalApiCalls / baselineMetrics.totalApiCalls)
      : 0;

    console.log(`API call reduction: ${(apiCallReduction * 100).toFixed(1)}%`);

    // Verify 70% reduction target
    expect(apiCallReduction).toBeGreaterThanOrEqual(0.7);
    expect(cachedMetrics.cacheHitRatio).toBeGreaterThanOrEqual(0.6);
  });

  test('should reduce page load time by 50%', async () => {
    const testUrl = '/discovery/field-mappings';

    // Measure cold load time (cache miss)
    await cacheUtils.clearAllCaches();
    const coldLoadTime = await monitor.measurePageLoad(testUrl);
    console.log(`Cold load time: ${coldLoadTime}ms`);

    // Measure warm load time (cache hit)
    const warmLoadTime = await monitor.measurePageLoad(testUrl);
    console.log(`Warm load time: ${warmLoadTime}ms`);

    // Calculate improvement
    const loadTimeImprovement = coldLoadTime > 0
      ? (coldLoadTime - warmLoadTime) / coldLoadTime
      : 0;

    console.log(`Page load improvement: ${(loadTimeImprovement * 100).toFixed(1)}%`);

    // Verify 50% improvement target
    expect(loadTimeImprovement).toBeGreaterThanOrEqual(0.5);
    expect(warmLoadTime).toBeLessThan(coldLoadTime);
  });

  test('should achieve sub-50ms cache response times', async () => {
    const endpoints = [
      '/api/v1/cached-context/me',
      '/api/v1/cached-context/clients',
      '/api/v1/cached-context/engagements?client_id=demo-client'
    ];

    // Prime the cache
    for (const endpoint of endpoints) {
      await page.request.get(endpoint, {
        headers: { 'X-Client-Account-ID': 'demo-client' }
      });
    }

    // Measure cached response times
    const responseTimesMs: number[] = [];

    for (const endpoint of endpoints) {
      const startTime = Date.now();
      const response = await page.request.get(endpoint, {
        headers: { 'X-Client-Account-ID': 'demo-client' }
      });
      const responseTime = Date.now() - startTime;

      expect(response.status()).toBe(200);
      expect(response.headers()['x-cache']).toBe('HIT');

      responseTimesMs.push(responseTime);
    }

    const avgResponseTime = responseTimesMs.reduce((sum, time) => sum + time, 0) / responseTimesMs.length;
    console.log(`Average cached response time: ${avgResponseTime.toFixed(1)}ms`);

    // Verify sub-50ms target for cached responses
    expect(avgResponseTime).toBeLessThan(50);

    // All individual responses should be fast
    responseTimesMs.forEach(time => {
      expect(time).toBeLessThan(100); // Allow some tolerance for network variance
    });
  });

  test('should maintain high cache hit ratio under concurrent load', async () => {
    const endpoint = '/api/v1/cached-context/me';
    const headers = { 'X-Client-Account-ID': 'demo-client' };

    // Prime the cache
    await page.request.get(endpoint, { headers });

    // Test concurrent requests
    const concurrentUsers = 10;
    const requestsPerUser = 5;

    const allRequests = [];
    for (let user = 0; user < concurrentUsers; user++) {
      for (let req = 0; req < requestsPerUser; req++) {
        allRequests.push(
          page.request.get(endpoint, { headers })
        );
      }
    }

    const startTime = Date.now();
    const responses = await Promise.all(allRequests);
    const totalTime = Date.now() - startTime;

    // Analyze results
    const successfulResponses = responses.filter(r => r.status() === 200);
    const cacheHits = responses.filter(r => r.headers()['x-cache'] === 'HIT');
    const hitRatio = cacheHits.length / successfulResponses.length;

    console.log(`Concurrent load test: ${successfulResponses.length} requests in ${totalTime}ms`);
    console.log(`Cache hit ratio under load: ${(hitRatio * 100).toFixed(1)}%`);

    // Verify performance under load
    expect(successfulResponses.length).toBe(allRequests.length);
    expect(hitRatio).toBeGreaterThanOrEqual(0.8); // 80% hit ratio under load
    expect(totalTime).toBeLessThan(5000); // Complete within 5 seconds
  });

  test('should demonstrate memory efficiency with caching', async () => {
    // Get initial memory usage
    const initialMemory = await page.evaluate(() => {
      if ('memory' in performance) {
        const mem = (performance as any).memory;
        return {
          used: mem.usedJSHeapSize,
          total: mem.totalJSHeapSize
        };
      }
      return null;
    });

    if (!initialMemory) {
      console.log('Memory API not available, skipping memory test');
      return;
    }

    // Load multiple pages with caching
    const pages = [
      '/dashboard',
      '/discovery/flows',
      '/discovery/field-mappings',
      '/admin/clients'
    ];

    for (const pagePath of pages) {
      await page.goto(pagePath);
      await page.waitForLoadState('networkidle');

      // Make additional API calls to populate cache
      try {
        await page.request.get('/api/v1/cached-context/me', {
          headers: { 'X-Client-Account-ID': 'demo-client' }
        });
        await page.request.get('/api/v1/cached-context/clients', {
          headers: { 'X-Client-Account-ID': 'demo-client' }
        });
      } catch (error) {
        console.log('API call failed:', error);
      }
    }

    // Get final memory usage
    const finalMemory = await page.evaluate(() => {
      if ('memory' in performance) {
        const mem = (performance as any).memory;
        return {
          used: mem.usedJSHeapSize,
          total: mem.totalJSHeapSize
        };
      }
      return null;
    });

    if (finalMemory) {
      const memoryIncrease = finalMemory.used - initialMemory.used;
      const memoryIncreasePercent = (memoryIncrease / initialMemory.used) * 100;

      console.log(`Memory increase: ${(memoryIncrease / 1024 / 1024).toFixed(1)}MB (${memoryIncreasePercent.toFixed(1)}%)`);

      // Memory usage should be reasonable (less than 50MB increase)
      expect(memoryIncrease).toBeLessThan(50 * 1024 * 1024); // 50MB
    }
  });

  test('should optimize network usage with efficient caching', async () => {
    const testEndpoints = [
      '/api/v1/cached-context/me',
      '/api/v1/cached-context/clients',
    ];

    // Phase 1: Measure network usage without cache
    await cacheUtils.setFeatureFlags({ USE_REDIS_CACHE: false });
    await page.reload();

    let totalUncachedBytes = 0;
    for (const endpoint of testEndpoints) {
      const response = await page.request.get(endpoint, {
        headers: { 'X-Client-Account-ID': 'demo-client' }
      });
      const contentLength = parseInt(response.headers()['content-length'] || '0');
      totalUncachedBytes += contentLength;
    }

    // Phase 2: Measure network usage with cache
    await cacheUtils.setFeatureFlags({ USE_REDIS_CACHE: true });
    await page.reload();
    await cacheUtils.clearAllCaches();

    let totalCachedBytes = 0;
    // First requests (cache misses)
    for (const endpoint of testEndpoints) {
      const response = await page.request.get(endpoint, {
        headers: { 'X-Client-Account-ID': 'demo-client' }
      });
      const contentLength = parseInt(response.headers()['content-length'] || '0');
      totalCachedBytes += contentLength;
    }

    // Second requests (cache hits - should use minimal network)
    for (const endpoint of testEndpoints) {
      const response = await page.request.get(endpoint, {
        headers: {
          'X-Client-Account-ID': 'demo-client',
          'If-None-Match': response.headers()['etag'] // This should trigger 304
        }
      });

      if (response.status() === 304) {
        // 304 responses have minimal content
        totalCachedBytes += 0;
      } else {
        const contentLength = parseInt(response.headers()['content-length'] || '0');
        totalCachedBytes += contentLength;
      }
    }

    console.log(`Network usage - Uncached: ${totalUncachedBytes} bytes, Cached: ${totalCachedBytes} bytes`);

    // Network usage should be reduced with caching (accounting for 304 responses)
    expect(totalCachedBytes).toBeLessThanOrEqual(totalUncachedBytes * 1.5); // Allow some tolerance
  });

  test('should handle cache performance under different network conditions', async () => {
    const endpoint = '/api/v1/cached-context/me';
    const headers = { 'X-Client-Account-ID': 'demo-client' };

    // Test under slow network conditions
    await cacheUtils.simulateNetworkConditions(
      100000,  // 100 KB/s download
      50000,   // 50 KB/s upload
      200      // 200ms latency
    );

    // Prime cache under slow conditions
    const slowResponse1 = await page.request.get(endpoint, { headers });
    expect(slowResponse1.status()).toBe(200);

    // Cached response should be much faster despite slow network
    const startTime = Date.now();
    const slowResponse2 = await page.request.get(endpoint, { headers });
    const cachedResponseTime = Date.now() - startTime;

    expect(slowResponse2.status()).toBe(200);
    expect(slowResponse2.headers()['x-cache']).toBe('HIT');

    // Cached response should be fast even on slow network
    expect(cachedResponseTime).toBeLessThan(100);

    // Reset network conditions
    await cacheUtils.resetNetworkConditions();
  });

  test('should provide detailed performance metrics', async () => {
    // Execute a typical user workflow
    await page.goto('/dashboard');
    await page.waitForLoadState('networkidle');

    await page.goto('/discovery/flows');
    await page.waitForLoadState('networkidle');

    await page.goto('/dashboard'); // Back to dashboard for cache hits
    await page.waitForLoadState('networkidle');

    // Get comprehensive metrics
    const metrics = await monitor.getMetrics();
    const endpointBreakdown = monitor.getEndpointBreakdown();

    // Validate metric completeness
    expect(metrics.totalApiCalls).toBeGreaterThan(0);
    expect(metrics.cacheHitRatio).toBeGreaterThanOrEqual(0);
    expect(metrics.averageResponseTime).toBeGreaterThan(0);

    // Check endpoint breakdown
    expect(Object.keys(endpointBreakdown).length).toBeGreaterThan(0);

    // Log detailed metrics for analysis
    console.log('Detailed Performance Metrics:');
    console.log('- Total API calls:', metrics.totalApiCalls);
    console.log('- Cache hit ratio:', `${(metrics.cacheHitRatio * 100).toFixed(1)}%`);
    console.log('- Average response time:', `${metrics.averageResponseTime.toFixed(1)}ms`);
    console.log('- Endpoint breakdown:', endpointBreakdown);

    // Performance should meet targets
    expect(metrics.averageResponseTime).toBeLessThan(500); // Average under 500ms
    if (metrics.totalApiCalls > 5) {
      expect(metrics.cacheHitRatio).toBeGreaterThan(0.3); // Some cache efficiency
    }
  });

  test('should generate comprehensive performance report', async () => {
    // Execute test workflow
    const workflows = [
      ['/dashboard', '/discovery/flows'],
      ['/discovery/field-mappings', '/dashboard'],
      ['/admin/clients', '/dashboard']
    ];

    for (const workflow of workflows) {
      for (const url of workflow) {
        await page.goto(url);
        await page.waitForLoadState('networkidle');
        await page.waitForTimeout(500);
      }
    }

    // Generate performance comparison report
    const baselineMetrics = await monitor.getMetrics();
    // Simulate improved metrics for comparison
    const improvedMetrics = {
      ...baselineMetrics,
      totalApiCalls: Math.floor(baselineMetrics.totalApiCalls * 0.3), // 70% reduction
      pageLoadTime: baselineMetrics.pageLoadTime * 0.5, // 50% improvement
      cacheHitRatio: 0.85 // 85% hit ratio
    };

    const report = monitor.generateComparisonReport(improvedMetrics, baselineMetrics);

    expect(report).toHaveProperty('apiCallReduction');
    expect(report).toHaveProperty('pageLoadImprovement');
    expect(report).toHaveProperty('cacheHitRatio');
    expect(report).toHaveProperty('recommendations');

    console.log('Performance Report:', report);
  });
});
