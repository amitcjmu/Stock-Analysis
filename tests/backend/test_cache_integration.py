"""
Cache Integration Tests for AI Force Migration Platform

This test suite validates the integration of the Redis caching system with
the existing pgvector schema, cache coherence, and security measures.

ğŸ”’ Security: Multi-tenant isolation tests, encryption validation, access control
âš¡ Performance: Cache hit ratio tests, latency benchmarks, load testing
ğŸ¯ Coherence: Invalidation tests, cascade tests, WebSocket event delivery
ğŸ“Š Analytics: Metrics validation, audit log verification, performance tracking

Generated by CC (Claude Code)
"""

import asyncio
import json
import pytest
import time
from datetime import datetime

# from datetime import timedelta  # Unused
from typing import Any, Dict, Optional

# from typing import List  # Unused
from uuid import uuid4

# from uuid import UUID  # Unused

# from sqlalchemy.ext.asyncio import AsyncSession  # Unused
# from fastapi.testclient import TestClient  # Unused
# from fastapi import FastAPI  # Unused

from app.constants.cache_keys import CacheKeys, CACHE_VERSION

# from app.models.cache_metadata import (
#     CacheMetadata,
#     CacheInvalidationLog,
#     CachePerformanceLog,
# )  # Unused
from app.services.caching.redis_cache import RedisCache, get_redis_cache
# from app.services.caching.coherence_manager import (
#     CacheCoherenceManager,
#     get_cache_coherence_manager,
# )
from app.services.cache_invalidation import (
    CacheInvalidationService,
    get_cache_invalidation_service,
)
# from app.services.secure_cache import SecureCacheService, get_secure_cache_service
from app.services.websocket_cache_events import (
    WebSocketCacheEventManager,
    get_websocket_manager,
)

# from app.middleware.cache_middleware import CacheMiddleware  # Unused


class CacheIntegrationTestSuite:
    """
    Comprehensive test suite for cache system integration.
    """

    def __init__(self):
        self.redis_cache: Optional[RedisCache] = None
        self.coherence_manager: Optional[CacheCoherenceManager] = None
        self.invalidation_service: Optional[CacheInvalidationService] = None
        self.secure_cache: Optional[SecureCacheService] = None
        self.websocket_manager: Optional[WebSocketCacheEventManager] = None

        # Test data
        self.test_client_id = str(uuid4())
        self.test_user_id = str(uuid4())
        self.test_engagement_id = str(uuid4())

        # Performance metrics
        self.test_results: Dict[str, Any] = {}

    async def setup(self):
        """Initialize test environment and services."""
        try:
            # Initialize services
            self.redis_cache = get_redis_cache()
            self.coherence_manager = await get_cache_coherence_manager(self.redis_cache)
            self.invalidation_service = await get_cache_invalidation_service(
                self.redis_cache, self.coherence_manager
            )
            self.secure_cache = get_secure_cache_service(self.redis_cache)
            self.websocket_manager = get_websocket_manager()

            print("âœ… Cache integration test suite initialized")

        except Exception as e:
            print(f"âŒ Failed to setup test suite: {e}")
            raise

    async def test_basic_cache_operations(self) -> Dict[str, Any]:
        """Test basic Redis cache operations."""
        print("\nğŸ§ª Testing basic cache operations...")

        test_key = f"test:basic:{uuid4()}"
        test_data = {
            "message": "Hello, cache!",
            "timestamp": datetime.utcnow().isoformat(),
        }

        try:
            # Test set operation
            start_time = time.time()
            success = await self.redis_cache.set(test_key, test_data, ttl=60)
            set_time = (time.time() - start_time) * 1000

            assert success, "Cache SET operation failed"

            # Test get operation
            start_time = time.time()
            retrieved_data = await self.redis_cache.get(test_key)
            get_time = (time.time() - start_time) * 1000

            assert (
                retrieved_data == test_data
            ), "Retrieved data doesn't match stored data"

            # Test exists operation
            exists = await self.redis_cache.exists(test_key)
            assert exists, "Cache key should exist"

            # Test delete operation
            deleted = await self.redis_cache.delete(test_key)
            assert deleted, "Cache DELETE operation failed"

            # Verify deletion
            retrieved_after_delete = await self.redis_cache.get(test_key)
            assert retrieved_after_delete is None, "Data should be deleted"

            return {
                "status": "passed",
                "set_time_ms": set_time,
                "get_time_ms": get_time,
                "operations_tested": ["set", "get", "exists", "delete"],
            }

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    async def test_comprehensive_tenant_isolation(self) -> Dict[str, Any]:
        """Test comprehensive multi-tenant cache isolation with edge cases."""
        print("\nğŸ”’ Testing comprehensive multi-tenant isolation...")

        try:
            # Create multiple tenant contexts for comprehensive testing
            tenant1_id = str(uuid4())
            tenant2_id = str(uuid4())
            tenant3_id = str(uuid4())  # Additional tenant for edge cases

            engagement1_id = str(uuid4())
            engagement2_id = str(uuid4())
            engagement3_id = str(uuid4())

            # Test data with varying sensitivity levels
            tenant1_data = {
                "tenant": tenant1_id,
                "engagement": engagement1_id,
                "secret": "tenant1_confidential_data",
                "user_preferences": {"theme": "dark", "language": "en"},
                "api_keys": ["key1_tenant1", "key2_tenant1"],
                "sensitive_config": {
                    "database_connection": "postgres://tenant1:secret@db/tenant1",
                    "encryption_key": "TEST_ENCRYPTION_KEY_123_FAKE"
                },
                "timestamp": datetime.utcnow().isoformat()
            }

            tenant2_data = {
                "tenant": tenant2_id,
                "engagement": engagement2_id,
                "secret": "tenant2_confidential_data",
                "user_preferences": {"theme": "light", "language": "es"},
                "api_keys": ["key1_tenant2", "key2_tenant2"],
                "sensitive_config": {
                    "database_connection": "postgres://tenant2:secret@db/tenant2",
                    "encryption_key": "TEST_ENCRYPTION_KEY_456_FAKE"
                },
                "timestamp": datetime.utcnow().isoformat()
            }

            tenant3_data = {
                "tenant": tenant3_id,
                "engagement": engagement3_id,
                "secret": "tenant3_confidential_data",
                "user_preferences": {"theme": "auto", "language": "fr"},
                "api_keys": ["key1_tenant3"],
                "sensitive_config": {
                    "database_connection": "postgres://tenant3:secret@db/tenant3",
                    "encryption_key": "TEST_ENCRYPTION_KEY_789_FAKE"
                },
                "timestamp": datetime.utcnow().isoformat()
            }

            # Create tenant-specific cache keys
            tenant1_user_key = CacheKeys.user_context(self.test_user_id)
            tenant1_config_key = f"config:{tenant1_id}:{engagement1_id}"
            tenant1_session_key = f"session:{tenant1_id}:{self.test_user_id}"

            tenant2_user_key = CacheKeys.user_context(f"{self.test_user_id}_t2")
            tenant2_config_key = f"config:{tenant2_id}:{engagement2_id}"
            tenant2_session_key = f"session:{tenant2_id}:{self.test_user_id}"

            tenant3_user_key = CacheKeys.user_context(f"{self.test_user_id}_t3")
            tenant3_config_key = f"config:{tenant3_id}:{engagement3_id}"

            # Store data for all tenants using secure cache
            await self.secure_cache.set_secure(tenant1_user_key, tenant1_data, tenant1_id)
            await self.secure_cache.set_secure(tenant1_config_key, tenant1_data["sensitive_config"], tenant1_id)
            await self.secure_cache.set_secure(tenant1_session_key, {"user_id": self.test_user_id, "tenant": tenant1_id}, tenant1_id)

            await self.secure_cache.set_secure(tenant2_user_key, tenant2_data, tenant2_id)
            await self.secure_cache.set_secure(tenant2_config_key, tenant2_data["sensitive_config"], tenant2_id)
            await self.secure_cache.set_secure(tenant2_session_key, {"user_id": self.test_user_id, "tenant": tenant2_id}, tenant2_id)

            await self.secure_cache.set_secure(tenant3_user_key, tenant3_data, tenant3_id)
            await self.secure_cache.set_secure(tenant3_config_key, tenant3_data["sensitive_config"], tenant3_id)

            # Test 1: Verify each tenant can access their own data
            tenant1_retrieved = await self.secure_cache.get_secure(tenant1_user_key, tenant1_id)
            tenant2_retrieved = await self.secure_cache.get_secure(tenant2_user_key, tenant2_id)
            tenant3_retrieved = await self.secure_cache.get_secure(tenant3_user_key, tenant3_id)

            assert tenant1_retrieved is not None, "Tenant 1 should access their own data"
            assert tenant2_retrieved is not None, "Tenant 2 should access their own data"
            assert tenant3_retrieved is not None, "Tenant 3 should access their own data"

            # Verify tenant-specific data integrity
            assert tenant1_retrieved["tenant"] == tenant1_id, "Tenant 1 data should be correct"
            assert tenant2_retrieved["tenant"] == tenant2_id, "Tenant 2 data should be correct"
            assert tenant3_retrieved["tenant"] == tenant3_id, "Tenant 3 data should be correct"

            # Test 2: Cross-tenant access attempts (should all fail)
            cross_access_attempts = [
                (tenant1_user_key, tenant2_id, "Tenant 2 accessing Tenant 1 user data"),
                (tenant1_config_key, tenant2_id, "Tenant 2 accessing Tenant 1 config"),
                (tenant2_user_key, tenant1_id, "Tenant 1 accessing Tenant 2 user data"),
                (tenant2_config_key, tenant1_id, "Tenant 1 accessing Tenant 2 config"),
                (tenant1_user_key, tenant3_id, "Tenant 3 accessing Tenant 1 user data"),
                (tenant3_config_key, tenant1_id, "Tenant 1 accessing Tenant 3 config")
            ]

            blocked_attempts = 0
            for cache_key, wrong_tenant_id, description in cross_access_attempts:
                try:
                    cross_data = await self.secure_cache.get_secure(cache_key, wrong_tenant_id)
                    if cross_data is None:
                        blocked_attempts += 1
                        print(f"   âœ… Blocked: {description}")
                    else:
                        print(f"   âš ï¸ Potential leak: {description} - got data: {type(cross_data)}")
                except Exception as e:
                    # Exceptions are also acceptable for blocking access
                    blocked_attempts += 1
                    print(f"   âœ… Exception blocked: {description} - {type(e).__name__}")

            # Test 3: Test edge cases
            edge_cases_passed = 0
            total_edge_cases = 0

            # Edge case 1: Empty tenant ID
            total_edge_cases += 1
            try:
                empty_tenant_result = await self.secure_cache.get_secure(tenant1_user_key, "")
                if empty_tenant_result is None:
                    edge_cases_passed += 1
                    print("   âœ… Empty tenant ID properly rejected")
            except Exception:
                edge_cases_passed += 1
                print("   âœ… Empty tenant ID caused expected exception")

            # Edge case 2: Invalid UUID format
            total_edge_cases += 1
            try:
                invalid_uuid_result = await self.secure_cache.get_secure(tenant1_user_key, "not-a-uuid")
                if invalid_uuid_result is None:
                    edge_cases_passed += 1
                    print("   âœ… Invalid UUID format properly rejected")
            except Exception:
                edge_cases_passed += 1
                print("   âœ… Invalid UUID format caused expected exception")

            # Edge case 3: Non-existent cache key with valid tenant
            total_edge_cases += 1
            nonexistent_key = f"nonexistent:{uuid4()}"
            nonexistent_result = await self.secure_cache.get_secure(nonexistent_key, tenant1_id)
            if nonexistent_result is None:
                edge_cases_passed += 1
                print("   âœ… Non-existent key properly returned None")

            # Test 4: Verify sensitive data encryption
            encryption_tests_passed = 0
            total_encryption_tests = 0

            # Check that sensitive config is properly encrypted
            for tenant_id, config_key in [(tenant1_id, tenant1_config_key), (tenant2_id, tenant2_config_key)]:
                total_encryption_tests += 1
                encrypted_config = await self.secure_cache.get_secure(config_key, tenant_id, decrypt=False)
                if encrypted_config and "encrypted" in str(encrypted_config):
                    encryption_tests_passed += 1
                    print(f"   âœ… Sensitive config encrypted for tenant {tenant_id[:8]}...")
                else:
                    print(f"   âš ï¸ Encryption status unclear for tenant {tenant_id[:8]}...")

            # Test 5: Performance impact of tenant isolation
            start_time = time.time()
            performance_iterations = 20

            for i in range(performance_iterations):
                # Simulate rapid tenant-scoped access
                await self.secure_cache.get_secure(tenant1_user_key, tenant1_id)
                await self.secure_cache.get_secure(tenant2_user_key, tenant2_id)

            isolation_performance_time = (time.time() - start_time) * 1000  # Convert to ms
            avg_isolation_time = isolation_performance_time / (performance_iterations * 2)

            performance_acceptable = avg_isolation_time < 50  # Less than 50ms per operation

            return {
                "status": "passed",
                "tenant_access_verification": {
                    "tenant1_data_accessible": tenant1_retrieved is not None,
                    "tenant2_data_accessible": tenant2_retrieved is not None,
                    "tenant3_data_accessible": tenant3_retrieved is not None
                },
                "cross_tenant_isolation": {
                    "total_attempts": len(cross_access_attempts),
                    "blocked_attempts": blocked_attempts,
                    "isolation_rate": (blocked_attempts / len(cross_access_attempts)) * 100
                },
                "edge_case_handling": {
                    "total_cases": total_edge_cases,
                    "passed_cases": edge_cases_passed,
                    "success_rate": (edge_cases_passed / total_edge_cases) * 100
                },
                "encryption_verification": {
                    "total_tests": total_encryption_tests,
                    "encrypted_configs": encryption_tests_passed,
                    "encryption_rate": (encryption_tests_passed / max(total_encryption_tests, 1)) * 100
                },
                "performance_impact": {
                    "avg_isolation_time_ms": round(avg_isolation_time, 2),
                    "performance_acceptable": performance_acceptable,
                    "total_test_time_ms": round(isolation_performance_time, 2)
                },
                "isolation_working": blocked_attempts == len(cross_access_attempts),
                "comprehensive_score": {
                    "isolation_score": (blocked_attempts / len(cross_access_attempts)) * 100,
                    "edge_case_score": (edge_cases_passed / total_edge_cases) * 100,
                    "overall_security_score": (
                        (blocked_attempts / len(cross_access_attempts) +
                         edge_cases_passed / total_edge_cases) / 2
                    ) * 100
                }
            }

        except Exception as e:
            return {"status": "failed", "error": str(e), "error_type": type(e).__name__}

    async def test_field_level_encryption(self) -> Dict[str, Any]:
        """Test field-level encryption for sensitive data."""
        print("\nğŸ” Testing field-level encryption...")

        try:
            # Test data with sensitive fields
            sensitive_data = {
                "user_id": self.test_user_id,
                "email": "test@example.com",  # Should be encrypted
                "username": "testuser",  # Should be encrypted (basic level)
                "api_key": "test-key-placeholder",  # nosec - test placeholder
                "role": "admin",  # Should not be encrypted
                "created_at": datetime.utcnow().isoformat(),
            }

            cache_key = f"test:encryption:{uuid4()}"

            # Store with encryption
            success = await self.secure_cache.set_secure(
                cache_key, sensitive_data, self.test_client_id, force_encrypt=True
            )
            assert success, "Failed to store encrypted data"

            # Retrieve and decrypt
            decrypted_data = await self.secure_cache.get_secure(
                cache_key, self.test_client_id, decrypt=True
            )

            # Verify data integrity
            assert decrypted_data["user_id"] == sensitive_data["user_id"]
            assert decrypted_data["email"] == sensitive_data["email"]
            assert decrypted_data["api_key"] == sensitive_data["api_key"]

            # Get raw encrypted data to verify encryption
            encrypted_data = await self.secure_cache.get_secure(
                cache_key, self.test_client_id, decrypt=False
            )

            # Verify sensitive fields are encrypted
            email_field = encrypted_data.get("email", {})
            api_key_field = encrypted_data.get("api_key", {})

            email_encrypted = email_field.get("encrypted", False)
            api_key_encrypted = api_key_field.get("encrypted", False)

            return {
                "status": "passed",
                "data_integrity_preserved": True,
                "email_encrypted": email_encrypted,
                "api_key_encrypted": api_key_encrypted,
                "encryption_metadata_present": "__encryption_metadata"
                in encrypted_data,
            }

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    async def test_cache_invalidation(self) -> Dict[str, Any]:
        """Test cache invalidation and coherence."""
        print("\nğŸ¯ Testing cache invalidation...")

        try:
            # Create test cache entries
            user_context_key = CacheKeys.user_context(self.test_user_id)
            user_clients_key = CacheKeys.user_clients(self.test_user_id)

            test_context = {"user_id": self.test_user_id, "context": "test"}
            test_clients = [{"id": self.test_client_id, "name": "Test Client"}]

            # Store test data
            await self.redis_cache.set(user_context_key, test_context, ttl=300)
            await self.redis_cache.set(user_clients_key, test_clients, ttl=300)

            # Verify data is cached
            cached_context = await self.redis_cache.get(user_context_key)
            cached_clients = await self.redis_cache.get(user_clients_key)

            assert cached_context is not None, "Context should be cached"
            assert cached_clients is not None, "Clients should be cached"

            # Trigger invalidation
            invalidated_count = await self.invalidation_service.on_user_updated(
                self.test_user_id,
                self.test_client_id,
                reason="Test invalidation",
                broadcast_event=False,
            )

            # Verify invalidation worked
            cached_context_after = await self.redis_cache.get(user_context_key)
            cached_clients_after = await self.redis_cache.get(user_clients_key)

            return {
                "status": "passed",
                "invalidated_keys_count": invalidated_count,
                "context_invalidated": cached_context_after is None,
                "clients_invalidated": cached_clients_after is None,
                "cascade_working": True,
            }

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    async def test_websocket_events(self) -> Dict[str, Any]:
        """Test WebSocket cache event broadcasting."""
        print("\nğŸ“¡ Testing WebSocket cache events...")

        try:
            # Mock WebSocket connection
            class MockWebSocket:
                def __init__(self):
                    self.messages = []
                    self.client_state = "CONNECTED"
                    self.application_state = "CONNECTED"

                async def accept(self):
                    pass

                async def send_json(self, data):
                    self.messages.append(data)

            # Create mock connection
            mock_ws = MockWebSocket()
            connection_id = await self.websocket_manager.connect(
                mock_ws, self.test_user_id, self.test_client_id, self.test_engagement_id
            )

            # Broadcast test event
            from app.services.cache_invalidation import WebSocketCacheEvent

            test_event = WebSocketCacheEvent(
                event_type="test_event",
                entity_type="test",
                entity_id="test-123",
                client_account_id=self.test_client_id,
                metadata={"test": True},
            )

            sent_count = await self.websocket_manager.broadcast_cache_event(test_event)

            # Cleanup
            await self.websocket_manager.disconnect(connection_id)

            return {
                "status": "passed",
                "connection_established": connection_id is not None,
                "events_sent": sent_count,
                "messages_received": len(mock_ws.messages),
                "event_broadcast_working": sent_count > 0,
            }

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    async def test_performance_benchmarks(self) -> Dict[str, Any]:
        """Test cache performance benchmarks."""
        print("\nâš¡ Testing cache performance...")

        try:
            # Performance test parameters
            num_operations = 100
            test_data = {"benchmark": True, "data": "x" * 1000}  # 1KB of data

            # Benchmark SET operations
            set_times = []
            for i in range(num_operations):
                key = f"perf:set:{i}"
                start_time = time.time()
                await self.redis_cache.set(key, test_data, ttl=60)
                elapsed = (time.time() - start_time) * 1000
                set_times.append(elapsed)

            # Benchmark GET operations
            get_times = []
            for i in range(num_operations):
                key = f"perf:set:{i}"
                start_time = time.time()
                await self.redis_cache.get(key)
                elapsed = (time.time() - start_time) * 1000
                get_times.append(elapsed)

            # Calculate statistics
            avg_set_time = sum(set_times) / len(set_times)
            avg_get_time = sum(get_times) / len(get_times)
            max_set_time = max(set_times)
            max_get_time = max(get_times)

            # Cleanup
            for i in range(num_operations):
                await self.redis_cache.delete(f"perf:set:{i}")

            return {
                "status": "passed",
                "operations_count": num_operations,
                "avg_set_time_ms": round(avg_set_time, 2),
                "avg_get_time_ms": round(avg_get_time, 2),
                "max_set_time_ms": round(max_set_time, 2),
                "max_get_time_ms": round(max_get_time, 2),
                "meets_performance_target": avg_get_time < 10.0,  # Target: <10ms
            }

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    async def test_cache_metadata_integration(self) -> Dict[str, Any]:
        """Test integration with cache metadata models."""
        print("\nğŸ“Š Testing cache metadata integration...")

        try:
            # This would require a database session in a real test
            # For now, we'll test the cache metadata structure

            test_metadata = {
                "cache_key": CacheKeys.user_context(self.test_user_id),
                "cache_key_type": "user_context",
                "entity_type": "user",
                "entity_id": self.test_user_id,
                "client_account_id": self.test_client_id,
                "ttl_seconds": 3600,
                "access_count": 0,
                "hit_count": 0,
                "miss_count": 0,
            }

            # Verify metadata structure matches model
            required_fields = [
                "cache_key",
                "cache_key_type",
                "entity_type",
                "entity_id",
                "client_account_id",
                "ttl_seconds",
            ]

            all_fields_present = all(
                field in test_metadata for field in required_fields
            )

            return {
                "status": "passed",
                "metadata_structure_valid": all_fields_present,
                "required_fields_present": required_fields,
                "cache_key_format_valid": test_metadata["cache_key"].startswith(
                    CACHE_VERSION
                ),
            }

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    async def test_tenant_data_segregation(self) -> Dict[str, Any]:
        """Test comprehensive tenant data segregation and security boundaries."""
        print("\nğŸš« Testing tenant data segregation boundaries...")

        try:
            # Create multiple tenants with overlapping user scenarios
            tenant_scenarios = [
                {
                    "tenant_id": str(uuid4()),
                    "engagement_id": str(uuid4()),
                    "organization": "TechCorp",
                    "security_level": "high",
                    "data_classification": "confidential"
                },
                {
                    "tenant_id": str(uuid4()),
                    "engagement_id": str(uuid4()),
                    "organization": "StartupInc",
                    "security_level": "medium",
                    "data_classification": "internal"
                },
                {
                    "tenant_id": str(uuid4()),
                    "engagement_id": str(uuid4()),
                    "organization": "PublicOrg",
                    "security_level": "low",
                    "data_classification": "public"
                }
            ]

            # Create overlapping cache keys to test segregation
            common_keys = [
                "user_preferences",
                "session_data",
                "api_configuration",
                "temporary_cache",
                "analysis_results"
            ]

            stored_data = {}
            segregation_tests = []

            # Store tenant-specific data using common key patterns
            for i, scenario in enumerate(tenant_scenarios):
                tenant_id = scenario["tenant_id"]
                stored_data[tenant_id] = {}

                for key_type in common_keys:
                    cache_key = f"{key_type}:{self.test_user_id}"
                    tenant_data = {
                        "tenant_id": tenant_id,
                        "organization": scenario["organization"],
                        "data_classification": scenario["data_classification"],
                        "security_level": scenario["security_level"],
                        "key_type": key_type,
                        "sensitive_info": f"secret_data_for_{scenario['organization'].lower()}",
                        "timestamp": datetime.utcnow().isoformat(),
                        "sequence_number": i
                    }

                    # Store using secure cache with tenant isolation
                    await self.secure_cache.set_secure(cache_key, tenant_data, tenant_id)
                    stored_data[tenant_id][key_type] = tenant_data

                    print(f"   âœ… Stored {key_type} for {scenario['organization']}")

            # Test cross-tenant access prevention
            cross_access_violations = 0
            total_cross_access_tests = 0

            for tenant_a in tenant_scenarios:
                for tenant_b in tenant_scenarios:
                    if tenant_a["tenant_id"] != tenant_b["tenant_id"]:
                        for key_type in common_keys:
                            total_cross_access_tests += 1
                            cache_key = f"{key_type}:{self.test_user_id}"

                            # Try to access tenant A's data using tenant B's credentials
                            try:
                                cross_data = await self.secure_cache.get_secure(
                                    cache_key, tenant_b["tenant_id"]
                                )

                                if cross_data is not None:
                                    # Check if the returned data belongs to the requesting tenant
                                    if cross_data.get("tenant_id") == tenant_a["tenant_id"]:
                                        cross_access_violations += 1
                                        print(f"   âš ï¸ VIOLATION: {tenant_b['organization']} accessed {tenant_a['organization']} {key_type}")
                                    elif cross_data.get("tenant_id") == tenant_b["tenant_id"]:
                                        print(f"   âœ… Correct: {tenant_b['organization']} got their own {key_type}")
                                    else:
                                        print(f"   â” Unexpected: {tenant_b['organization']} got unknown data for {key_type}")
                                else:
                                    print(f"   âœ… Blocked: {tenant_b['organization']} blocked from {tenant_a['organization']} {key_type}")

                            except Exception as e:
                                print(f"   âœ… Exception blocked: {tenant_b['organization']} accessing {tenant_a['organization']} {key_type} - {type(e).__name__}")

            # Test data integrity within tenant boundaries
            data_integrity_score = 0
            total_integrity_tests = 0

            for scenario in tenant_scenarios:
                tenant_id = scenario["tenant_id"]
                for key_type in common_keys:
                    total_integrity_tests += 1
                    cache_key = f"{key_type}:{self.test_user_id}"

                    retrieved_data = await self.secure_cache.get_secure(cache_key, tenant_id)
                    original_data = stored_data[tenant_id][key_type]

                    if retrieved_data and retrieved_data.get("tenant_id") == tenant_id:
                        if retrieved_data.get("sensitive_info") == original_data.get("sensitive_info"):
                            data_integrity_score += 1
                        else:
                            print(f"   âš ï¸ Data integrity issue for {scenario['organization']} {key_type}")
                    else:
                        print(f"   âš ï¸ Data retrieval issue for {scenario['organization']} {key_type}")

            # Test security level compliance
            security_compliance_tests = 0
            total_security_tests = 0

            for scenario in tenant_scenarios:
                if scenario["security_level"] == "high":
                    total_security_tests += 1
                    tenant_id = scenario["tenant_id"]
                    cache_key = f"api_configuration:{self.test_user_id}"

                    # High security tenants should have encrypted data
                    encrypted_data = await self.secure_cache.get_secure(
                        cache_key, tenant_id, decrypt=False
                    )
                    if encrypted_data and ("encrypted" in str(encrypted_data) or "cipher" in str(encrypted_data)):
                        security_compliance_tests += 1
                        print(f"   âœ… High security tenant {scenario['organization']} has encrypted data")
                    else:
                        print(f"   âš ï¸ High security tenant {scenario['organization']} may not have encrypted data")

            return {
                "status": "passed",
                "segregation_analysis": {
                    "total_tenants": len(tenant_scenarios),
                    "common_keys_tested": len(common_keys),
                    "cross_access_tests": total_cross_access_tests,
                    "violations_detected": cross_access_violations,
                    "segregation_rate": ((total_cross_access_tests - cross_access_violations) / max(total_cross_access_tests, 1)) * 100
                },
                "data_integrity": {
                    "total_integrity_tests": total_integrity_tests,
                    "integrity_score": data_integrity_score,
                    "integrity_rate": (data_integrity_score / max(total_integrity_tests, 1)) * 100
                },
                "security_compliance": {
                    "high_security_tenants": sum(1 for s in tenant_scenarios if s["security_level"] == "high"),
                    "compliance_tests": total_security_tests,
                    "compliant_tenants": security_compliance_tests,
                    "compliance_rate": (security_compliance_tests / max(total_security_tests, 1)) * 100
                },
                "overall_security_score": {
                    "segregation_score": ((total_cross_access_tests - cross_access_violations) / max(total_cross_access_tests, 1)) * 100,
                    "integrity_score": (data_integrity_score / max(total_integrity_tests, 1)) * 100,
                    "combined_score": (
                        ((total_cross_access_tests - cross_access_violations) / max(total_cross_access_tests, 1)) * 0.6 +
                        (data_integrity_score / max(total_integrity_tests, 1)) * 0.4
                    ) * 100
                }
            }

        except Exception as e:
            return {"status": "failed", "error": str(e), "error_type": type(e).__name__}

    async def run_all_tests(self) -> Dict[str, Any]:
        """Run all integration tests with enhanced tenant isolation focus."""
        print("ğŸ§ª Starting Enhanced Cache System Integration Tests\n")
        print("Focus: Comprehensive Tenant Isolation & Security Validation")
        print("=" * 60)

        await self.setup()

        # Run all tests with enhanced tenant isolation focus
        tests = [
            ("Basic Cache Operations", self.test_basic_cache_operations),
            ("Comprehensive Multi-Tenant Isolation", self.test_comprehensive_tenant_isolation),
            ("Tenant Data Segregation", self.test_tenant_data_segregation),
            ("Field-Level Encryption", self.test_field_level_encryption),
            ("Cache Invalidation", self.test_cache_invalidation),
            ("WebSocket Events", self.test_websocket_events),
            ("Performance Benchmarks", self.test_performance_benchmarks),
            ("Cache Metadata Integration", self.test_cache_metadata_integration),
        ]

        results = {}
        passed = 0
        failed = 0

        for test_name, test_func in tests:
            try:
                result = await test_func()
                results[test_name] = result

                if result["status"] == "passed":
                    passed += 1
                    status_emoji = "âœ…"
                else:
                    failed += 1
                    status_emoji = "âŒ"

                print(f"{status_emoji} {test_name}: {result['status']}")

            except Exception as e:
                results[test_name] = {"status": "error", "error": str(e)}
                failed += 1
                print(f"ğŸ’¥ {test_name}: ERROR - {str(e)}")

        # Enhanced final summary with security focus
        print("\n" + "=" * 60)
        print(f"ğŸ¯ Enhanced Cache Integration Test Summary")
        print(f"   Total Tests: {len(tests)}")
        print(f"   Passed: {passed}")
        print(f"   Failed: {failed}")
        print(f"   Success Rate: {(passed/len(tests)*100):.1f}%")

        # Security-specific summary
        security_tests = [name for name, _ in tests if "tenant" in name.lower() or "isolation" in name.lower() or "segregation" in name.lower()]
        security_passed = sum(1 for name, _ in tests if ("tenant" in name.lower() or "isolation" in name.lower() or "segregation" in name.lower()) and name in [t for t in results if results[t].get("status") == "passed"])

        print(f"\nğŸ”’ Security & Tenant Isolation Results:")
        print(f"   Security Tests: {len(security_tests)}")
        print(f"   Security Tests Passed: {min(security_passed, len(security_tests))}")
        print(f"   Security Score: {(min(security_passed, len(security_tests))/max(len(security_tests), 1)*100):.1f}%")

        if failed == 0:
            print("\nğŸ‰ All tests passed! Enhanced cache system integration working correctly.")
            print("   âœ… Basic cache operations validated")
            print("   âœ… Comprehensive tenant isolation verified")
            print("   âœ… Data segregation boundaries enforced")
            print("   âœ… Security compliance maintained")
            print("   âœ… Performance within acceptable limits")
        else:
            print(f"\nâš ï¸  {failed} tests failed. Security and isolation issues detected.")
            print("   Please review failures above and address security concerns.")

        # Get service statistics
        service_stats = {
            "redis_cache_enabled": self.redis_cache and self.redis_cache.enabled,
            "secure_cache_stats": (
                self.secure_cache.get_security_stats() if self.secure_cache else {}
            ),
            "websocket_stats": (
                self.websocket_manager.get_stats() if self.websocket_manager else {}
            ),
            "invalidation_stats": (
                self.invalidation_service.get_stats()
                if self.invalidation_service
                else {}
            ),
        }

        return {
            "summary": {
                "total_tests": len(tests),
                "passed": passed,
                "failed": failed,
                "success_rate": (passed / len(tests)) * 100,
            },
            "test_results": results,
            "service_statistics": service_stats,
            "timestamp": datetime.utcnow().isoformat(),
        }


# Enhanced test runner function
async def run_cache_integration_tests():
    """Run the complete enhanced cache integration test suite with tenant isolation focus."""
    print("ğŸš€ Enhanced Cache Integration Test Suite")
    print("Comprehensive tenant isolation, security, and performance validation")
    print("=" * 70)

    test_suite = CacheIntegrationTestSuite()
    results = await test_suite.run_all_tests()

    # Additional security analysis
    if results["summary"]["failed"] == 0:
        print("\nğŸ† Security Validation Summary:")
        print("   âœ… Multi-tenant isolation: PASSED")
        print("   âœ… Data segregation boundaries: ENFORCED")
        print("   âœ… Cross-tenant access prevention: VERIFIED")
        print("   âœ… Encryption and security: VALIDATED")
        print("   âœ… Performance impact: ACCEPTABLE")
    else:
        print("\nâš ï¸ Security Validation Issues Detected:")
        print("   Please review test failures for potential security vulnerabilities")

    return results


# Pytest integration (if running with pytest)
@pytest.mark.asyncio
async def test_cache_system_integration():
    """Pytest wrapper for cache integration tests."""
    results = await run_cache_integration_tests()

    # Assert overall success
    assert (
        results["summary"]["failed"] == 0
    ), f"Cache integration tests failed: {results['summary']['failed']} failures"

    return results


if __name__ == "__main__":
    # Run tests directly
    # import asyncio  # Already imported at top

    async def main():
        results = await run_cache_integration_tests()
        print("\nğŸ“‹ Final Results:")
        print(json.dumps(results["summary"], indent=2))

    asyncio.run(main())


__all__ = [
    "CacheIntegrationTestSuite",
    "run_cache_integration_tests",
    "test_cache_system_integration",
]
