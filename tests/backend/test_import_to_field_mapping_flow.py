#!/usr/bin/env python3
"""
Test script to verify data import to field mapping flow works correctly.
Tests that the flow status endpoint returns the required data for field mapping.
"""

import asyncio
import json
import os
import sys
from pathlib import Path

# Add backend to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "backend"))

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker

from app.models.discovery_flow import DiscoveryFlow
from app.models.data_import.core import DataImport, RawImportRecord


async def test_flow_status_includes_import_data():
    """Test that flow status endpoint includes import metadata and raw data."""

    # Database connection
    DATABASE_URL = os.getenv(
        "DATABASE_URL",
        "postgresql+asyncpg://postgres:postgres@localhost:5433/migration_db"
    )

    engine = create_async_engine(DATABASE_URL, echo=False)
    async_session = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

    async with async_session() as session:
        try:
            # Find a discovery flow with data import
            flow_query = (
                select(DiscoveryFlow)
                .where(DiscoveryFlow.data_import_id.isnot(None))
                .limit(1)
            )
            result = await session.execute(flow_query)
            flow = result.scalar_one_or_none()

            if not flow:
                print("‚ùå No discovery flow with data import found")
                return False

            print(f"‚úÖ Found flow: {flow.flow_id}")
            print(f"   Data Import ID: {flow.data_import_id}")

            # Check if data import exists
            if flow.data_import_id:
                import_query = select(DataImport).where(
                    DataImport.id == flow.data_import_id
                )
                import_result = await session.execute(import_query)
                data_import = import_result.scalar_one_or_none()

                if data_import:
                    print(f"‚úÖ Data import found: {data_import.id}")

                    # Get raw records for this import
                    raw_records_query = (
                        select(RawImportRecord)
                        .where(RawImportRecord.data_import_id == data_import.id)
                        .order_by(RawImportRecord.row_number)
                    )
                    raw_result = await session.execute(raw_records_query)
                    raw_records = raw_result.scalars().all()

                    raw_data = [record.raw_data for record in raw_records] if raw_records else []

                    print(f"   Has raw records: {bool(raw_records)}")
                    if raw_data:
                        print(f"   Record count: {len(raw_data)}")
                        print(f"   Sample fields: {list(raw_data[0].keys())[:5] if raw_data else []}")
                else:
                    print(f"‚ùå Data import not found for ID: {flow.data_import_id}")

            # Simulate what the flow status endpoint should return
            flow_status = {
                "flow_id": flow.flow_id,
                "data_import_id": flow.data_import_id,
                "import_metadata": {
                    "import_id": flow.data_import_id,
                    "data_import_id": flow.data_import_id,
                },
                "field_mappings": flow.field_mappings or [],
            }

            if data_import and raw_data:
                flow_status["raw_data"] = raw_data
                flow_status["flow_name"] = f"Discovery Import {flow.data_import_id}"

            print("\nüìä Flow status response structure:")
            print(f"   - Has import_metadata: {bool(flow_status.get('import_metadata'))}")
            print(f"   - Has raw_data: {bool(flow_status.get('raw_data'))}")
            print(f"   - Has field_mappings: {bool(flow_status.get('field_mappings'))}")

            # Check if essential fields for field mapping are present
            # Note: field_mappings may be empty initially until generated
            essential_fields = ["import_metadata", "raw_data"]
            missing_essential = [f for f in essential_fields if f not in flow_status or not flow_status[f]]

            if missing_essential:
                print(f"\n‚ùå Missing essential fields: {missing_essential}")
                return False
            else:
                print(f"\n‚úÖ Essential fields present for field mapping")
                if not flow_status.get("field_mappings"):
                    print("   ‚ÑπÔ∏è  Field mappings not yet generated (this is normal for new imports)")
                else:
                    print(f"   ‚úÖ Field mappings present: {len(flow_status['field_mappings'])} mappings")
                return True

        except Exception as e:
            print(f"‚ùå Error testing flow status: {e}")
            import traceback
            traceback.print_exc()
            return False
        finally:
            await engine.dispose()


async def main():
    """Main test runner."""
    print("üîç Testing Data Import to Field Mapping Flow")
    print("=" * 50)

    success = await test_flow_status_includes_import_data()

    print("\n" + "=" * 50)
    if success:
        print("‚úÖ FLOW STATUS TEST: PASSED")
        print("   The flow status endpoint is properly configured")
        print("   Field mapping should work correctly")
    else:
        print("‚ùå FLOW STATUS TEST: FAILED")
        print("   The flow status endpoint needs fixing")
        print("   Field mapping may not work properly")

    return 0 if success else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
